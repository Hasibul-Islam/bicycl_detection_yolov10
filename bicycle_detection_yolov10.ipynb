{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBUBA2T8wVU+u1uP+l+ghz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasibul-Islam/bicycl_detection_yolov10/blob/main/bicycle_detection_yolov10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuPi_qcDTPCQ",
        "outputId": "78c4a16f-45b0-4496-a94d-ecf1f3baac39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrntV1CISM6X",
        "outputId": "b3558534-5f32-4f09-d860-cea35c267dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset prepared in YOLO format at: /content/drive/MyDrive/bicycle_dataset\n"
          ]
        }
      ],
      "source": [
        "# dataset labeling and splitting\n",
        "\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# ======== CONFIG ========\n",
        "dataset_folder = \"/content/gdrive/MyDrive/bicycle_raw\"  # your folder with jpg + xml\n",
        "output_folder = \"/content/gdrive/MyDrive/bicycle_dataset\"       # new YOLO dataset folder\n",
        "split_ratio = 0.8  # 80% train, 20% val\n",
        "class_name_to_id = {\"Bicycle\": 0}  # class mapping\n",
        "# ========================\n",
        "\n",
        "# Create folders\n",
        "for split in ['train', 'val']:\n",
        "    os.makedirs(os.path.join(output_folder, 'images', split), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_folder, 'labels', split), exist_ok=True)\n",
        "\n",
        "# Get all image files\n",
        "image_files = [f for f in os.listdir(dataset_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Split into train/val\n",
        "split_index = int(len(image_files) * split_ratio)\n",
        "train_files = image_files[:split_index]\n",
        "val_files = image_files[split_index:]\n",
        "\n",
        "def convert_xml_to_yolo(xml_path, img_w, img_h):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    yolo_lines = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "\n",
        "        cls_name = obj.find('name').text\n",
        "        if cls_name not in class_name_to_id:\n",
        "            continue\n",
        "        cls_id = class_name_to_id[cls_name]\n",
        "\n",
        "        xml_box = obj.find('bndbox')\n",
        "        xmin = float(xml_box.find('xmin').text)\n",
        "        ymin = float(xml_box.find('ymin').text)\n",
        "        xmax = float(xml_box.find('xmax').text)\n",
        "        ymax = float(xml_box.find('ymax').text)\n",
        "\n",
        "        # Convert to YOLO format\n",
        "        x_center = ((xmin + xmax) / 2) / img_w\n",
        "        y_center = ((ymin + ymax) / 2) / img_h\n",
        "        width = (xmax - xmin) / img_w\n",
        "        height = (ymax - ymin) / img_h\n",
        "\n",
        "        yolo_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "    return yolo_lines\n",
        "\n",
        "def process_split(files_list, split_name):\n",
        "\n",
        "    for img_file in files_list:\n",
        "\n",
        "\n",
        "        xml_file = os.path.splitext(img_file)[0] + \".xml\"\n",
        "        img_path = os.path.join(dataset_folder, img_file)\n",
        "        xml_path = os.path.join(dataset_folder, xml_file)\n",
        "\n",
        "        # Copy image\n",
        "        shutil.copy(img_path, os.path.join(output_folder, 'images', split_name, img_file))\n",
        "\n",
        "        # Get image size from XML\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        img_w = int(root.find('size').find('width').text)\n",
        "        img_h = int(root.find('size').find('height').text)\n",
        "\n",
        "        # Convert and save YOLO label\n",
        "        yolo_data = convert_xml_to_yolo(xml_path, img_w, img_h)\n",
        "        label_path = os.path.join(output_folder, 'labels', split_name, os.path.splitext(img_file)[0] + \".txt\")\n",
        "        with open(label_path, 'w') as f:\n",
        "            f.write(\"\\n\".join(yolo_data))\n",
        "\n",
        "# Process train and val\n",
        "process_split(train_files, 'train')\n",
        "process_split(val_files, 'val')\n",
        "\n",
        "print(\"âœ… Dataset prepared in YOLO format at:\", output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# =====================\n",
        "# STEP 2: Install YOLOv10 (Ultralytics)\n",
        "# =====================\n",
        "!pip install ultralytics opencv-python --quiet\n",
        "\n",
        "# =====================\n",
        "# STEP 3: Create data.yaml\n",
        "# =====================\n",
        "yaml_content = \"\"\"\n",
        "path: /content/drive/MyDrive/bicycle_dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "  0: Bicycle\n",
        "\"\"\"\n",
        "#with open(\"/content/drive/MyDrive/bicycle_dataset/data.yaml\", \"w\") as f:\n",
        "    #f.write(yaml_content)\n",
        "\n",
        "#print(\"âœ… data.yaml created at /content/drive/MyDrive/bicycle_dataset/data.yaml\")\n",
        "\n",
        "# =====================\n",
        "# STEP 4: Train YOLOv10\n",
        "# =====================\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv10n (nano, fastest) â€” change to yolov10s/m/l/x for bigger models\n",
        "model = YOLO(\"yolov10n.pt\")\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    data= \"/content/gdrive/MyDrive/bicycle_dataset/data.yaml\",\n",
        "    epochs=50,            # adjust based on dataset size & GPU\n",
        "    imgsz=640,            # image size\n",
        "    batch=16,             # adjust to fit your GPU memory\n",
        "    project=\"/content/gdrive/MyDrive/yolov10_train\",\n",
        "    name=\"bicycle_model\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Training complete!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZNPH-9gW7-s",
        "outputId": "950abcfe-a5d7-4f5d-d3ea-5a393f568e4c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.179 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/bicycle_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=bicycle_model2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/yolov10_train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/yolov10_train/bicycle_model2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 33.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 23        [16, 19, 22]  1    861718  ultralytics.nn.modules.head.v10Detect        [1, [64, 128, 256]]           \n",
            "YOLOv10n summary: 223 layers, 2,707,430 parameters, 2,707,414 gradients, 8.4 GFLOPs\n",
            "\n",
            "Transferred 493/595 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 220.3Â±300.5 MB/s, size: 3300.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/bicycle_dataset/labels/train... 158 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 158/158 [02:13<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220815_10_46_01_999_000_CsAKAxlHwFVMP3MiV8QmgHFopZc2_T_3072_4080.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220816_18_37_55_083_000_eqApSyuvQgVw8iWRsAySFW29A962_T_1800_4000 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_28_58_774_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_28_58_774_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_29_39_285_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_34_41_006_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_37_35_853_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_37_35_853_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_10_38_20_254_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_17_54_02_541_000_fnAzOl2V8jUzhRf7C1pNKH7XZCg2_T_4608_2080 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220819_17_54_02_541_000_fnAzOl2V8jUzhRf7C1pNKH7XZCg2_T_4608_2080.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220821_09_12_10_357_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220821_09_19_53_009_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/train/20220821_09_23_06_161_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/MyDrive/bicycle_dataset/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 2.5Â±1.8 MB/s, size: 2925.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/bicycle_dataset/labels/val... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:38<00:00,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/val/20220816_18_37_55_083_000_eqApSyuvQgVw8iWRsAySFW29A962_T_1800_4000.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/val/20220819_10_29_39_285_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/val/20220819_10_34_41_006_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/val/20220819_10_36_19_060_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944 (1).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/gdrive/MyDrive/bicycle_dataset/images/val/20220821_09_23_06_161_000_hZQaKn4zVMT2wlTW9KEEaSSmUWr1_F_2592_1944.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gdrive/MyDrive/bicycle_dataset/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/gdrive/MyDrive/yolov10_train/bicycle_model2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/gdrive/MyDrive/yolov10_train/bicycle_model2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50       2.8G      2.161      7.891      2.757         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44    0.00367          1      0.327      0.236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      3.29G      2.093       7.13      2.751         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44    0.00367          1      0.297      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50       3.3G      2.126      6.531      2.799         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44    0.00367          1      0.294      0.152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      3.32G       2.19       6.42      2.807         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44    0.00358      0.977      0.321      0.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      3.33G      2.286      6.012      2.816         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44    0.00358      0.977       0.23      0.108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      3.35G      2.408      5.728      2.884         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.463      0.341      0.361      0.161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      3.36G      2.592      5.816      3.045         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.269      0.295      0.244      0.123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      3.38G      2.505       5.29      2.883         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.382      0.197      0.295      0.123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      3.39G      2.482      5.285      2.963         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.555      0.198      0.276      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      3.41G      2.444      4.933      2.892         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.351     0.0455      0.066     0.0307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      3.43G      2.402      4.485      2.829         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44       0.25      0.295      0.235     0.0942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      3.44G      2.422      4.377      2.883         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44       0.22      0.159      0.132     0.0557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      3.46G       2.47      4.299      2.815         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.414      0.227      0.205      0.107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      3.47G      2.327      4.112      2.844         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.486      0.559      0.466      0.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      3.49G      2.476      3.851      2.831         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.391      0.591      0.455      0.239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50       3.5G      2.561      3.915      2.937         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.401      0.472      0.333      0.149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      3.52G      2.421      3.676      2.795         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.619      0.455       0.48       0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      3.54G      2.327      3.584      2.808         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.618      0.591      0.624      0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      3.55G      2.277      3.386      2.716         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.645      0.591      0.568      0.287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      3.57G      2.243      3.295      2.747         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.653      0.641      0.725      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      3.58G      2.222      3.005      2.619         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.601      0.547      0.602      0.304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50       3.6G      2.265       3.06      2.671         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.648      0.773      0.794      0.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      3.61G      2.214      2.973      2.641         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.602      0.659      0.673      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      3.63G      2.009      2.833      2.527         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.635      0.712      0.723      0.463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      3.64G      2.185      2.788      2.697         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.712       0.75      0.731      0.408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      3.66G      2.069       2.63       2.62         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.857      0.727      0.803      0.527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      3.67G      2.023      2.597      2.502         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.747      0.807      0.809      0.547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      3.69G      1.992      2.432      2.565         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.941      0.723      0.858      0.627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      3.71G      1.938       2.38      2.524         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.898      0.773      0.871      0.644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      3.72G      1.905      2.297      2.446         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.831      0.864      0.901      0.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      3.74G      1.754      2.141      2.371         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.854      0.795      0.881      0.613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      3.75G      1.799      2.269      2.458         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.842      0.705      0.814      0.502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      3.77G      1.816      2.129        2.4         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.845      0.744      0.804      0.518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      3.78G      1.782      2.056      2.427         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.885      0.773      0.851      0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50       3.8G      1.865      2.107       2.45         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.896      0.841      0.871      0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      3.81G      1.743      2.007      2.349         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44       0.84      0.864      0.892       0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      3.83G      1.797      2.096      2.454         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.911      0.818       0.91      0.651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      3.84G      1.624      1.894      2.312         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.902      0.886      0.899      0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      3.86G      1.606      1.809      2.296         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.892      0.886      0.935       0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      3.88G      1.638      1.884      2.306         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.903      0.909      0.929      0.667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      3.89G      1.347       2.37      2.166         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.92s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.921      0.886      0.945      0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      3.91G      1.409      2.206      2.182         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.952      0.904      0.948      0.686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      3.93G      1.355      2.038      2.184         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.953      0.912      0.948      0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      3.94G      1.256      1.994      2.036         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.944      0.909      0.938      0.693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      3.96G      1.289       1.93      2.127         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.945      0.909      0.937       0.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      3.97G      1.204      1.865      2.023         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.909      0.904      0.928      0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      3.99G      1.173      1.804      2.042         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.898      0.909       0.93      0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50         4G      1.164      1.833      2.026         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44       0.93      0.899      0.942      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      4.02G      1.175      1.782      1.979         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.938      0.909      0.944      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      4.03G      1.069      1.663      1.948         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.951      0.932      0.946      0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.152 hours.\n",
            "Optimizer stripped from /content/gdrive/MyDrive/yolov10_train/bicycle_model2/weights/last.pt, 5.7MB\n",
            "Optimizer stripped from /content/gdrive/MyDrive/yolov10_train/bicycle_model2/weights/best.pt, 5.7MB\n",
            "\n",
            "Validating /content/gdrive/MyDrive/yolov10_train/bicycle_model2/weights/best.pt...\n",
            "Ultralytics 8.3.179 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv10n summary (fused): 102 layers, 2,265,363 parameters, 0 gradients, 6.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         40         44      0.952      0.905      0.948      0.732\n",
            "Speed: 0.2ms preprocess, 5.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/yolov10_train/bicycle_model2\u001b[0m\n",
            "âœ… Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import shutil\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Copy video to local storage\n",
        "drive_video_path = \"/content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4\"\n",
        "local_video_path = '/content/video.mp4'\n",
        "\n",
        "if not os.path.exists(local_video_path):\n",
        "    print(\"Copying video from Google Drive to local storage...\")\n",
        "    shutil.copy(drive_video_path, local_video_path)\n",
        "    print(\"Copy complete!\")\n",
        "else:\n",
        "    print(\"Video already exists locally.\")\n",
        "\n",
        "# Step 2: Load YOLOv10 model\n",
        "#model_path = \"/content/gdrive/MyDrive/yolov10_train/bicycle_model2/weights/best.pt\"\n",
        "#model = YOLO(model_path)\n",
        "model = YOLO('yolov10n.pt')\n",
        "\n",
        "# Step 3: Open video\n",
        "cap = cv2.VideoCapture(local_video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"Failed to open video!\")\n",
        "\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Save locally first\n",
        "output_path = \"/content/bike_detected.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "print(f\"Processing video: {frame_count} frames at {fps} FPS...\")\n",
        "\n",
        "# Step 4: Process frames\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    t0 = time.time()\n",
        "    ret, frame = cap.read()\n",
        "    t1 = time.time()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run YOLO inference and draw boxes\n",
        "    results = model(frame)\n",
        "    frame_with_boxes = results[0].plot()  # Draw boxes\n",
        "\n",
        "    # Write frame to output video\n",
        "    out.write(frame_with_boxes)\n",
        "\n",
        "    print(f\"Frame {frame_idx}: Read {(t1-t0)*1000:.1f} ms | Inference {(time.time()-t1)*1000:.1f} ms\")\n",
        "    frame_idx += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Step 5: Copy video to Google Drive\n",
        "shutil.copy(output_path, \"/content/gdrive/MyDrive/bicycle_dataset/bike_detected.mp4\")\n",
        "print(\"Processing complete! Video saved to Google Drive!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1V-yfaHxJ_a",
        "outputId": "85bb45c7-57ab-4c1c-9211-1e71a0dddaa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video already exists locally.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt': 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.59M/5.59M [00:00<00:00, 46.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 120.1ms\n",
            "Speed: 5.6ms preprocess, 120.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 174: Read 3.6 ms | Inference 158.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.8ms\n",
            "Speed: 7.5ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 175: Read 3.6 ms | Inference 164.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.0ms\n",
            "Speed: 6.0ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 176: Read 3.6 ms | Inference 163.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 138.1ms\n",
            "Speed: 7.6ms preprocess, 138.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 177: Read 3.7 ms | Inference 173.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.0ms\n",
            "Speed: 6.3ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 178: Read 3.7 ms | Inference 157.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 118.9ms\n",
            "Speed: 4.9ms preprocess, 118.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 179: Read 3.8 ms | Inference 155.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.2ms\n",
            "Speed: 6.9ms preprocess, 120.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 180: Read 3.6 ms | Inference 161.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 123.5ms\n",
            "Speed: 7.8ms preprocess, 123.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 181: Read 3.9 ms | Inference 159.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.4ms\n",
            "Speed: 6.2ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 182: Read 4.6 ms | Inference 157.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.7ms\n",
            "Speed: 6.2ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 183: Read 3.7 ms | Inference 168.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 130.3ms\n",
            "Speed: 5.8ms preprocess, 130.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 184: Read 4.3 ms | Inference 178.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 188.2ms\n",
            "Speed: 6.0ms preprocess, 188.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 185: Read 3.5 ms | Inference 232.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 182.1ms\n",
            "Speed: 4.2ms preprocess, 182.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 186: Read 3.6 ms | Inference 232.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 182.8ms\n",
            "Speed: 9.7ms preprocess, 182.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 187: Read 11.9 ms | Inference 239.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 230.9ms\n",
            "Speed: 6.4ms preprocess, 230.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 188: Read 3.6 ms | Inference 276.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 179.1ms\n",
            "Speed: 6.2ms preprocess, 179.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 189: Read 3.5 ms | Inference 226.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 185.8ms\n",
            "Speed: 7.0ms preprocess, 185.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 190: Read 3.6 ms | Inference 229.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 275.4ms\n",
            "Speed: 6.2ms preprocess, 275.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 191: Read 3.9 ms | Inference 320.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 196.4ms\n",
            "Speed: 6.3ms preprocess, 196.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 192: Read 3.5 ms | Inference 255.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 217.3ms\n",
            "Speed: 12.8ms preprocess, 217.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 193: Read 12.8 ms | Inference 274.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 3 cell phones, 181.5ms\n",
            "Speed: 6.0ms preprocess, 181.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 194: Read 3.7 ms | Inference 232.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 177.3ms\n",
            "Speed: 11.6ms preprocess, 177.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 195: Read 17.1 ms | Inference 233.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 186.8ms\n",
            "Speed: 10.0ms preprocess, 186.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 196: Read 10.0 ms | Inference 247.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 194.2ms\n",
            "Speed: 11.9ms preprocess, 194.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 197: Read 3.5 ms | Inference 258.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 197.4ms\n",
            "Speed: 5.7ms preprocess, 197.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 198: Read 10.0 ms | Inference 246.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 186.0ms\n",
            "Speed: 10.0ms preprocess, 186.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 199: Read 3.6 ms | Inference 241.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 127.0ms\n",
            "Speed: 5.7ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 200: Read 12.4 ms | Inference 166.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 130.1ms\n",
            "Speed: 6.3ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 201: Read 3.5 ms | Inference 171.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 124.3ms\n",
            "Speed: 9.5ms preprocess, 124.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 202: Read 4.1 ms | Inference 165.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 128.1ms\n",
            "Speed: 6.0ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 203: Read 4.4 ms | Inference 167.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 122.2ms\n",
            "Speed: 8.4ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 204: Read 4.1 ms | Inference 164.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.5ms\n",
            "Speed: 6.0ms preprocess, 121.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 205: Read 3.6 ms | Inference 159.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 118.5ms\n",
            "Speed: 6.1ms preprocess, 118.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 206: Read 3.5 ms | Inference 159.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 120.2ms\n",
            "Speed: 10.2ms preprocess, 120.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 207: Read 3.7 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 124.5ms\n",
            "Speed: 8.1ms preprocess, 124.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 208: Read 3.5 ms | Inference 170.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.0ms\n",
            "Speed: 5.3ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 209: Read 8.2 ms | Inference 155.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.9ms\n",
            "Speed: 7.2ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 210: Read 3.6 ms | Inference 156.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 124.2ms\n",
            "Speed: 8.2ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 211: Read 3.9 ms | Inference 161.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.7ms\n",
            "Speed: 6.0ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 212: Read 3.5 ms | Inference 160.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 bicycles, 1 cell phone, 119.7ms\n",
            "Speed: 5.8ms preprocess, 119.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 213: Read 3.5 ms | Inference 158.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 143.7ms\n",
            "Speed: 6.0ms preprocess, 143.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 214: Read 3.5 ms | Inference 180.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 149.3ms\n",
            "Speed: 6.0ms preprocess, 149.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 215: Read 3.8 ms | Inference 188.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 118.2ms\n",
            "Speed: 5.4ms preprocess, 118.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 216: Read 3.4 ms | Inference 160.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.2ms\n",
            "Speed: 6.1ms preprocess, 119.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 217: Read 3.5 ms | Inference 157.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.9ms\n",
            "Speed: 5.9ms preprocess, 120.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 218: Read 3.5 ms | Inference 157.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.0ms\n",
            "Speed: 6.1ms preprocess, 119.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 219: Read 3.5 ms | Inference 158.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 141.3ms\n",
            "Speed: 5.8ms preprocess, 141.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 220: Read 3.7 ms | Inference 180.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 118.5ms\n",
            "Speed: 5.9ms preprocess, 118.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 221: Read 3.7 ms | Inference 155.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.1ms\n",
            "Speed: 6.1ms preprocess, 121.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 222: Read 3.5 ms | Inference 159.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.4ms\n",
            "Speed: 6.2ms preprocess, 119.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 223: Read 3.6 ms | Inference 161.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.8ms\n",
            "Speed: 6.5ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 224: Read 3.7 ms | Inference 158.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 118.0ms\n",
            "Speed: 5.7ms preprocess, 118.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 225: Read 3.6 ms | Inference 159.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 138.7ms\n",
            "Speed: 8.1ms preprocess, 138.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 226: Read 3.7 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 126.1ms\n",
            "Speed: 5.9ms preprocess, 126.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 227: Read 3.6 ms | Inference 164.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.1ms\n",
            "Speed: 5.9ms preprocess, 122.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 228: Read 3.5 ms | Inference 163.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 124.9ms\n",
            "Speed: 6.2ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 229: Read 4.6 ms | Inference 163.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 3 cell phones, 117.5ms\n",
            "Speed: 9.0ms preprocess, 117.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 230: Read 3.6 ms | Inference 162.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.4ms\n",
            "Speed: 5.4ms preprocess, 120.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 231: Read 3.5 ms | Inference 160.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 127.8ms\n",
            "Speed: 6.4ms preprocess, 127.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 232: Read 3.7 ms | Inference 178.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.6ms\n",
            "Speed: 6.0ms preprocess, 122.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 233: Read 10.7 ms | Inference 159.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.0ms\n",
            "Speed: 6.5ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 234: Read 3.7 ms | Inference 158.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.9ms\n",
            "Speed: 6.1ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 235: Read 3.5 ms | Inference 159.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 117.1ms\n",
            "Speed: 6.0ms preprocess, 117.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 236: Read 3.5 ms | Inference 155.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.0ms\n",
            "Speed: 6.1ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 237: Read 3.5 ms | Inference 160.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 123.8ms\n",
            "Speed: 5.2ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 238: Read 3.6 ms | Inference 164.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 167.6ms\n",
            "Speed: 5.9ms preprocess, 167.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 239: Read 4.2 ms | Inference 210.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.0ms\n",
            "Speed: 4.7ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 240: Read 3.6 ms | Inference 164.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.0ms\n",
            "Speed: 5.6ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 241: Read 3.6 ms | Inference 161.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.3ms\n",
            "Speed: 6.7ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 242: Read 4.8 ms | Inference 158.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 122.2ms\n",
            "Speed: 7.8ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 243: Read 3.7 ms | Inference 159.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 124.4ms\n",
            "Speed: 6.4ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 244: Read 3.5 ms | Inference 163.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 132.1ms\n",
            "Speed: 4.5ms preprocess, 132.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 245: Read 3.5 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 119.9ms\n",
            "Speed: 9.8ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 246: Read 3.8 ms | Inference 158.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 1 cell phone, 121.6ms\n",
            "Speed: 8.2ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 247: Read 3.9 ms | Inference 163.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 119.7ms\n",
            "Speed: 7.2ms preprocess, 119.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 248: Read 3.8 ms | Inference 161.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 1 cell phone, 122.9ms\n",
            "Speed: 6.1ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 249: Read 3.6 ms | Inference 164.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.3ms\n",
            "Speed: 6.6ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 250: Read 4.5 ms | Inference 163.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 140.8ms\n",
            "Speed: 6.5ms preprocess, 140.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 251: Read 4.3 ms | Inference 176.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 119.9ms\n",
            "Speed: 6.0ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 252: Read 3.8 ms | Inference 160.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 126.2ms\n",
            "Speed: 6.7ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 253: Read 3.8 ms | Inference 167.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 119.9ms\n",
            "Speed: 9.2ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 254: Read 3.6 ms | Inference 159.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 120.4ms\n",
            "Speed: 4.4ms preprocess, 120.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 255: Read 3.8 ms | Inference 159.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 126.8ms\n",
            "Speed: 6.0ms preprocess, 126.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 256: Read 3.7 ms | Inference 162.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 139.0ms\n",
            "Speed: 8.8ms preprocess, 139.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 257: Read 3.8 ms | Inference 178.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 121.2ms\n",
            "Speed: 7.6ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 258: Read 3.6 ms | Inference 160.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 1 cell phone, 152.7ms\n",
            "Speed: 7.1ms preprocess, 152.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 259: Read 3.7 ms | Inference 205.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 2 cell phones, 183.5ms\n",
            "Speed: 5.7ms preprocess, 183.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 260: Read 3.5 ms | Inference 232.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 183.3ms\n",
            "Speed: 10.0ms preprocess, 183.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 261: Read 9.8 ms | Inference 238.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 207.8ms\n",
            "Speed: 8.5ms preprocess, 207.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 262: Read 3.6 ms | Inference 259.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 235.7ms\n",
            "Speed: 4.2ms preprocess, 235.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 263: Read 13.8 ms | Inference 283.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 1 cell phone, 183.5ms\n",
            "Speed: 5.8ms preprocess, 183.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 264: Read 10.5 ms | Inference 236.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 182.3ms\n",
            "Speed: 5.8ms preprocess, 182.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 265: Read 3.6 ms | Inference 229.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 196.7ms\n",
            "Speed: 6.7ms preprocess, 196.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 266: Read 16.6 ms | Inference 250.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 bicycles, 180.0ms\n",
            "Speed: 5.7ms preprocess, 180.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 267: Read 9.6 ms | Inference 232.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 180.9ms\n",
            "Speed: 5.8ms preprocess, 180.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 268: Read 9.9 ms | Inference 245.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 183.9ms\n",
            "Speed: 6.0ms preprocess, 183.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 269: Read 3.5 ms | Inference 236.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 189.1ms\n",
            "Speed: 7.0ms preprocess, 189.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 270: Read 12.2 ms | Inference 246.2 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 196.4ms\n",
            "Speed: 7.3ms preprocess, 196.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 271: Read 3.6 ms | Inference 251.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 185.6ms\n",
            "Speed: 9.0ms preprocess, 185.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 272: Read 9.7 ms | Inference 242.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 195.8ms\n",
            "Speed: 6.8ms preprocess, 195.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 273: Read 3.6 ms | Inference 253.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 189.1ms\n",
            "Speed: 5.8ms preprocess, 189.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 274: Read 10.1 ms | Inference 241.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 138.6ms\n",
            "Speed: 7.5ms preprocess, 138.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 275: Read 3.6 ms | Inference 178.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 114.7ms\n",
            "Speed: 4.9ms preprocess, 114.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 276: Read 3.8 ms | Inference 155.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 135.3ms\n",
            "Speed: 5.9ms preprocess, 135.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 277: Read 5.1 ms | Inference 177.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 129.3ms\n",
            "Speed: 5.9ms preprocess, 129.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 278: Read 3.7 ms | Inference 183.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 truck, 1 backpack, 128.9ms\n",
            "Speed: 5.6ms preprocess, 128.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 279: Read 3.8 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 truck, 1 backpack, 124.8ms\n",
            "Speed: 5.9ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 280: Read 3.8 ms | Inference 175.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 backpack, 141.3ms\n",
            "Speed: 6.0ms preprocess, 141.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 281: Read 3.8 ms | Inference 184.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 backpack, 121.9ms\n",
            "Speed: 6.1ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 282: Read 3.7 ms | Inference 169.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 1 backpack, 137.5ms\n",
            "Speed: 6.3ms preprocess, 137.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 283: Read 3.8 ms | Inference 179.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 backpack, 128.8ms\n",
            "Speed: 6.3ms preprocess, 128.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 284: Read 3.7 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 backpack, 123.2ms\n",
            "Speed: 6.2ms preprocess, 123.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 285: Read 3.7 ms | Inference 166.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 backpack, 122.8ms\n",
            "Speed: 6.0ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 286: Read 3.6 ms | Inference 167.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 12 cars, 1 backpack, 144.0ms\n",
            "Speed: 6.2ms preprocess, 144.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 287: Read 3.8 ms | Inference 193.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 1 backpack, 127.3ms\n",
            "Speed: 5.7ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 288: Read 4.2 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 122.0ms\n",
            "Speed: 6.3ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 289: Read 3.7 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 126.2ms\n",
            "Speed: 5.8ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 290: Read 3.6 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 backpack, 120.7ms\n",
            "Speed: 6.0ms preprocess, 120.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 291: Read 3.5 ms | Inference 165.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 backpack, 122.0ms\n",
            "Speed: 6.0ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 292: Read 3.6 ms | Inference 171.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 136.9ms\n",
            "Speed: 11.2ms preprocess, 136.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 293: Read 3.8 ms | Inference 182.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 backpack, 132.4ms\n",
            "Speed: 9.3ms preprocess, 132.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 294: Read 3.8 ms | Inference 177.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 1 backpack, 124.1ms\n",
            "Speed: 6.2ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 295: Read 3.7 ms | Inference 168.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 backpack, 119.6ms\n",
            "Speed: 9.9ms preprocess, 119.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 296: Read 4.4 ms | Inference 168.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 2 backpacks, 123.9ms\n",
            "Speed: 6.0ms preprocess, 123.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 297: Read 3.6 ms | Inference 170.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 backpack, 119.3ms\n",
            "Speed: 4.3ms preprocess, 119.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 298: Read 3.8 ms | Inference 159.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 backpack, 133.0ms\n",
            "Speed: 8.9ms preprocess, 133.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 299: Read 4.2 ms | Inference 184.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 1 backpack, 125.6ms\n",
            "Speed: 8.2ms preprocess, 125.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 300: Read 3.8 ms | Inference 166.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 1 backpack, 123.1ms\n",
            "Speed: 6.2ms preprocess, 123.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 301: Read 3.5 ms | Inference 171.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 121.5ms\n",
            "Speed: 6.2ms preprocess, 121.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 302: Read 3.8 ms | Inference 163.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 backpack, 120.9ms\n",
            "Speed: 9.1ms preprocess, 120.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 303: Read 8.2 ms | Inference 167.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 backpack, 121.1ms\n",
            "Speed: 5.7ms preprocess, 121.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 304: Read 3.5 ms | Inference 162.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 146.0ms\n",
            "Speed: 7.3ms preprocess, 146.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 305: Read 4.9 ms | Inference 188.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 127.0ms\n",
            "Speed: 6.7ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 306: Read 3.5 ms | Inference 171.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 backpack, 128.1ms\n",
            "Speed: 7.1ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 307: Read 3.8 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 2 backpacks, 122.9ms\n",
            "Speed: 6.7ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 308: Read 3.7 ms | Inference 167.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 121.9ms\n",
            "Speed: 9.9ms preprocess, 121.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 309: Read 3.7 ms | Inference 167.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 123.6ms\n",
            "Speed: 6.0ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 310: Read 3.6 ms | Inference 168.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 140.7ms\n",
            "Speed: 10.6ms preprocess, 140.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 311: Read 3.8 ms | Inference 188.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 123.0ms\n",
            "Speed: 6.5ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 312: Read 3.8 ms | Inference 160.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 122.6ms\n",
            "Speed: 10.1ms preprocess, 122.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 313: Read 4.4 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 119.3ms\n",
            "Speed: 6.0ms preprocess, 119.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 314: Read 3.7 ms | Inference 164.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 123.6ms\n",
            "Speed: 5.9ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 315: Read 3.6 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 130.9ms\n",
            "Speed: 7.1ms preprocess, 130.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 316: Read 3.7 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 139.1ms\n",
            "Speed: 12.2ms preprocess, 139.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 317: Read 3.7 ms | Inference 191.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 127.6ms\n",
            "Speed: 7.2ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 318: Read 3.8 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 128.5ms\n",
            "Speed: 9.5ms preprocess, 128.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 319: Read 3.7 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 127.7ms\n",
            "Speed: 6.2ms preprocess, 127.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 320: Read 3.7 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 122.1ms\n",
            "Speed: 6.1ms preprocess, 122.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 321: Read 3.6 ms | Inference 167.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 122.0ms\n",
            "Speed: 6.0ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 322: Read 3.6 ms | Inference 168.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 143.0ms\n",
            "Speed: 5.8ms preprocess, 143.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 323: Read 3.7 ms | Inference 181.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 131.0ms\n",
            "Speed: 6.4ms preprocess, 131.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 324: Read 3.6 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 131.8ms\n",
            "Speed: 6.0ms preprocess, 131.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 325: Read 3.7 ms | Inference 177.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 122.5ms\n",
            "Speed: 6.0ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 326: Read 3.6 ms | Inference 168.2 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 4 cars, 128.8ms\n",
            "Speed: 6.2ms preprocess, 128.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 327: Read 3.7 ms | Inference 174.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 127.3ms\n",
            "Speed: 6.0ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 328: Read 3.6 ms | Inference 182.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 123.8ms\n",
            "Speed: 12.1ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 329: Read 15.3 ms | Inference 172.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 124.3ms\n",
            "Speed: 9.7ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 330: Read 3.8 ms | Inference 168.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 134.2ms\n",
            "Speed: 10.5ms preprocess, 134.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 331: Read 3.8 ms | Inference 192.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 1 backpack, 187.9ms\n",
            "Speed: 8.8ms preprocess, 187.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 332: Read 13.8 ms | Inference 247.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 187.1ms\n",
            "Speed: 10.9ms preprocess, 187.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 333: Read 15.3 ms | Inference 251.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 187.4ms\n",
            "Speed: 5.9ms preprocess, 187.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 334: Read 10.4 ms | Inference 243.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 189.1ms\n",
            "Speed: 12.9ms preprocess, 189.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 335: Read 9.9 ms | Inference 256.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 185.6ms\n",
            "Speed: 5.7ms preprocess, 185.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 336: Read 3.8 ms | Inference 245.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 180.7ms\n",
            "Speed: 11.5ms preprocess, 180.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 337: Read 3.7 ms | Inference 244.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 195.7ms\n",
            "Speed: 6.3ms preprocess, 195.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 338: Read 3.6 ms | Inference 258.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 192.2ms\n",
            "Speed: 6.1ms preprocess, 192.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 339: Read 10.5 ms | Inference 259.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 185.1ms\n",
            "Speed: 5.8ms preprocess, 185.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 340: Read 3.7 ms | Inference 248.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 183.3ms\n",
            "Speed: 12.5ms preprocess, 183.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 341: Read 10.3 ms | Inference 259.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 218.8ms\n",
            "Speed: 5.9ms preprocess, 218.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 342: Read 3.6 ms | Inference 281.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 truck, 1 backpack, 193.1ms\n",
            "Speed: 11.9ms preprocess, 193.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 343: Read 9.9 ms | Inference 262.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 190.8ms\n",
            "Speed: 10.9ms preprocess, 190.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 344: Read 12.2 ms | Inference 249.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 bus, 200.0ms\n",
            "Speed: 13.4ms preprocess, 200.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 345: Read 3.8 ms | Inference 268.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 bus, 1 truck, 197.9ms\n",
            "Speed: 9.7ms preprocess, 197.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 346: Read 9.7 ms | Inference 268.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 10 cars, 1 truck, 1 backpack, 122.9ms\n",
            "Speed: 5.6ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 347: Read 4.5 ms | Inference 166.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 10 cars, 1 truck, 1 backpack, 119.3ms\n",
            "Speed: 10.7ms preprocess, 119.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 348: Read 3.7 ms | Inference 163.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 10 cars, 1 bus, 1 truck, 1 backpack, 125.9ms\n",
            "Speed: 6.0ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 349: Read 3.6 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 1 backpack, 122.0ms\n",
            "Speed: 6.3ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 350: Read 3.8 ms | Inference 166.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 9 cars, 1 truck, 123.7ms\n",
            "Speed: 6.9ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 351: Read 3.5 ms | Inference 167.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 9 cars, 1 truck, 139.0ms\n",
            "Speed: 5.8ms preprocess, 139.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 352: Read 3.5 ms | Inference 184.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 1 bus, 1 backpack, 124.5ms\n",
            "Speed: 7.3ms preprocess, 124.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 353: Read 3.7 ms | Inference 169.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 123.6ms\n",
            "Speed: 6.7ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 354: Read 3.6 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 125.1ms\n",
            "Speed: 6.1ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 355: Read 3.6 ms | Inference 171.8 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 10 cars, 1 truck, 122.4ms\n",
            "Speed: 6.6ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 356: Read 3.7 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 128.2ms\n",
            "Speed: 6.5ms preprocess, 128.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 357: Read 3.7 ms | Inference 171.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 truck, 1 backpack, 145.4ms\n",
            "Speed: 6.3ms preprocess, 145.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 358: Read 3.8 ms | Inference 188.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 truck, 1 backpack, 124.0ms\n",
            "Speed: 6.0ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 359: Read 3.8 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 9 cars, 1 backpack, 122.0ms\n",
            "Speed: 10.1ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 360: Read 3.7 ms | Inference 170.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 1 bus, 1 backpack, 121.3ms\n",
            "Speed: 8.2ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 361: Read 3.7 ms | Inference 163.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 1 bus, 1 backpack, 126.6ms\n",
            "Speed: 6.0ms preprocess, 126.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 362: Read 3.6 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 bus, 1 truck, 1 backpack, 121.3ms\n",
            "Speed: 5.8ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 363: Read 3.7 ms | Inference 161.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 bus, 139.5ms\n",
            "Speed: 5.9ms preprocess, 139.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 364: Read 3.5 ms | Inference 180.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 122.3ms\n",
            "Speed: 6.2ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 365: Read 3.6 ms | Inference 162.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 125.2ms\n",
            "Speed: 8.2ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 366: Read 4.5 ms | Inference 173.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 125.1ms\n",
            "Speed: 10.3ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 367: Read 3.7 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 128.4ms\n",
            "Speed: 6.8ms preprocess, 128.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 368: Read 3.8 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 127.5ms\n",
            "Speed: 5.6ms preprocess, 127.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 369: Read 3.7 ms | Inference 167.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 bus, 1 truck, 1 backpack, 132.3ms\n",
            "Speed: 9.6ms preprocess, 132.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 370: Read 3.7 ms | Inference 181.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 bus, 1 truck, 1 backpack, 122.0ms\n",
            "Speed: 5.8ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 371: Read 3.6 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 bus, 1 truck, 1 backpack, 121.9ms\n",
            "Speed: 5.9ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 372: Read 3.6 ms | Inference 164.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 126.7ms\n",
            "Speed: 5.8ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 373: Read 3.7 ms | Inference 170.9 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 6 cars, 1 truck, 1 backpack, 117.9ms\n",
            "Speed: 7.6ms preprocess, 117.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 374: Read 3.5 ms | Inference 163.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 122.1ms\n",
            "Speed: 7.5ms preprocess, 122.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 375: Read 3.7 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 1 backpack, 139.2ms\n",
            "Speed: 5.8ms preprocess, 139.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 376: Read 3.6 ms | Inference 185.3 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 truck, 1 backpack, 122.4ms\n",
            "Speed: 5.6ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 377: Read 3.6 ms | Inference 164.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 truck, 1 backpack, 122.4ms\n",
            "Speed: 6.2ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 378: Read 3.6 ms | Inference 171.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 1 bus, 1 truck, 1 backpack, 126.0ms\n",
            "Speed: 6.0ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 379: Read 3.6 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 truck, 120.9ms\n",
            "Speed: 10.3ms preprocess, 120.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 380: Read 3.7 ms | Inference 168.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 124.0ms\n",
            "Speed: 6.0ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 381: Read 3.6 ms | Inference 166.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 1 backpack, 138.0ms\n",
            "Speed: 10.8ms preprocess, 138.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 382: Read 3.7 ms | Inference 184.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 128.8ms\n",
            "Speed: 5.9ms preprocess, 128.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 383: Read 3.8 ms | Inference 178.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 1 backpack, 121.7ms\n",
            "Speed: 5.9ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 384: Read 3.5 ms | Inference 166.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 1 backpack, 126.0ms\n",
            "Speed: 6.0ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 385: Read 3.6 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 7 cars, 1 truck, 1 backpack, 122.7ms\n",
            "Speed: 9.0ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 386: Read 4.1 ms | Inference 171.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 120.7ms\n",
            "Speed: 8.7ms preprocess, 120.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 387: Read 3.7 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 1 truck, 126.9ms\n",
            "Speed: 11.5ms preprocess, 126.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 388: Read 14.1 ms | Inference 175.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 124.3ms\n",
            "Speed: 5.9ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 389: Read 3.5 ms | Inference 170.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 1 backpack, 121.8ms\n",
            "Speed: 5.9ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 390: Read 3.5 ms | Inference 172.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 122.5ms\n",
            "Speed: 6.4ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 391: Read 3.6 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 121.6ms\n",
            "Speed: 6.0ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 392: Read 3.6 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 120.1ms\n",
            "Speed: 6.2ms preprocess, 120.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 393: Read 3.6 ms | Inference 174.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 138.1ms\n",
            "Speed: 5.8ms preprocess, 138.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 394: Read 3.6 ms | Inference 181.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 124.8ms\n",
            "Speed: 8.0ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 395: Read 4.4 ms | Inference 169.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 128.7ms\n",
            "Speed: 10.8ms preprocess, 128.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 396: Read 3.7 ms | Inference 172.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 127.4ms\n",
            "Speed: 9.0ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 397: Read 3.8 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 123.4ms\n",
            "Speed: 8.0ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 398: Read 3.7 ms | Inference 167.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 121.9ms\n",
            "Speed: 6.2ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 399: Read 3.7 ms | Inference 177.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 133.1ms\n",
            "Speed: 6.7ms preprocess, 133.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 400: Read 3.6 ms | Inference 177.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 128.7ms\n",
            "Speed: 5.9ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 401: Read 3.8 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 1 backpack, 126.0ms\n",
            "Speed: 6.0ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 402: Read 3.7 ms | Inference 175.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 122.8ms\n",
            "Speed: 6.4ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 403: Read 3.9 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 185.1ms\n",
            "Speed: 6.1ms preprocess, 185.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 404: Read 10.5 ms | Inference 249.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 1 truck, 1 backpack, 236.3ms\n",
            "Speed: 6.9ms preprocess, 236.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 405: Read 3.6 ms | Inference 298.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 193.5ms\n",
            "Speed: 6.8ms preprocess, 193.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 406: Read 3.6 ms | Inference 260.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 186.1ms\n",
            "Speed: 5.9ms preprocess, 186.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 407: Read 3.8 ms | Inference 252.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 194.6ms\n",
            "Speed: 11.8ms preprocess, 194.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 408: Read 9.8 ms | Inference 259.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 truck, 207.0ms\n",
            "Speed: 9.0ms preprocess, 207.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 409: Read 3.6 ms | Inference 270.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 196.7ms\n",
            "Speed: 10.1ms preprocess, 196.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 410: Read 10.4 ms | Inference 269.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 1 truck, 182.3ms\n",
            "Speed: 6.1ms preprocess, 182.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 411: Read 3.6 ms | Inference 241.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 182.9ms\n",
            "Speed: 5.8ms preprocess, 182.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 412: Read 10.2 ms | Inference 246.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 2 trucks, 201.2ms\n",
            "Speed: 7.7ms preprocess, 201.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 413: Read 4.0 ms | Inference 259.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 195.9ms\n",
            "Speed: 5.8ms preprocess, 195.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 414: Read 10.4 ms | Inference 259.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 186.4ms\n",
            "Speed: 12.1ms preprocess, 186.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 415: Read 10.9 ms | Inference 260.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 1 truck, 193.6ms\n",
            "Speed: 12.2ms preprocess, 193.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 416: Read 4.2 ms | Inference 263.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 208.1ms\n",
            "Speed: 7.1ms preprocess, 208.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 417: Read 5.8 ms | Inference 270.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 1 truck, 1 backpack, 192.9ms\n",
            "Speed: 6.1ms preprocess, 192.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 418: Read 3.7 ms | Inference 253.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 119.5ms\n",
            "Speed: 5.9ms preprocess, 119.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 419: Read 9.9 ms | Inference 168.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 124.0ms\n",
            "Speed: 5.9ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 420: Read 3.6 ms | Inference 165.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 1 backpack, 130.5ms\n",
            "Speed: 7.3ms preprocess, 130.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 421: Read 3.6 ms | Inference 176.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 1 truck, 1 backpack, 122.7ms\n",
            "Speed: 11.4ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 422: Read 3.7 ms | Inference 184.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 119.9ms\n",
            "Speed: 8.7ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 423: Read 10.1 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 truck, 136.0ms\n",
            "Speed: 7.2ms preprocess, 136.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 424: Read 3.8 ms | Inference 178.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 123.8ms\n",
            "Speed: 5.9ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 425: Read 3.7 ms | Inference 166.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 124.9ms\n",
            "Speed: 11.1ms preprocess, 124.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 426: Read 3.7 ms | Inference 176.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 126.9ms\n",
            "Speed: 11.3ms preprocess, 126.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 427: Read 3.8 ms | Inference 173.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 147.9ms\n",
            "Speed: 11.0ms preprocess, 147.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 428: Read 3.7 ms | Inference 198.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 131.0ms\n",
            "Speed: 7.8ms preprocess, 131.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 429: Read 3.7 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 126.2ms\n",
            "Speed: 9.7ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 430: Read 3.7 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 1 truck, 128.0ms\n",
            "Speed: 5.7ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 431: Read 3.6 ms | Inference 173.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 125.5ms\n",
            "Speed: 11.0ms preprocess, 125.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 432: Read 3.7 ms | Inference 170.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 132.9ms\n",
            "Speed: 7.4ms preprocess, 132.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 433: Read 3.8 ms | Inference 177.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 2 backpacks, 142.9ms\n",
            "Speed: 10.1ms preprocess, 142.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 434: Read 3.7 ms | Inference 191.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 1 backpack, 122.9ms\n",
            "Speed: 6.0ms preprocess, 122.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 435: Read 3.5 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 traffic light, 1 backpack, 120.0ms\n",
            "Speed: 6.0ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 436: Read 3.6 ms | Inference 164.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 121.6ms\n",
            "Speed: 5.8ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 437: Read 3.5 ms | Inference 168.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 2 trucks, 1 backpack, 117.4ms\n",
            "Speed: 4.8ms preprocess, 117.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 438: Read 3.5 ms | Inference 165.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 117.0ms\n",
            "Speed: 7.5ms preprocess, 117.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 439: Read 3.7 ms | Inference 163.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 1 truck, 1 backpack, 137.0ms\n",
            "Speed: 8.7ms preprocess, 137.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 440: Read 3.7 ms | Inference 190.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 124.2ms\n",
            "Speed: 6.7ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 441: Read 3.6 ms | Inference 169.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 122.9ms\n",
            "Speed: 5.7ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 442: Read 3.6 ms | Inference 164.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 126.5ms\n",
            "Speed: 6.0ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 443: Read 4.7 ms | Inference 173.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 1 truck, 1 backpack, 122.1ms\n",
            "Speed: 5.9ms preprocess, 122.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 444: Read 3.6 ms | Inference 164.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 2 backpacks, 125.4ms\n",
            "Speed: 6.5ms preprocess, 125.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 445: Read 3.6 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 bus, 2 trucks, 1 backpack, 139.0ms\n",
            "Speed: 7.9ms preprocess, 139.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 446: Read 5.3 ms | Inference 186.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 bus, 1 truck, 2 backpacks, 125.8ms\n",
            "Speed: 6.2ms preprocess, 125.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 447: Read 3.8 ms | Inference 172.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 bus, 1 truck, 1 backpack, 122.4ms\n",
            "Speed: 9.2ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 448: Read 3.8 ms | Inference 168.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 1 backpack, 131.4ms\n",
            "Speed: 5.7ms preprocess, 131.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 449: Read 3.5 ms | Inference 173.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 1 truck, 1 backpack, 128.0ms\n",
            "Speed: 7.0ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 450: Read 3.8 ms | Inference 171.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 bus, 1 truck, 1 traffic light, 1 backpack, 128.0ms\n",
            "Speed: 6.9ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 451: Read 3.6 ms | Inference 177.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 141.8ms\n",
            "Speed: 5.7ms preprocess, 141.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 452: Read 3.7 ms | Inference 181.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 120.0ms\n",
            "Speed: 10.7ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 453: Read 3.7 ms | Inference 165.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 122.6ms\n",
            "Speed: 5.6ms preprocess, 122.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 454: Read 3.6 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 truck, 1 backpack, 131.7ms\n",
            "Speed: 6.7ms preprocess, 131.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 455: Read 3.6 ms | Inference 175.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 128.0ms\n",
            "Speed: 6.0ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 456: Read 3.5 ms | Inference 175.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 126.0ms\n",
            "Speed: 10.2ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 457: Read 3.9 ms | Inference 175.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 1 backpack, 137.3ms\n",
            "Speed: 5.9ms preprocess, 137.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 458: Read 3.6 ms | Inference 186.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 backpack, 119.2ms\n",
            "Speed: 10.9ms preprocess, 119.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 459: Read 3.7 ms | Inference 168.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 124.4ms\n",
            "Speed: 11.1ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 460: Read 3.7 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 truck, 124.7ms\n",
            "Speed: 6.5ms preprocess, 124.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 461: Read 3.7 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 1 truck, 126.7ms\n",
            "Speed: 6.1ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 462: Read 3.6 ms | Inference 176.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 123.6ms\n",
            "Speed: 6.7ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 463: Read 3.7 ms | Inference 174.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 132.2ms\n",
            "Speed: 9.5ms preprocess, 132.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 464: Read 16.0 ms | Inference 176.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 7 cars, 129.5ms\n",
            "Speed: 7.5ms preprocess, 129.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 465: Read 3.8 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 truck, 124.9ms\n",
            "Speed: 7.8ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 466: Read 3.6 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 120.8ms\n",
            "Speed: 5.8ms preprocess, 120.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 467: Read 3.5 ms | Inference 171.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 127.6ms\n",
            "Speed: 8.6ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 468: Read 3.8 ms | Inference 167.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 128.0ms\n",
            "Speed: 5.4ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 469: Read 3.5 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 138.3ms\n",
            "Speed: 5.8ms preprocess, 138.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 470: Read 3.9 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 131.8ms\n",
            "Speed: 6.1ms preprocess, 131.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 471: Read 3.5 ms | Inference 175.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 121.8ms\n",
            "Speed: 7.5ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 472: Read 3.8 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 125.3ms\n",
            "Speed: 6.6ms preprocess, 125.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 473: Read 3.6 ms | Inference 176.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 125.5ms\n",
            "Speed: 5.9ms preprocess, 125.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 474: Read 9.0 ms | Inference 170.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 backpack, 192.9ms\n",
            "Speed: 6.0ms preprocess, 192.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 475: Read 3.5 ms | Inference 269.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 186.7ms\n",
            "Speed: 10.1ms preprocess, 186.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 476: Read 12.8 ms | Inference 249.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 183.7ms\n",
            "Speed: 7.6ms preprocess, 183.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 477: Read 10.6 ms | Inference 244.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 9 cars, 192.8ms\n",
            "Speed: 9.6ms preprocess, 192.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 478: Read 10.2 ms | Inference 268.7 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 8 cars, 198.4ms\n",
            "Speed: 6.9ms preprocess, 198.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 479: Read 3.9 ms | Inference 262.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 1 backpack, 205.4ms\n",
            "Speed: 5.9ms preprocess, 205.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 480: Read 3.8 ms | Inference 255.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 traffic light, 200.9ms\n",
            "Speed: 10.3ms preprocess, 200.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 481: Read 10.6 ms | Inference 277.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 185.1ms\n",
            "Speed: 5.8ms preprocess, 185.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 482: Read 9.8 ms | Inference 243.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 traffic light, 182.0ms\n",
            "Speed: 5.8ms preprocess, 182.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 483: Read 9.7 ms | Inference 244.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 197.0ms\n",
            "Speed: 15.0ms preprocess, 197.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 484: Read 12.2 ms | Inference 260.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 187.6ms\n",
            "Speed: 5.9ms preprocess, 187.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 485: Read 10.5 ms | Inference 246.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 198.1ms\n",
            "Speed: 6.5ms preprocess, 198.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 486: Read 13.1 ms | Inference 253.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 198.1ms\n",
            "Speed: 12.6ms preprocess, 198.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 487: Read 3.7 ms | Inference 277.5 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 4 cars, 3 traffic lights, 1 backpack, 208.0ms\n",
            "Speed: 12.7ms preprocess, 208.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 488: Read 20.1 ms | Inference 271.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 2 traffic lights, 192.9ms\n",
            "Speed: 11.2ms preprocess, 192.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 489: Read 12.3 ms | Inference 255.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 3 traffic lights, 1 backpack, 155.9ms\n",
            "Speed: 10.5ms preprocess, 155.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 490: Read 3.5 ms | Inference 214.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 2 traffic lights, 1 backpack, 121.7ms\n",
            "Speed: 8.0ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 491: Read 4.2 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 139.4ms\n",
            "Speed: 6.5ms preprocess, 139.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 492: Read 3.6 ms | Inference 181.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 traffic light, 1 backpack, 123.2ms\n",
            "Speed: 6.0ms preprocess, 123.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 493: Read 3.7 ms | Inference 168.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 2 traffic lights, 1 potted plant, 125.3ms\n",
            "Speed: 7.3ms preprocess, 125.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 494: Read 3.7 ms | Inference 174.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 4 cars, 1 traffic light, 1 backpack, 1 potted plant, 139.9ms\n",
            "Speed: 5.9ms preprocess, 139.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 495: Read 3.6 ms | Inference 191.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 traffic light, 126.9ms\n",
            "Speed: 5.9ms preprocess, 126.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 496: Read 3.8 ms | Inference 169.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 1 potted plant, 126.5ms\n",
            "Speed: 6.0ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 497: Read 3.6 ms | Inference 175.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 2 traffic lights, 1 backpack, 1 potted plant, 141.1ms\n",
            "Speed: 6.0ms preprocess, 141.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 498: Read 3.7 ms | Inference 191.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 2 traffic lights, 1 backpack, 1 potted plant, 124.5ms\n",
            "Speed: 9.1ms preprocess, 124.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 499: Read 3.8 ms | Inference 173.1 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 traffic lights, 1 potted plant, 123.7ms\n",
            "Speed: 6.7ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 500: Read 3.6 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 124.4ms\n",
            "Speed: 6.6ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 501: Read 3.7 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 truck, 2 traffic lights, 1 backpack, 1 potted plant, 121.8ms\n",
            "Speed: 6.0ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 502: Read 3.6 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 2 traffic lights, 1 backpack, 1 potted plant, 127.0ms\n",
            "Speed: 6.8ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 503: Read 4.7 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 1 potted plant, 143.9ms\n",
            "Speed: 6.5ms preprocess, 143.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 504: Read 3.7 ms | Inference 189.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 2 traffic lights, 1 backpack, 1 potted plant, 128.5ms\n",
            "Speed: 7.3ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 505: Read 3.7 ms | Inference 178.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 122.8ms\n",
            "Speed: 7.2ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 506: Read 3.8 ms | Inference 165.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 1 potted plant, 125.8ms\n",
            "Speed: 7.1ms preprocess, 125.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 507: Read 3.7 ms | Inference 169.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 1 potted plant, 128.4ms\n",
            "Speed: 6.2ms preprocess, 128.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 508: Read 3.7 ms | Inference 171.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 1 potted plant, 120.3ms\n",
            "Speed: 6.1ms preprocess, 120.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 509: Read 3.6 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 140.7ms\n",
            "Speed: 5.7ms preprocess, 140.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 510: Read 3.6 ms | Inference 187.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 3 traffic lights, 1 backpack, 126.3ms\n",
            "Speed: 5.9ms preprocess, 126.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 511: Read 3.6 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 2 traffic lights, 1 backpack, 121.4ms\n",
            "Speed: 5.9ms preprocess, 121.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 512: Read 3.7 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 backpack, 124.7ms\n",
            "Speed: 6.0ms preprocess, 124.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 513: Read 3.8 ms | Inference 167.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 1 potted plant, 124.0ms\n",
            "Speed: 6.1ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 514: Read 3.6 ms | Inference 176.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 backpack, 121.3ms\n",
            "Speed: 6.1ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 515: Read 3.6 ms | Inference 175.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 backpack, 138.4ms\n",
            "Speed: 5.7ms preprocess, 138.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 516: Read 3.5 ms | Inference 178.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 backpack, 124.0ms\n",
            "Speed: 6.1ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 517: Read 3.7 ms | Inference 168.4 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 traffic light, 1 potted plant, 121.9ms\n",
            "Speed: 6.0ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 518: Read 3.6 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 1 potted plant, 121.2ms\n",
            "Speed: 6.0ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 519: Read 3.6 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 122.6ms\n",
            "Speed: 11.5ms preprocess, 122.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 520: Read 3.7 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 1 backpack, 123.7ms\n",
            "Speed: 6.1ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 521: Read 3.6 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 129.9ms\n",
            "Speed: 10.8ms preprocess, 129.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 522: Read 14.3 ms | Inference 179.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 1 potted plant, 124.1ms\n",
            "Speed: 7.6ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 523: Read 3.8 ms | Inference 170.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 121.7ms\n",
            "Speed: 5.9ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 524: Read 3.6 ms | Inference 169.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 125.6ms\n",
            "Speed: 13.5ms preprocess, 125.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 525: Read 3.8 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 124.7ms\n",
            "Speed: 9.4ms preprocess, 124.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 526: Read 3.8 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 128.7ms\n",
            "Speed: 7.7ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 527: Read 3.8 ms | Inference 194.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 1 car, 128.3ms\n",
            "Speed: 9.9ms preprocess, 128.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 528: Read 4.5 ms | Inference 170.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 traffic light, 123.0ms\n",
            "Speed: 13.5ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 529: Read 3.8 ms | Inference 173.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 130.5ms\n",
            "Speed: 5.8ms preprocess, 130.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 530: Read 3.8 ms | Inference 175.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 3 cars, 125.0ms\n",
            "Speed: 11.6ms preprocess, 125.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 531: Read 3.8 ms | Inference 172.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 3 cars, 1 traffic light, 126.0ms\n",
            "Speed: 6.1ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 532: Read 3.7 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 3 cars, 1 traffic light, 1 backpack, 139.3ms\n",
            "Speed: 13.2ms preprocess, 139.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 533: Read 3.6 ms | Inference 203.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 3 cars, 119.4ms\n",
            "Speed: 9.9ms preprocess, 119.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 534: Read 3.6 ms | Inference 166.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 2 cars, 121.8ms\n",
            "Speed: 6.1ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 535: Read 3.6 ms | Inference 169.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 bicycles, 2 cars, 1 backpack, 128.8ms\n",
            "Speed: 9.9ms preprocess, 128.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 536: Read 3.8 ms | Inference 176.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 1 car, 122.2ms\n",
            "Speed: 5.9ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 537: Read 3.6 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 car, 1 backpack, 124.7ms\n",
            "Speed: 6.3ms preprocess, 124.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 538: Read 3.5 ms | Inference 171.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 backpacks, 140.2ms\n",
            "Speed: 10.5ms preprocess, 140.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 539: Read 3.7 ms | Inference 189.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 121.7ms\n",
            "Speed: 6.2ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 540: Read 3.7 ms | Inference 163.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 2 cars, 1 traffic light, 1 backpack, 143.0ms\n",
            "Speed: 6.3ms preprocess, 143.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 541: Read 3.8 ms | Inference 188.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 1 car, 1 backpack, 129.7ms\n",
            "Speed: 8.4ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 542: Read 3.8 ms | Inference 175.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 5 bicycles, 1 car, 127.2ms\n",
            "Speed: 9.0ms preprocess, 127.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 543: Read 3.8 ms | Inference 175.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 1 car, 124.6ms\n",
            "Speed: 6.1ms preprocess, 124.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 544: Read 3.6 ms | Inference 176.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 2 cars, 139.9ms\n",
            "Speed: 10.0ms preprocess, 139.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 545: Read 3.7 ms | Inference 185.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 1 car, 1 traffic light, 192.6ms\n",
            "Speed: 5.4ms preprocess, 192.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 546: Read 3.5 ms | Inference 251.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 2 cars, 191.9ms\n",
            "Speed: 6.8ms preprocess, 191.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 547: Read 3.8 ms | Inference 245.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 cars, 188.3ms\n",
            "Speed: 12.2ms preprocess, 188.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 548: Read 13.4 ms | Inference 247.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 car, 211.7ms\n",
            "Speed: 5.8ms preprocess, 211.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 549: Read 3.6 ms | Inference 263.2 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 3 cars, 1 traffic light, 185.7ms\n",
            "Speed: 11.4ms preprocess, 185.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 550: Read 10.3 ms | Inference 251.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 2 cars, 204.2ms\n",
            "Speed: 7.4ms preprocess, 204.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 551: Read 4.1 ms | Inference 258.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 186.8ms\n",
            "Speed: 10.4ms preprocess, 186.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 552: Read 10.1 ms | Inference 244.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 2 traffic lights, 191.2ms\n",
            "Speed: 18.0ms preprocess, 191.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 553: Read 14.9 ms | Inference 269.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 1 traffic light, 188.2ms\n",
            "Speed: 15.5ms preprocess, 188.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 554: Read 9.8 ms | Inference 258.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 1 car, 187.4ms\n",
            "Speed: 5.9ms preprocess, 187.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 555: Read 3.6 ms | Inference 240.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 1 backpack, 184.6ms\n",
            "Speed: 6.5ms preprocess, 184.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 556: Read 3.6 ms | Inference 245.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 2 traffic lights, 200.1ms\n",
            "Speed: 6.0ms preprocess, 200.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 557: Read 3.6 ms | Inference 278.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 1 backpack, 200.8ms\n",
            "Speed: 8.6ms preprocess, 200.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 558: Read 3.6 ms | Inference 274.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 190.5ms\n",
            "Speed: 6.0ms preprocess, 190.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 559: Read 3.6 ms | Inference 256.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 197.9ms\n",
            "Speed: 5.8ms preprocess, 197.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 560: Read 15.1 ms | Inference 263.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 176.5ms\n",
            "Speed: 6.3ms preprocess, 176.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 561: Read 3.6 ms | Inference 231.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 131.5ms\n",
            "Speed: 7.8ms preprocess, 131.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 562: Read 19.1 ms | Inference 175.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 127.4ms\n",
            "Speed: 6.1ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 563: Read 3.8 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 127.7ms\n",
            "Speed: 6.1ms preprocess, 127.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 564: Read 3.6 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 127.5ms\n",
            "Speed: 5.9ms preprocess, 127.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 565: Read 3.6 ms | Inference 169.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 4 cars, 118.8ms\n",
            "Speed: 6.0ms preprocess, 118.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 566: Read 3.6 ms | Inference 166.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 traffic light, 121.6ms\n",
            "Speed: 6.0ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 567: Read 3.5 ms | Inference 190.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 traffic light, 133.5ms\n",
            "Speed: 6.0ms preprocess, 133.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 568: Read 3.8 ms | Inference 175.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 car, 1 traffic light, 1 backpack, 123.1ms\n",
            "Speed: 13.5ms preprocess, 123.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 569: Read 4.1 ms | Inference 177.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 2 cars, 1 traffic light, 128.9ms\n",
            "Speed: 8.0ms preprocess, 128.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 570: Read 3.6 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 car, 3 traffic lights, 127.9ms\n",
            "Speed: 6.0ms preprocess, 127.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 571: Read 3.8 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 1 car, 2 traffic lights, 1 backpack, 122.0ms\n",
            "Speed: 8.7ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 572: Read 3.7 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 car, 1 traffic light, 139.5ms\n",
            "Speed: 11.6ms preprocess, 139.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 573: Read 3.8 ms | Inference 188.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 121.9ms\n",
            "Speed: 6.2ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 574: Read 3.6 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 traffic lights, 137.1ms\n",
            "Speed: 6.8ms preprocess, 137.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 575: Read 3.9 ms | Inference 184.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 traffic lights, 130.5ms\n",
            "Speed: 6.0ms preprocess, 130.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 576: Read 3.6 ms | Inference 175.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 traffic light, 121.8ms\n",
            "Speed: 6.4ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 577: Read 3.7 ms | Inference 167.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 traffic light, 121.8ms\n",
            "Speed: 11.6ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 578: Read 3.7 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 traffic lights, 144.5ms\n",
            "Speed: 8.3ms preprocess, 144.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 579: Read 3.5 ms | Inference 192.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 backpack, 126.7ms\n",
            "Speed: 7.0ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 580: Read 3.8 ms | Inference 172.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 traffic light, 121.8ms\n",
            "Speed: 6.0ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 581: Read 3.6 ms | Inference 169.1 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 2 traffic lights, 1 backpack, 121.5ms\n",
            "Speed: 6.0ms preprocess, 121.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 582: Read 3.6 ms | Inference 171.7 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 2 traffic lights, 122.7ms\n",
            "Speed: 5.9ms preprocess, 122.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 583: Read 3.7 ms | Inference 165.1 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 1 backpack, 130.1ms\n",
            "Speed: 7.5ms preprocess, 130.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 584: Read 3.7 ms | Inference 173.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 143.8ms\n",
            "Speed: 7.2ms preprocess, 143.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 585: Read 3.7 ms | Inference 184.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 127.1ms\n",
            "Speed: 5.8ms preprocess, 127.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 586: Read 3.7 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 traffic light, 127.4ms\n",
            "Speed: 10.5ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 587: Read 3.7 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 132.2ms\n",
            "Speed: 9.9ms preprocess, 132.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 588: Read 3.6 ms | Inference 172.6 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 1 traffic light, 125.4ms\n",
            "Speed: 13.6ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 589: Read 3.7 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 126.1ms\n",
            "Speed: 13.0ms preprocess, 126.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 590: Read 3.7 ms | Inference 175.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 138.4ms\n",
            "Speed: 11.9ms preprocess, 138.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 591: Read 3.7 ms | Inference 185.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 125.5ms\n",
            "Speed: 15.0ms preprocess, 125.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 592: Read 3.7 ms | Inference 174.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 traffic lights, 122.3ms\n",
            "Speed: 5.8ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 593: Read 3.6 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 traffic lights, 119.3ms\n",
            "Speed: 11.5ms preprocess, 119.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 594: Read 3.5 ms | Inference 168.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 122.7ms\n",
            "Speed: 6.1ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 595: Read 3.5 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 traffic lights, 123.9ms\n",
            "Speed: 6.8ms preprocess, 123.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 596: Read 3.5 ms | Inference 177.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 traffic lights, 125.8ms\n",
            "Speed: 13.0ms preprocess, 125.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 597: Read 9.6 ms | Inference 182.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 traffic lights, 2 benchs, 125.6ms\n",
            "Speed: 6.8ms preprocess, 125.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 598: Read 3.9 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 traffic lights, 129.0ms\n",
            "Speed: 5.9ms preprocess, 129.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 599: Read 3.7 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 1 person, 3 traffic lights, 125.2ms\n",
            "Speed: 5.8ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 600: Read 3.8 ms | Inference 165.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 traffic lights, 124.2ms\n",
            "Speed: 7.3ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 601: Read 9.9 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 121.3ms\n",
            "Speed: 6.0ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 602: Read 3.6 ms | Inference 182.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 121.8ms\n",
            "Speed: 15.2ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 603: Read 3.6 ms | Inference 181.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 124.7ms\n",
            "Speed: 9.0ms preprocess, 124.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 604: Read 3.4 ms | Inference 170.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 122.4ms\n",
            "Speed: 10.0ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 605: Read 3.7 ms | Inference 170.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 122.4ms\n",
            "Speed: 6.0ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 606: Read 3.6 ms | Inference 169.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 3 traffic lights, 2 benchs, 125.9ms\n",
            "Speed: 9.6ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 607: Read 3.7 ms | Inference 175.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 122.4ms\n",
            "Speed: 5.7ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 608: Read 3.6 ms | Inference 183.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 2 traffic lights, 123.0ms\n",
            "Speed: 6.1ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 609: Read 3.6 ms | Inference 174.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 126.1ms\n",
            "Speed: 6.1ms preprocess, 126.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 610: Read 3.6 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 122.4ms\n",
            "Speed: 5.6ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 611: Read 3.7 ms | Inference 167.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 128.7ms\n",
            "Speed: 7.1ms preprocess, 128.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 612: Read 3.7 ms | Inference 166.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 130.5ms\n",
            "Speed: 12.3ms preprocess, 130.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 613: Read 3.7 ms | Inference 178.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 121.7ms\n",
            "Speed: 12.5ms preprocess, 121.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 614: Read 3.7 ms | Inference 186.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 122.9ms\n",
            "Speed: 10.2ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 615: Read 3.5 ms | Inference 169.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 128.6ms\n",
            "Speed: 7.3ms preprocess, 128.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 616: Read 3.8 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 162.6ms\n",
            "Speed: 9.3ms preprocess, 162.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 617: Read 3.7 ms | Inference 216.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 192.7ms\n",
            "Speed: 8.8ms preprocess, 192.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 618: Read 14.3 ms | Inference 253.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 206.2ms\n",
            "Speed: 9.7ms preprocess, 206.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 619: Read 9.7 ms | Inference 277.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 186.4ms\n",
            "Speed: 15.2ms preprocess, 186.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 620: Read 13.6 ms | Inference 245.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 196.8ms\n",
            "Speed: 8.3ms preprocess, 196.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 621: Read 10.3 ms | Inference 255.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 umbrella, 184.8ms\n",
            "Speed: 16.1ms preprocess, 184.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 622: Read 10.5 ms | Inference 258.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 198.1ms\n",
            "Speed: 5.8ms preprocess, 198.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 623: Read 3.7 ms | Inference 265.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 202.7ms\n",
            "Speed: 6.2ms preprocess, 202.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 624: Read 4.4 ms | Inference 247.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 187.0ms\n",
            "Speed: 6.5ms preprocess, 187.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 625: Read 16.6 ms | Inference 237.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 196.3ms\n",
            "Speed: 5.9ms preprocess, 196.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 626: Read 3.5 ms | Inference 243.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 195.7ms\n",
            "Speed: 5.6ms preprocess, 195.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 627: Read 3.6 ms | Inference 242.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 222.9ms\n",
            "Speed: 13.0ms preprocess, 222.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 628: Read 9.9 ms | Inference 290.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 191.7ms\n",
            "Speed: 13.0ms preprocess, 191.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 629: Read 3.7 ms | Inference 260.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 197.8ms\n",
            "Speed: 9.4ms preprocess, 197.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 630: Read 3.6 ms | Inference 255.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 208.4ms\n",
            "Speed: 5.9ms preprocess, 208.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 631: Read 3.8 ms | Inference 261.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 203.8ms\n",
            "Speed: 9.8ms preprocess, 203.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 632: Read 3.6 ms | Inference 265.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 157.7ms\n",
            "Speed: 12.9ms preprocess, 157.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 633: Read 3.6 ms | Inference 215.5 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 122.2ms\n",
            "Speed: 6.2ms preprocess, 122.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 634: Read 3.6 ms | Inference 168.0 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 122.5ms\n",
            "Speed: 5.9ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 635: Read 3.6 ms | Inference 173.7 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 1 car, 121.5ms\n",
            "Speed: 6.0ms preprocess, 121.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 636: Read 3.6 ms | Inference 167.5 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 122.2ms\n",
            "Speed: 6.7ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 637: Read 3.7 ms | Inference 169.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 141.6ms\n",
            "Speed: 5.7ms preprocess, 141.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 638: Read 3.6 ms | Inference 190.3 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 1 bench, 124.1ms\n",
            "Speed: 6.5ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 639: Read 3.7 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 130.2ms\n",
            "Speed: 6.1ms preprocess, 130.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 640: Read 3.6 ms | Inference 179.2 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 1 bench, 127.3ms\n",
            "Speed: 8.2ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 641: Read 3.7 ms | Inference 175.1 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 130.3ms\n",
            "Speed: 12.6ms preprocess, 130.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 642: Read 3.7 ms | Inference 179.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 124.0ms\n",
            "Speed: 9.8ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 643: Read 3.8 ms | Inference 186.4 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 127.8ms\n",
            "Speed: 5.9ms preprocess, 127.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 644: Read 3.6 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 123.1ms\n",
            "Speed: 5.8ms preprocess, 123.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 645: Read 3.6 ms | Inference 168.5 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 121.3ms\n",
            "Speed: 6.2ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 646: Read 3.6 ms | Inference 171.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 128.5ms\n",
            "Speed: 10.1ms preprocess, 128.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 647: Read 3.6 ms | Inference 180.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 147.5ms\n",
            "Speed: 7.6ms preprocess, 147.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 648: Read 3.6 ms | Inference 194.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 150.8ms\n",
            "Speed: 6.4ms preprocess, 150.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 649: Read 4.4 ms | Inference 193.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.1ms\n",
            "Speed: 4.8ms preprocess, 121.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 650: Read 4.4 ms | Inference 163.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 124.9ms\n",
            "Speed: 9.4ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 651: Read 9.9 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 bicycles, 1 car, 122.3ms\n",
            "Speed: 6.0ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 652: Read 3.6 ms | Inference 176.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 131.0ms\n",
            "Speed: 7.3ms preprocess, 131.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 653: Read 3.8 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 122.0ms\n",
            "Speed: 7.5ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 654: Read 3.5 ms | Inference 170.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 141.5ms\n",
            "Speed: 11.4ms preprocess, 141.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 655: Read 3.6 ms | Inference 195.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 bicycles, 131.0ms\n",
            "Speed: 7.9ms preprocess, 131.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 656: Read 4.5 ms | Inference 176.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 bicycles, 127.3ms\n",
            "Speed: 7.4ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 657: Read 3.8 ms | Inference 174.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 120.2ms\n",
            "Speed: 13.8ms preprocess, 120.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 658: Read 3.6 ms | Inference 172.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 127.4ms\n",
            "Speed: 11.4ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 659: Read 3.8 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 135.0ms\n",
            "Speed: 6.3ms preprocess, 135.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 660: Read 3.8 ms | Inference 174.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 bench, 159.5ms\n",
            "Speed: 5.9ms preprocess, 159.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 661: Read 3.5 ms | Inference 209.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 bench, 127.3ms\n",
            "Speed: 18.9ms preprocess, 127.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 662: Read 3.8 ms | Inference 186.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 car, 1 bench, 125.0ms\n",
            "Speed: 6.9ms preprocess, 125.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 663: Read 3.6 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 1 person, 7 bicycles, 1 bench, 121.3ms\n",
            "Speed: 6.0ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 664: Read 3.6 ms | Inference 174.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 bicycles, 1 bench, 120.7ms\n",
            "Speed: 6.1ms preprocess, 120.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 665: Read 3.6 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 1 car, 135.7ms\n",
            "Speed: 7.3ms preprocess, 135.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 666: Read 3.8 ms | Inference 186.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 8 bicycles, 1 car, 1 bench, 129.8ms\n",
            "Speed: 8.1ms preprocess, 129.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 667: Read 3.8 ms | Inference 183.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 bicycles, 121.9ms\n",
            "Speed: 6.1ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 668: Read 3.8 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 5 bicycles, 1 backpack, 128.1ms\n",
            "Speed: 6.5ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 669: Read 3.7 ms | Inference 174.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 5 bicycles, 1 car, 1 backpack, 126.4ms\n",
            "Speed: 6.5ms preprocess, 126.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 670: Read 3.6 ms | Inference 176.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 130.9ms\n",
            "Speed: 6.1ms preprocess, 130.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 671: Read 3.9 ms | Inference 182.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 143.4ms\n",
            "Speed: 6.0ms preprocess, 143.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 672: Read 3.6 ms | Inference 183.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 5 bicycles, 1 bench, 124.1ms\n",
            "Speed: 6.0ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 673: Read 3.6 ms | Inference 176.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 8 bicycles, 123.1ms\n",
            "Speed: 4.0ms preprocess, 123.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 674: Read 3.5 ms | Inference 168.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 8 bicycles, 127.3ms\n",
            "Speed: 12.2ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 675: Read 3.8 ms | Inference 182.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 1 car, 125.5ms\n",
            "Speed: 12.0ms preprocess, 125.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 676: Read 4.0 ms | Inference 175.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 8 bicycles, 125.2ms\n",
            "Speed: 10.7ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 677: Read 3.9 ms | Inference 180.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 145.2ms\n",
            "Speed: 5.8ms preprocess, 145.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 678: Read 3.8 ms | Inference 192.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 8 bicycles, 129.2ms\n",
            "Speed: 6.4ms preprocess, 129.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 679: Read 3.8 ms | Inference 176.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 5 bicycles, 121.7ms\n",
            "Speed: 12.8ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 680: Read 3.8 ms | Inference 172.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 7 bicycles, 1 motorcycle, 117.4ms\n",
            "Speed: 4.3ms preprocess, 117.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 681: Read 7.7 ms | Inference 162.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 bicycles, 1 motorcycle, 126.9ms\n",
            "Speed: 11.2ms preprocess, 126.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 682: Read 3.8 ms | Inference 178.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 6 bicycles, 126.7ms\n",
            "Speed: 6.1ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 683: Read 3.8 ms | Inference 181.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 bicycles, 128.3ms\n",
            "Speed: 11.1ms preprocess, 128.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 684: Read 10.0 ms | Inference 181.5 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 132.9ms\n",
            "Speed: 6.0ms preprocess, 132.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 685: Read 3.6 ms | Inference 179.1 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 131.1ms\n",
            "Speed: 6.5ms preprocess, 131.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 686: Read 3.7 ms | Inference 174.2 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 127.6ms\n",
            "Speed: 6.2ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 687: Read 3.8 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 traffic light, 166.7ms\n",
            "Speed: 6.1ms preprocess, 166.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 688: Read 3.6 ms | Inference 228.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 212.0ms\n",
            "Speed: 4.1ms preprocess, 212.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 689: Read 3.7 ms | Inference 265.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 183.9ms\n",
            "Speed: 8.2ms preprocess, 183.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 690: Read 3.6 ms | Inference 247.4 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 198.2ms\n",
            "Speed: 5.7ms preprocess, 198.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 691: Read 3.6 ms | Inference 250.4 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 194.5ms\n",
            "Speed: 17.7ms preprocess, 194.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 692: Read 3.7 ms | Inference 257.1 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 206.8ms\n",
            "Speed: 5.7ms preprocess, 206.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 693: Read 17.1 ms | Inference 261.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 traffic light, 186.0ms\n",
            "Speed: 5.5ms preprocess, 186.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 694: Read 13.2 ms | Inference 238.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 203.0ms\n",
            "Speed: 5.9ms preprocess, 203.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 695: Read 10.4 ms | Inference 267.9 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 1 car, 195.6ms\n",
            "Speed: 5.9ms preprocess, 195.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 696: Read 9.7 ms | Inference 260.4 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 192.7ms\n",
            "Speed: 5.9ms preprocess, 192.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 697: Read 10.2 ms | Inference 267.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 bicycles, 185.0ms\n",
            "Speed: 10.8ms preprocess, 185.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 698: Read 12.4 ms | Inference 254.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 187.8ms\n",
            "Speed: 11.3ms preprocess, 187.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 699: Read 14.5 ms | Inference 256.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 194.3ms\n",
            "Speed: 7.7ms preprocess, 194.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 700: Read 3.7 ms | Inference 252.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 186.5ms\n",
            "Speed: 12.0ms preprocess, 186.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 701: Read 3.6 ms | Inference 263.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 215.6ms\n",
            "Speed: 8.8ms preprocess, 215.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 702: Read 5.7 ms | Inference 280.7 ms\n",
            "\n",
            "0: 384x640 2 bicycles, 191.7ms\n",
            "Speed: 7.8ms preprocess, 191.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 703: Read 3.6 ms | Inference 242.7 ms\n",
            "\n",
            "0: 384x640 2 bicycles, 1 traffic light, 121.3ms\n",
            "Speed: 5.9ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 704: Read 3.6 ms | Inference 166.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 1 traffic light, 122.9ms\n",
            "Speed: 6.0ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 705: Read 3.7 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 traffic light, 122.3ms\n",
            "Speed: 6.0ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 706: Read 3.7 ms | Inference 167.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 141.6ms\n",
            "Speed: 10.1ms preprocess, 141.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 707: Read 3.7 ms | Inference 191.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 122.9ms\n",
            "Speed: 6.0ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 708: Read 3.5 ms | Inference 164.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 traffic light, 123.0ms\n",
            "Speed: 6.7ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 709: Read 3.7 ms | Inference 165.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 127.3ms\n",
            "Speed: 6.8ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 710: Read 4.7 ms | Inference 168.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 125.1ms\n",
            "Speed: 6.0ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 711: Read 3.6 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 122.0ms\n",
            "Speed: 6.6ms preprocess, 122.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 712: Read 3.8 ms | Inference 166.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 137.4ms\n",
            "Speed: 9.7ms preprocess, 137.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 713: Read 3.5 ms | Inference 190.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 123.3ms\n",
            "Speed: 9.5ms preprocess, 123.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 714: Read 3.6 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 121.9ms\n",
            "Speed: 6.0ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 715: Read 3.5 ms | Inference 171.0 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 1 traffic light, 121.9ms\n",
            "Speed: 6.0ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 716: Read 3.7 ms | Inference 173.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 car, 125.0ms\n",
            "Speed: 6.0ms preprocess, 125.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 717: Read 3.5 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 traffic light, 122.2ms\n",
            "Speed: 6.1ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 718: Read 3.8 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 139.6ms\n",
            "Speed: 15.9ms preprocess, 139.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 719: Read 3.7 ms | Inference 198.7 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 129.1ms\n",
            "Speed: 6.2ms preprocess, 129.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 720: Read 3.7 ms | Inference 175.4 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 124.0ms\n",
            "Speed: 6.4ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 721: Read 3.6 ms | Inference 178.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 122.7ms\n",
            "Speed: 6.0ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 722: Read 3.6 ms | Inference 177.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 119.6ms\n",
            "Speed: 6.0ms preprocess, 119.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 723: Read 3.6 ms | Inference 167.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 120.2ms\n",
            "Speed: 4.3ms preprocess, 120.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 724: Read 3.6 ms | Inference 178.7 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 1 backpack, 124.3ms\n",
            "Speed: 7.5ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 725: Read 3.8 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 121.0ms\n",
            "Speed: 7.0ms preprocess, 121.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 726: Read 3.6 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 127.7ms\n",
            "Speed: 7.2ms preprocess, 127.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 727: Read 3.7 ms | Inference 177.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 1 car, 126.5ms\n",
            "Speed: 6.4ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 728: Read 3.8 ms | Inference 170.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 119.6ms\n",
            "Speed: 5.9ms preprocess, 119.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 729: Read 3.5 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 133.8ms\n",
            "Speed: 12.2ms preprocess, 133.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 730: Read 3.7 ms | Inference 194.2 ms\n",
            "\n",
            "0: 384x640 7 persons, 2 bicycles, 128.4ms\n",
            "Speed: 6.5ms preprocess, 128.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 731: Read 4.6 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 6 persons, 2 bicycles, 131.2ms\n",
            "Speed: 7.2ms preprocess, 131.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 732: Read 3.8 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 128.5ms\n",
            "Speed: 7.5ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 733: Read 3.9 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 bus, 123.8ms\n",
            "Speed: 5.6ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 734: Read 3.5 ms | Inference 172.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 126.0ms\n",
            "Speed: 6.0ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 735: Read 3.7 ms | Inference 172.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 139.6ms\n",
            "Speed: 6.7ms preprocess, 139.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 736: Read 3.6 ms | Inference 188.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 1 car, 1 motorcycle, 126.1ms\n",
            "Speed: 6.7ms preprocess, 126.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 737: Read 3.7 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 121.1ms\n",
            "Speed: 5.8ms preprocess, 121.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 738: Read 3.5 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 car, 127.3ms\n",
            "Speed: 6.5ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 739: Read 3.8 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 124.4ms\n",
            "Speed: 5.7ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 740: Read 3.6 ms | Inference 176.4 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 1 motorcycle, 125.4ms\n",
            "Speed: 9.8ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 741: Read 3.8 ms | Inference 178.8 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 1 motorcycle, 137.5ms\n",
            "Speed: 10.6ms preprocess, 137.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 742: Read 3.5 ms | Inference 189.4 ms\n",
            "\n",
            "0: 384x640 5 persons, 4 bicycles, 133.7ms\n",
            "Speed: 5.9ms preprocess, 133.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 743: Read 3.8 ms | Inference 181.4 ms\n",
            "\n",
            "0: 384x640 5 persons, 3 bicycles, 1 motorcycle, 121.2ms\n",
            "Speed: 6.3ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 744: Read 3.6 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 119.6ms\n",
            "Speed: 6.1ms preprocess, 119.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 745: Read 3.6 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 motorcycle, 126.7ms\n",
            "Speed: 5.7ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 746: Read 3.5 ms | Inference 176.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 4 bicycles, 128.3ms\n",
            "Speed: 6.1ms preprocess, 128.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 747: Read 3.8 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 car, 1 backpack, 129.8ms\n",
            "Speed: 16.4ms preprocess, 129.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 748: Read 10.1 ms | Inference 186.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 122.9ms\n",
            "Speed: 6.1ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 749: Read 3.5 ms | Inference 172.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 126.5ms\n",
            "Speed: 6.1ms preprocess, 126.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 750: Read 3.8 ms | Inference 172.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 1 traffic light, 125.6ms\n",
            "Speed: 6.1ms preprocess, 125.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 751: Read 3.6 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 1 backpack, 125.9ms\n",
            "Speed: 6.1ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 752: Read 3.8 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 1 traffic light, 121.7ms\n",
            "Speed: 12.0ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 753: Read 4.2 ms | Inference 183.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 129.8ms\n",
            "Speed: 6.0ms preprocess, 129.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 754: Read 3.9 ms | Inference 172.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 125.3ms\n",
            "Speed: 7.6ms preprocess, 125.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 755: Read 3.7 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 127.4ms\n",
            "Speed: 5.6ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 756: Read 3.9 ms | Inference 167.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 123.7ms\n",
            "Speed: 9.2ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 757: Read 3.8 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 127.4ms\n",
            "Speed: 9.2ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 758: Read 3.5 ms | Inference 175.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 127.2ms\n",
            "Speed: 12.9ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 759: Read 3.8 ms | Inference 199.4 ms\n",
            "\n",
            "0: 384x640 5 persons, 3 bicycles, 1 backpack, 190.6ms\n",
            "Speed: 17.1ms preprocess, 190.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 760: Read 16.2 ms | Inference 264.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 188.3ms\n",
            "Speed: 6.0ms preprocess, 188.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 761: Read 3.6 ms | Inference 253.8 ms\n",
            "\n",
            "0: 384x640 6 persons, 2 bicycles, 198.3ms\n",
            "Speed: 6.0ms preprocess, 198.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 762: Read 3.6 ms | Inference 261.2 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 1 backpack, 196.2ms\n",
            "Speed: 5.8ms preprocess, 196.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 763: Read 3.7 ms | Inference 251.7 ms\n",
            "\n",
            "0: 384x640 5 persons, 3 bicycles, 196.7ms\n",
            "Speed: 12.3ms preprocess, 196.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 764: Read 10.0 ms | Inference 264.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 180.8ms\n",
            "Speed: 12.9ms preprocess, 180.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 765: Read 10.3 ms | Inference 245.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 backpack, 188.1ms\n",
            "Speed: 12.8ms preprocess, 188.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 766: Read 10.1 ms | Inference 257.4 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 198.7ms\n",
            "Speed: 5.9ms preprocess, 198.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 767: Read 3.7 ms | Inference 268.5 ms\n",
            "\n",
            "0: 384x640 6 persons, 3 bicycles, 1 backpack, 208.7ms\n",
            "Speed: 15.2ms preprocess, 208.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 768: Read 17.0 ms | Inference 269.7 ms\n",
            "\n",
            "0: 384x640 6 persons, 5 bicycles, 1 backpack, 181.6ms\n",
            "Speed: 5.7ms preprocess, 181.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 769: Read 10.1 ms | Inference 255.3 ms\n",
            "\n",
            "0: 384x640 5 persons, 3 bicycles, 1 backpack, 184.7ms\n",
            "Speed: 5.9ms preprocess, 184.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 770: Read 10.6 ms | Inference 251.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 5 bicycles, 1 backpack, 195.7ms\n",
            "Speed: 5.9ms preprocess, 195.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 771: Read 3.6 ms | Inference 265.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 211.5ms\n",
            "Speed: 6.0ms preprocess, 211.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 772: Read 3.6 ms | Inference 278.1 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 backpack, 196.5ms\n",
            "Speed: 5.8ms preprocess, 196.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 773: Read 3.6 ms | Inference 265.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 4 bicycles, 1 backpack, 197.0ms\n",
            "Speed: 17.3ms preprocess, 197.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 774: Read 3.6 ms | Inference 281.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 1 traffic light, 1 backpack, 157.3ms\n",
            "Speed: 6.0ms preprocess, 157.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 775: Read 3.5 ms | Inference 202.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 car, 1 backpack, 128.6ms\n",
            "Speed: 5.7ms preprocess, 128.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 776: Read 3.7 ms | Inference 190.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 1 backpack, 128.5ms\n",
            "Speed: 6.6ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 777: Read 3.8 ms | Inference 178.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 car, 1 traffic light, 133.4ms\n",
            "Speed: 5.8ms preprocess, 133.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 778: Read 3.6 ms | Inference 177.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 1 traffic light, 118.9ms\n",
            "Speed: 4.4ms preprocess, 118.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 779: Read 3.6 ms | Inference 164.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 car, 1 traffic light, 1 backpack, 126.0ms\n",
            "Speed: 5.9ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 780: Read 3.6 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 5 bicycles, 2 cars, 1 traffic light, 121.5ms\n",
            "Speed: 6.0ms preprocess, 121.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 781: Read 3.6 ms | Inference 174.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 2 cars, 1 traffic light, 135.8ms\n",
            "Speed: 5.6ms preprocess, 135.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 782: Read 3.5 ms | Inference 187.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 4 bicycles, 2 cars, 1 traffic light, 128.5ms\n",
            "Speed: 5.8ms preprocess, 128.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 783: Read 3.5 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 4 bicycles, 2 cars, 1 traffic light, 1 umbrella, 126.5ms\n",
            "Speed: 7.6ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 784: Read 3.6 ms | Inference 182.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 4 bicycles, 1 car, 1 traffic light, 122.7ms\n",
            "Speed: 5.7ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 785: Read 3.5 ms | Inference 176.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 traffic light, 126.0ms\n",
            "Speed: 6.2ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 786: Read 3.8 ms | Inference 173.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 1 car, 1 traffic light, 128.6ms\n",
            "Speed: 6.1ms preprocess, 128.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 787: Read 3.8 ms | Inference 173.8 ms\n",
            "\n",
            "0: 384x640 6 persons, 3 bicycles, 1 car, 1 traffic light, 146.6ms\n",
            "Speed: 6.0ms preprocess, 146.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 788: Read 3.8 ms | Inference 196.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 2 cars, 1 traffic light, 132.5ms\n",
            "Speed: 7.3ms preprocess, 132.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 789: Read 10.4 ms | Inference 180.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 3 cars, 1 traffic light, 128.1ms\n",
            "Speed: 7.0ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 790: Read 3.8 ms | Inference 177.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 4 cars, 1 traffic light, 128.7ms\n",
            "Speed: 11.3ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 791: Read 3.9 ms | Inference 181.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 2 cars, 1 traffic light, 125.8ms\n",
            "Speed: 6.6ms preprocess, 125.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 792: Read 3.6 ms | Inference 170.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 traffic light, 123.6ms\n",
            "Speed: 5.8ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 793: Read 3.7 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 6 persons, 2 bicycles, 5 cars, 1 traffic light, 137.8ms\n",
            "Speed: 9.8ms preprocess, 137.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 794: Read 3.7 ms | Inference 191.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 2 cars, 1 traffic light, 124.0ms\n",
            "Speed: 7.3ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 795: Read 3.6 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 traffic light, 123.6ms\n",
            "Speed: 6.0ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 796: Read 3.5 ms | Inference 176.2 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 cars, 1 traffic light, 117.3ms\n",
            "Speed: 14.9ms preprocess, 117.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 797: Read 3.8 ms | Inference 173.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 1 traffic light, 121.4ms\n",
            "Speed: 11.8ms preprocess, 121.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 798: Read 3.7 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 cars, 1 traffic light, 147.2ms\n",
            "Speed: 8.0ms preprocess, 147.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 799: Read 3.7 ms | Inference 210.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 126.2ms\n",
            "Speed: 12.5ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 800: Read 3.8 ms | Inference 176.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 3 cars, 2 traffic lights, 119.1ms\n",
            "Speed: 4.2ms preprocess, 119.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 801: Read 3.6 ms | Inference 164.5 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 1 traffic light, 120.2ms\n",
            "Speed: 6.4ms preprocess, 120.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 802: Read 3.8 ms | Inference 164.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 2 traffic lights, 118.9ms\n",
            "Speed: 5.5ms preprocess, 118.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 803: Read 3.8 ms | Inference 165.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 2 traffic lights, 1 backpack, 122.4ms\n",
            "Speed: 5.7ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 804: Read 3.7 ms | Inference 164.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 traffic light, 1 backpack, 125.7ms\n",
            "Speed: 5.9ms preprocess, 125.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 805: Read 3.6 ms | Inference 184.7 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 2 cars, 1 traffic light, 131.2ms\n",
            "Speed: 6.5ms preprocess, 131.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 806: Read 9.6 ms | Inference 179.1 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 2 traffic lights, 1 backpack, 126.7ms\n",
            "Speed: 6.3ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 807: Read 3.6 ms | Inference 175.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 124.3ms\n",
            "Speed: 6.8ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 808: Read 3.8 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 1 traffic light, 2 backpacks, 122.1ms\n",
            "Speed: 6.1ms preprocess, 122.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 809: Read 3.5 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 1 traffic light, 1 backpack, 122.7ms\n",
            "Speed: 6.1ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 810: Read 3.6 ms | Inference 170.7 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 4 cars, 1 traffic light, 148.3ms\n",
            "Speed: 7.2ms preprocess, 148.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 811: Read 3.7 ms | Inference 196.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 4 cars, 1 traffic light, 119.4ms\n",
            "Speed: 10.2ms preprocess, 119.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 812: Read 13.5 ms | Inference 170.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 1 traffic light, 123.7ms\n",
            "Speed: 5.8ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 813: Read 3.6 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 118.9ms\n",
            "Speed: 12.3ms preprocess, 118.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 814: Read 3.7 ms | Inference 169.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 132.1ms\n",
            "Speed: 6.0ms preprocess, 132.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 815: Read 3.8 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 130.9ms\n",
            "Speed: 7.2ms preprocess, 130.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 816: Read 3.8 ms | Inference 173.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 4 cars, 1 bus, 1 traffic light, 1 backpack, 142.2ms\n",
            "Speed: 5.9ms preprocess, 142.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 817: Read 3.6 ms | Inference 194.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 traffic light, 1 backpack, 122.3ms\n",
            "Speed: 12.8ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 818: Read 4.5 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 1 traffic light, 121.2ms\n",
            "Speed: 13.1ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 819: Read 3.7 ms | Inference 172.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 4 cars, 3 traffic lights, 126.7ms\n",
            "Speed: 6.2ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 820: Read 3.7 ms | Inference 172.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 3 traffic lights, 119.5ms\n",
            "Speed: 5.9ms preprocess, 119.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 821: Read 3.5 ms | Inference 171.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 1 traffic light, 123.4ms\n",
            "Speed: 6.0ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 822: Read 3.7 ms | Inference 168.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 141.7ms\n",
            "Speed: 7.8ms preprocess, 141.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 823: Read 3.8 ms | Inference 187.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 traffic light, 122.6ms\n",
            "Speed: 5.6ms preprocess, 122.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 824: Read 3.6 ms | Inference 169.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 4 cars, 2 traffic lights, 1 backpack, 128.2ms\n",
            "Speed: 9.0ms preprocess, 128.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 825: Read 3.8 ms | Inference 181.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 3 traffic lights, 1 backpack, 125.7ms\n",
            "Speed: 6.2ms preprocess, 125.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 826: Read 4.0 ms | Inference 173.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 3 traffic lights, 1 backpack, 129.6ms\n",
            "Speed: 5.7ms preprocess, 129.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 827: Read 3.7 ms | Inference 173.0 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 2 traffic lights, 126.7ms\n",
            "Speed: 6.4ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 828: Read 3.5 ms | Inference 183.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 136.6ms\n",
            "Speed: 5.9ms preprocess, 136.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 829: Read 3.7 ms | Inference 190.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 3 traffic lights, 1 backpack, 149.2ms\n",
            "Speed: 7.5ms preprocess, 149.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 830: Read 3.8 ms | Inference 211.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 198.6ms\n",
            "Speed: 5.9ms preprocess, 198.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 831: Read 3.6 ms | Inference 265.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 2 traffic lights, 1 backpack, 190.8ms\n",
            "Speed: 9.0ms preprocess, 190.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 832: Read 12.4 ms | Inference 258.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 209.0ms\n",
            "Speed: 7.2ms preprocess, 209.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 833: Read 3.6 ms | Inference 277.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 186.6ms\n",
            "Speed: 7.6ms preprocess, 186.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 834: Read 3.6 ms | Inference 240.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 2 traffic lights, 1 backpack, 192.2ms\n",
            "Speed: 5.9ms preprocess, 192.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 835: Read 3.6 ms | Inference 252.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 185.0ms\n",
            "Speed: 8.6ms preprocess, 185.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 836: Read 9.8 ms | Inference 249.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 191.7ms\n",
            "Speed: 11.3ms preprocess, 191.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 837: Read 13.9 ms | Inference 264.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 186.7ms\n",
            "Speed: 8.2ms preprocess, 186.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 838: Read 14.2 ms | Inference 255.1 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 traffic light, 191.1ms\n",
            "Speed: 10.0ms preprocess, 191.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 839: Read 10.4 ms | Inference 251.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 192.9ms\n",
            "Speed: 6.1ms preprocess, 192.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 840: Read 3.6 ms | Inference 246.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 185.8ms\n",
            "Speed: 8.9ms preprocess, 185.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 841: Read 10.0 ms | Inference 267.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 194.6ms\n",
            "Speed: 6.1ms preprocess, 194.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 842: Read 8.0 ms | Inference 255.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 196.7ms\n",
            "Speed: 6.1ms preprocess, 196.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 843: Read 3.5 ms | Inference 264.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 2 traffic lights, 202.3ms\n",
            "Speed: 9.6ms preprocess, 202.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 844: Read 11.0 ms | Inference 268.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 208.6ms\n",
            "Speed: 6.1ms preprocess, 208.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 845: Read 4.3 ms | Inference 280.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 128.7ms\n",
            "Speed: 5.9ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 846: Read 14.6 ms | Inference 175.7 ms\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 2 traffic lights, 121.1ms\n",
            "Speed: 8.0ms preprocess, 121.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 847: Read 3.6 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 2 traffic lights, 132.6ms\n",
            "Speed: 5.8ms preprocess, 132.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 848: Read 3.7 ms | Inference 183.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 122.9ms\n",
            "Speed: 6.3ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 849: Read 3.6 ms | Inference 174.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 3 traffic lights, 1 backpack, 123.4ms\n",
            "Speed: 6.5ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 850: Read 3.6 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 1 bicycle, 3 cars, 3 traffic lights, 1 backpack, 144.7ms\n",
            "Speed: 7.0ms preprocess, 144.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 851: Read 3.8 ms | Inference 192.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 3 traffic lights, 1 backpack, 135.9ms\n",
            "Speed: 6.1ms preprocess, 135.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 852: Read 4.0 ms | Inference 180.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 130.3ms\n",
            "Speed: 6.2ms preprocess, 130.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 853: Read 3.9 ms | Inference 182.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 127.2ms\n",
            "Speed: 6.1ms preprocess, 127.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 854: Read 3.6 ms | Inference 181.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 128.0ms\n",
            "Speed: 6.9ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 855: Read 4.0 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 127.6ms\n",
            "Speed: 5.8ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 856: Read 3.8 ms | Inference 171.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 traffic light, 143.3ms\n",
            "Speed: 6.1ms preprocess, 143.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 857: Read 3.8 ms | Inference 187.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 traffic light, 121.8ms\n",
            "Speed: 11.8ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 858: Read 3.8 ms | Inference 175.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 125.2ms\n",
            "Speed: 6.1ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 859: Read 3.6 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 2 traffic lights, 1 backpack, 131.4ms\n",
            "Speed: 6.0ms preprocess, 131.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 860: Read 3.7 ms | Inference 179.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 128.7ms\n",
            "Speed: 5.7ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 861: Read 3.7 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 123.6ms\n",
            "Speed: 6.0ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 862: Read 3.8 ms | Inference 166.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 135.3ms\n",
            "Speed: 12.6ms preprocess, 135.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 863: Read 13.7 ms | Inference 189.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 traffic light, 1 backpack, 129.7ms\n",
            "Speed: 7.3ms preprocess, 129.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 864: Read 3.7 ms | Inference 176.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 123.8ms\n",
            "Speed: 12.9ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 865: Read 3.7 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 123.4ms\n",
            "Speed: 7.4ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 866: Read 3.7 ms | Inference 176.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 129.2ms\n",
            "Speed: 7.3ms preprocess, 129.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 867: Read 3.8 ms | Inference 177.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 131.2ms\n",
            "Speed: 6.1ms preprocess, 131.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 868: Read 3.8 ms | Inference 181.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 122.5ms\n",
            "Speed: 8.5ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 869: Read 3.5 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 5 cars, 2 traffic lights, 126.2ms\n",
            "Speed: 6.0ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 870: Read 3.5 ms | Inference 181.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 1 backpack, 129.0ms\n",
            "Speed: 5.8ms preprocess, 129.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 871: Read 3.8 ms | Inference 173.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 traffic light, 1 backpack, 127.2ms\n",
            "Speed: 6.5ms preprocess, 127.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 872: Read 3.8 ms | Inference 178.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 123.9ms\n",
            "Speed: 9.2ms preprocess, 123.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 873: Read 3.8 ms | Inference 168.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 143.1ms\n",
            "Speed: 6.5ms preprocess, 143.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 874: Read 3.8 ms | Inference 186.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 traffic light, 122.9ms\n",
            "Speed: 9.3ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 875: Read 3.7 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 124.6ms\n",
            "Speed: 5.8ms preprocess, 124.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 876: Read 3.6 ms | Inference 172.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 traffic light, 125.9ms\n",
            "Speed: 7.2ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 877: Read 3.8 ms | Inference 173.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 1 traffic light, 124.4ms\n",
            "Speed: 5.9ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 878: Read 3.6 ms | Inference 166.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 123.3ms\n",
            "Speed: 6.1ms preprocess, 123.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 879: Read 3.6 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 144.1ms\n",
            "Speed: 5.7ms preprocess, 144.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 880: Read 3.7 ms | Inference 186.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 traffic light, 125.5ms\n",
            "Speed: 6.1ms preprocess, 125.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 881: Read 3.6 ms | Inference 176.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 traffic light, 128.6ms\n",
            "Speed: 5.9ms preprocess, 128.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 882: Read 3.6 ms | Inference 173.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 1 backpack, 126.0ms\n",
            "Speed: 8.3ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 883: Read 3.8 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 backpack, 124.8ms\n",
            "Speed: 5.8ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 884: Read 3.5 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 1 backpack, 126.8ms\n",
            "Speed: 6.6ms preprocess, 126.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 885: Read 3.5 ms | Inference 174.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 traffic light, 1 backpack, 142.6ms\n",
            "Speed: 7.2ms preprocess, 142.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 886: Read 3.8 ms | Inference 186.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 traffic light, 1 backpack, 138.7ms\n",
            "Speed: 6.0ms preprocess, 138.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 887: Read 10.8 ms | Inference 183.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 1 backpack, 125.0ms\n",
            "Speed: 8.5ms preprocess, 125.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 888: Read 3.8 ms | Inference 173.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 2 traffic lights, 1 backpack, 121.5ms\n",
            "Speed: 6.2ms preprocess, 121.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 889: Read 3.6 ms | Inference 174.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 2 traffic lights, 1 backpack, 132.1ms\n",
            "Speed: 5.8ms preprocess, 132.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 890: Read 3.6 ms | Inference 178.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 5 cars, 2 traffic lights, 1 backpack, 117.7ms\n",
            "Speed: 7.3ms preprocess, 117.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 891: Read 3.7 ms | Inference 163.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 3 traffic lights, 1 backpack, 145.8ms\n",
            "Speed: 4.2ms preprocess, 145.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 892: Read 5.0 ms | Inference 188.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 2 traffic lights, 1 backpack, 119.9ms\n",
            "Speed: 4.2ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 893: Read 3.6 ms | Inference 171.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 2 traffic lights, 1 backpack, 123.0ms\n",
            "Speed: 7.6ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 894: Read 3.8 ms | Inference 169.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 2 traffic lights, 1 backpack, 121.0ms\n",
            "Speed: 4.9ms preprocess, 121.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 895: Read 3.8 ms | Inference 168.1 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 traffic lights, 131.3ms\n",
            "Speed: 5.8ms preprocess, 131.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 896: Read 3.6 ms | Inference 181.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 2 traffic lights, 1 backpack, 127.0ms\n",
            "Speed: 6.1ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 897: Read 3.8 ms | Inference 178.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 traffic light, 131.9ms\n",
            "Speed: 5.7ms preprocess, 131.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 898: Read 11.5 ms | Inference 183.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 traffic lights, 128.5ms\n",
            "Speed: 6.0ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 899: Read 3.7 ms | Inference 173.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 126.2ms\n",
            "Speed: 8.6ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 900: Read 3.7 ms | Inference 170.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 149.7ms\n",
            "Speed: 5.9ms preprocess, 149.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 901: Read 3.5 ms | Inference 205.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 187.8ms\n",
            "Speed: 6.3ms preprocess, 187.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 902: Read 7.6 ms | Inference 230.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 196.5ms\n",
            "Speed: 5.4ms preprocess, 196.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 903: Read 8.8 ms | Inference 245.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 185.9ms\n",
            "Speed: 10.4ms preprocess, 185.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 904: Read 5.5 ms | Inference 232.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 185.1ms\n",
            "Speed: 6.4ms preprocess, 185.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 905: Read 9.7 ms | Inference 239.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 182.0ms\n",
            "Speed: 5.8ms preprocess, 182.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 906: Read 9.8 ms | Inference 248.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 207.1ms\n",
            "Speed: 6.0ms preprocess, 207.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 907: Read 3.6 ms | Inference 274.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 187.1ms\n",
            "Speed: 6.9ms preprocess, 187.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 908: Read 11.8 ms | Inference 243.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 188.5ms\n",
            "Speed: 19.1ms preprocess, 188.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 909: Read 3.6 ms | Inference 252.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 174.3ms\n",
            "Speed: 4.4ms preprocess, 174.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 910: Read 10.3 ms | Inference 227.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 207.3ms\n",
            "Speed: 11.9ms preprocess, 207.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 911: Read 11.9 ms | Inference 262.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 209.8ms\n",
            "Speed: 14.2ms preprocess, 209.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 912: Read 15.5 ms | Inference 275.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 192.4ms\n",
            "Speed: 6.2ms preprocess, 192.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 913: Read 3.6 ms | Inference 253.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 196.5ms\n",
            "Speed: 6.7ms preprocess, 196.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 914: Read 5.2 ms | Inference 244.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 200.0ms\n",
            "Speed: 7.2ms preprocess, 200.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 915: Read 3.5 ms | Inference 244.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 211.4ms\n",
            "Speed: 7.0ms preprocess, 211.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 916: Read 10.0 ms | Inference 268.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 160.0ms\n",
            "Speed: 5.6ms preprocess, 160.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 917: Read 10.2 ms | Inference 206.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 126.5ms\n",
            "Speed: 7.1ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 918: Read 3.7 ms | Inference 165.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 130.2ms\n",
            "Speed: 5.8ms preprocess, 130.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 919: Read 3.8 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 126.7ms\n",
            "Speed: 5.1ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 920: Read 3.6 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 132.8ms\n",
            "Speed: 8.4ms preprocess, 132.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 921: Read 3.7 ms | Inference 179.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.7ms\n",
            "Speed: 6.4ms preprocess, 127.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 922: Read 4.0 ms | Inference 167.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 130.5ms\n",
            "Speed: 6.0ms preprocess, 130.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 923: Read 3.7 ms | Inference 168.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.1ms\n",
            "Speed: 5.9ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 924: Read 3.8 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.8ms\n",
            "Speed: 6.3ms preprocess, 125.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 925: Read 3.6 ms | Inference 173.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 121.1ms\n",
            "Speed: 9.6ms preprocess, 121.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 926: Read 3.5 ms | Inference 168.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.3ms\n",
            "Speed: 9.2ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 927: Read 3.7 ms | Inference 173.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 138.6ms\n",
            "Speed: 6.3ms preprocess, 138.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 928: Read 3.8 ms | Inference 179.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.6ms\n",
            "Speed: 6.3ms preprocess, 125.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 929: Read 3.7 ms | Inference 173.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.8ms\n",
            "Speed: 4.4ms preprocess, 120.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 930: Read 3.6 ms | Inference 171.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 124.1ms\n",
            "Speed: 9.7ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 931: Read 3.7 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 2 cell phones, 126.1ms\n",
            "Speed: 9.5ms preprocess, 126.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 932: Read 3.7 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 122.8ms\n",
            "Speed: 5.0ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 933: Read 3.5 ms | Inference 178.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 133.8ms\n",
            "Speed: 5.9ms preprocess, 133.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 934: Read 4.2 ms | Inference 176.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 147.0ms\n",
            "Speed: 5.8ms preprocess, 147.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 935: Read 3.9 ms | Inference 187.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 128.9ms\n",
            "Speed: 10.7ms preprocess, 128.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 936: Read 3.7 ms | Inference 178.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.6ms\n",
            "Speed: 5.7ms preprocess, 124.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 937: Read 3.6 ms | Inference 170.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.2ms\n",
            "Speed: 6.1ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 938: Read 3.5 ms | Inference 161.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.0ms\n",
            "Speed: 5.7ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 939: Read 4.3 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 128.5ms\n",
            "Speed: 5.7ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 940: Read 11.4 ms | Inference 163.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.7ms\n",
            "Speed: 6.3ms preprocess, 125.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 941: Read 3.5 ms | Inference 166.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.6ms\n",
            "Speed: 6.1ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 942: Read 5.2 ms | Inference 161.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.2ms\n",
            "Speed: 10.7ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 943: Read 4.6 ms | Inference 170.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.2ms\n",
            "Speed: 5.1ms preprocess, 123.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 944: Read 3.6 ms | Inference 166.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.6ms\n",
            "Speed: 10.8ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 945: Read 3.7 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 136.4ms\n",
            "Speed: 6.2ms preprocess, 136.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 946: Read 3.7 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.4ms\n",
            "Speed: 10.3ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 947: Read 3.8 ms | Inference 165.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 129.7ms\n",
            "Speed: 5.5ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 948: Read 10.0 ms | Inference 169.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.5ms\n",
            "Speed: 6.0ms preprocess, 121.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 949: Read 3.6 ms | Inference 166.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 120.8ms\n",
            "Speed: 5.2ms preprocess, 120.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 950: Read 3.6 ms | Inference 162.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 120.1ms\n",
            "Speed: 6.0ms preprocess, 120.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 951: Read 3.8 ms | Inference 160.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 156.8ms\n",
            "Speed: 6.9ms preprocess, 156.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 952: Read 3.7 ms | Inference 193.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 136.5ms\n",
            "Speed: 5.8ms preprocess, 136.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 953: Read 4.4 ms | Inference 174.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.1ms\n",
            "Speed: 5.8ms preprocess, 127.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 954: Read 3.8 ms | Inference 169.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.4ms\n",
            "Speed: 6.2ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 955: Read 3.6 ms | Inference 165.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.9ms\n",
            "Speed: 5.7ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 956: Read 3.7 ms | Inference 163.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.1ms\n",
            "Speed: 6.2ms preprocess, 123.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 957: Read 3.7 ms | Inference 163.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 138.5ms\n",
            "Speed: 11.7ms preprocess, 138.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 958: Read 3.8 ms | Inference 182.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 145.4ms\n",
            "Speed: 10.7ms preprocess, 145.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 959: Read 4.3 ms | Inference 194.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 131.5ms\n",
            "Speed: 13.4ms preprocess, 131.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 960: Read 4.5 ms | Inference 183.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.4ms\n",
            "Speed: 6.1ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 961: Read 3.8 ms | Inference 164.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.4ms\n",
            "Speed: 5.8ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 962: Read 3.7 ms | Inference 160.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.5ms\n",
            "Speed: 9.6ms preprocess, 123.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 963: Read 3.7 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 131.0ms\n",
            "Speed: 5.9ms preprocess, 131.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 964: Read 11.8 ms | Inference 172.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.9ms\n",
            "Speed: 5.8ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 965: Read 3.7 ms | Inference 164.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.6ms\n",
            "Speed: 9.0ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 966: Read 3.7 ms | Inference 164.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.5ms\n",
            "Speed: 6.1ms preprocess, 124.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 967: Read 6.9 ms | Inference 163.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 128.9ms\n",
            "Speed: 6.6ms preprocess, 128.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 968: Read 4.3 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.9ms\n",
            "Speed: 5.8ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 969: Read 3.6 ms | Inference 169.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 129.7ms\n",
            "Speed: 9.7ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 970: Read 12.8 ms | Inference 174.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 119.7ms\n",
            "Speed: 5.0ms preprocess, 119.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 971: Read 3.5 ms | Inference 158.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 129.8ms\n",
            "Speed: 5.7ms preprocess, 129.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 972: Read 3.7 ms | Inference 171.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.0ms\n",
            "Speed: 9.4ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 973: Read 3.7 ms | Inference 164.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 146.7ms\n",
            "Speed: 6.0ms preprocess, 146.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 974: Read 3.6 ms | Inference 199.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 191.2ms\n",
            "Speed: 4.3ms preprocess, 191.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 975: Read 3.5 ms | Inference 231.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 178.8ms\n",
            "Speed: 5.1ms preprocess, 178.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 976: Read 12.7 ms | Inference 221.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 186.3ms\n",
            "Speed: 5.9ms preprocess, 186.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 977: Read 3.6 ms | Inference 226.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 173.1ms\n",
            "Speed: 6.1ms preprocess, 173.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 978: Read 15.0 ms | Inference 218.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 186.6ms\n",
            "Speed: 6.7ms preprocess, 186.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 979: Read 3.7 ms | Inference 229.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 205.0ms\n",
            "Speed: 12.1ms preprocess, 205.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 980: Read 13.2 ms | Inference 255.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 189.6ms\n",
            "Speed: 6.1ms preprocess, 189.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 981: Read 3.6 ms | Inference 232.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 186.2ms\n",
            "Speed: 12.3ms preprocess, 186.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 982: Read 10.3 ms | Inference 240.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 249.1ms\n",
            "Speed: 6.0ms preprocess, 249.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 983: Read 4.3 ms | Inference 323.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 245.7ms\n",
            "Speed: 8.9ms preprocess, 245.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 984: Read 3.9 ms | Inference 300.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 188.6ms\n",
            "Speed: 7.6ms preprocess, 188.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 985: Read 3.6 ms | Inference 249.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 190.9ms\n",
            "Speed: 7.3ms preprocess, 190.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 986: Read 11.6 ms | Inference 244.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 194.2ms\n",
            "Speed: 7.7ms preprocess, 194.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 987: Read 3.5 ms | Inference 246.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 205.8ms\n",
            "Speed: 4.4ms preprocess, 205.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 988: Read 5.7 ms | Inference 252.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 183.3ms\n",
            "Speed: 4.1ms preprocess, 183.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 989: Read 10.4 ms | Inference 228.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 192.4ms\n",
            "Speed: 6.4ms preprocess, 192.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 990: Read 10.3 ms | Inference 243.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 160.1ms\n",
            "Speed: 14.1ms preprocess, 160.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 991: Read 3.6 ms | Inference 207.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.2ms\n",
            "Speed: 5.7ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 992: Read 3.5 ms | Inference 165.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 143.5ms\n",
            "Speed: 6.0ms preprocess, 143.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 993: Read 4.4 ms | Inference 181.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 123.9ms\n",
            "Speed: 6.7ms preprocess, 123.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 994: Read 3.5 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.3ms\n",
            "Speed: 9.2ms preprocess, 125.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 995: Read 3.7 ms | Inference 170.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 122.7ms\n",
            "Speed: 12.2ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 996: Read 3.8 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 130.1ms\n",
            "Speed: 7.6ms preprocess, 130.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 997: Read 3.8 ms | Inference 173.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.0ms\n",
            "Speed: 10.3ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 998: Read 3.6 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 141.1ms\n",
            "Speed: 6.3ms preprocess, 141.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 999: Read 3.6 ms | Inference 183.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.4ms\n",
            "Speed: 5.9ms preprocess, 121.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1000: Read 3.6 ms | Inference 162.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 128.2ms\n",
            "Speed: 9.6ms preprocess, 128.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1001: Read 3.8 ms | Inference 168.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.5ms\n",
            "Speed: 4.1ms preprocess, 127.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1002: Read 3.5 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.8ms\n",
            "Speed: 8.0ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1003: Read 3.7 ms | Inference 161.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 128.8ms\n",
            "Speed: 5.7ms preprocess, 128.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1004: Read 4.5 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 141.1ms\n",
            "Speed: 9.8ms preprocess, 141.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1005: Read 3.6 ms | Inference 184.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.8ms\n",
            "Speed: 5.4ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1006: Read 3.6 ms | Inference 167.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 153.2ms\n",
            "Speed: 5.9ms preprocess, 153.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1007: Read 4.2 ms | Inference 196.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 133.8ms\n",
            "Speed: 6.7ms preprocess, 133.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1008: Read 3.4 ms | Inference 180.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.1ms\n",
            "Speed: 5.9ms preprocess, 123.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1009: Read 3.7 ms | Inference 162.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.4ms\n",
            "Speed: 6.0ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1010: Read 3.6 ms | Inference 165.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 139.1ms\n",
            "Speed: 5.9ms preprocess, 139.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1011: Read 7.0 ms | Inference 181.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.9ms\n",
            "Speed: 5.9ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1012: Read 3.5 ms | Inference 163.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 122.8ms\n",
            "Speed: 10.6ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1013: Read 3.8 ms | Inference 162.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.6ms\n",
            "Speed: 6.1ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1014: Read 3.5 ms | Inference 171.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.2ms\n",
            "Speed: 5.9ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1015: Read 3.5 ms | Inference 160.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 133.6ms\n",
            "Speed: 6.2ms preprocess, 133.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1016: Read 4.4 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 143.6ms\n",
            "Speed: 6.0ms preprocess, 143.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1017: Read 3.7 ms | Inference 182.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.5ms\n",
            "Speed: 5.9ms preprocess, 127.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1018: Read 3.7 ms | Inference 162.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.0ms\n",
            "Speed: 9.2ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1019: Read 3.7 ms | Inference 167.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.5ms\n",
            "Speed: 6.3ms preprocess, 124.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1020: Read 3.6 ms | Inference 169.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 126.5ms\n",
            "Speed: 6.1ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1021: Read 3.6 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.9ms\n",
            "Speed: 6.1ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1022: Read 3.6 ms | Inference 168.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 141.3ms\n",
            "Speed: 5.6ms preprocess, 141.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1023: Read 3.8 ms | Inference 178.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 126.0ms\n",
            "Speed: 7.3ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1024: Read 3.7 ms | Inference 162.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 130.9ms\n",
            "Speed: 6.0ms preprocess, 130.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1025: Read 3.6 ms | Inference 168.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 131.9ms\n",
            "Speed: 8.0ms preprocess, 131.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1026: Read 4.3 ms | Inference 175.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 124.5ms\n",
            "Speed: 9.4ms preprocess, 124.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1027: Read 3.7 ms | Inference 171.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 127.2ms\n",
            "Speed: 6.4ms preprocess, 127.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1028: Read 4.1 ms | Inference 166.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 136.9ms\n",
            "Speed: 8.4ms preprocess, 136.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1029: Read 3.7 ms | Inference 177.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 127.6ms\n",
            "Speed: 8.1ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1030: Read 3.7 ms | Inference 166.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 158.9ms\n",
            "Speed: 5.8ms preprocess, 158.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1031: Read 5.7 ms | Inference 197.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 125.1ms\n",
            "Speed: 8.9ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1032: Read 7.7 ms | Inference 174.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 126.3ms\n",
            "Speed: 6.0ms preprocess, 126.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1033: Read 3.7 ms | Inference 163.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.7ms\n",
            "Speed: 5.8ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1034: Read 3.6 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 126.5ms\n",
            "Speed: 11.4ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1035: Read 3.6 ms | Inference 180.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 121.2ms\n",
            "Speed: 9.1ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1036: Read 3.7 ms | Inference 166.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 123.6ms\n",
            "Speed: 6.9ms preprocess, 123.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1037: Read 3.7 ms | Inference 161.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 133.5ms\n",
            "Speed: 6.2ms preprocess, 133.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1038: Read 4.5 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 128.0ms\n",
            "Speed: 6.8ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1039: Read 3.7 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 122.9ms\n",
            "Speed: 12.2ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1040: Read 3.7 ms | Inference 180.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 132.6ms\n",
            "Speed: 6.6ms preprocess, 132.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1041: Read 3.6 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 129.0ms\n",
            "Speed: 5.9ms preprocess, 129.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1042: Read 3.8 ms | Inference 168.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 126.0ms\n",
            "Speed: 7.1ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1043: Read 10.4 ms | Inference 165.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 127.7ms\n",
            "Speed: 6.1ms preprocess, 127.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1044: Read 3.7 ms | Inference 176.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 126.7ms\n",
            "Speed: 6.8ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1045: Read 3.7 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 123.4ms\n",
            "Speed: 9.9ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1046: Read 3.7 ms | Inference 172.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 138.1ms\n",
            "Speed: 5.9ms preprocess, 138.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1047: Read 3.6 ms | Inference 178.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 177.5ms\n",
            "Speed: 7.5ms preprocess, 177.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1048: Read 3.7 ms | Inference 229.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 189.0ms\n",
            "Speed: 6.1ms preprocess, 189.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1049: Read 13.9 ms | Inference 245.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 182.8ms\n",
            "Speed: 8.9ms preprocess, 182.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1050: Read 14.2 ms | Inference 243.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 188.5ms\n",
            "Speed: 6.7ms preprocess, 188.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1051: Read 10.4 ms | Inference 256.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 188.5ms\n",
            "Speed: 9.0ms preprocess, 188.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1052: Read 12.3 ms | Inference 247.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 183.7ms\n",
            "Speed: 5.8ms preprocess, 183.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1053: Read 9.9 ms | Inference 236.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 181.4ms\n",
            "Speed: 5.9ms preprocess, 181.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1054: Read 12.8 ms | Inference 223.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 222.3ms\n",
            "Speed: 6.7ms preprocess, 222.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1055: Read 4.0 ms | Inference 275.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 186.8ms\n",
            "Speed: 5.0ms preprocess, 186.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1056: Read 3.7 ms | Inference 238.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 178.4ms\n",
            "Speed: 4.4ms preprocess, 178.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1057: Read 3.6 ms | Inference 221.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 186.1ms\n",
            "Speed: 9.9ms preprocess, 186.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1058: Read 4.4 ms | Inference 246.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 188.2ms\n",
            "Speed: 5.8ms preprocess, 188.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1059: Read 3.5 ms | Inference 251.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 214.1ms\n",
            "Speed: 7.5ms preprocess, 214.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1060: Read 3.5 ms | Inference 265.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 195.1ms\n",
            "Speed: 5.4ms preprocess, 195.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1061: Read 14.7 ms | Inference 255.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 192.7ms\n",
            "Speed: 8.0ms preprocess, 192.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1062: Read 3.7 ms | Inference 243.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 198.4ms\n",
            "Speed: 5.8ms preprocess, 198.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1063: Read 3.6 ms | Inference 262.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 2 cell phones, 201.8ms\n",
            "Speed: 6.6ms preprocess, 201.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1064: Read 9.6 ms | Inference 250.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 126.2ms\n",
            "Speed: 6.0ms preprocess, 126.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1065: Read 3.8 ms | Inference 167.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.2ms\n",
            "Speed: 9.4ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1066: Read 3.7 ms | Inference 169.9 ms\n",
            "\n",
            "0: 384x640 1 person, 7 bicycles, 1 cell phone, 121.4ms\n",
            "Speed: 6.1ms preprocess, 121.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1067: Read 3.6 ms | Inference 167.0 ms\n",
            "\n",
            "0: 384x640 1 person, 7 bicycles, 1 cell phone, 124.6ms\n",
            "Speed: 14.6ms preprocess, 124.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1068: Read 3.6 ms | Inference 180.9 ms\n",
            "\n",
            "0: 384x640 1 person, 7 bicycles, 125.2ms\n",
            "Speed: 6.9ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1069: Read 3.4 ms | Inference 167.2 ms\n",
            "\n",
            "0: 384x640 1 person, 7 bicycles, 1 cell phone, 138.9ms\n",
            "Speed: 5.9ms preprocess, 138.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1070: Read 3.5 ms | Inference 181.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.7ms\n",
            "Speed: 11.1ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1071: Read 3.7 ms | Inference 168.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.1ms\n",
            "Speed: 8.5ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1072: Read 3.7 ms | Inference 172.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 127.4ms\n",
            "Speed: 7.3ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1073: Read 3.7 ms | Inference 165.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 131.5ms\n",
            "Speed: 5.9ms preprocess, 131.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1074: Read 3.5 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 124.4ms\n",
            "Speed: 6.3ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1075: Read 3.5 ms | Inference 167.6 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 140.3ms\n",
            "Speed: 10.4ms preprocess, 140.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1076: Read 3.6 ms | Inference 192.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.2ms\n",
            "Speed: 6.6ms preprocess, 125.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1077: Read 3.8 ms | Inference 170.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 3 cell phones, 126.6ms\n",
            "Speed: 7.7ms preprocess, 126.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1078: Read 3.7 ms | Inference 168.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 3 cell phones, 152.3ms\n",
            "Speed: 5.9ms preprocess, 152.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1079: Read 3.9 ms | Inference 192.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 137.6ms\n",
            "Speed: 6.0ms preprocess, 137.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1080: Read 3.7 ms | Inference 184.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 126.1ms\n",
            "Speed: 6.7ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1081: Read 3.7 ms | Inference 178.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 130.3ms\n",
            "Speed: 7.6ms preprocess, 130.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1082: Read 4.2 ms | Inference 176.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 129.7ms\n",
            "Speed: 5.9ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1083: Read 3.6 ms | Inference 170.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.0ms\n",
            "Speed: 8.0ms preprocess, 125.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1084: Read 3.7 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.9ms\n",
            "Speed: 6.6ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1085: Read 3.6 ms | Inference 175.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 125.3ms\n",
            "Speed: 6.0ms preprocess, 125.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1086: Read 3.8 ms | Inference 162.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 126.1ms\n",
            "Speed: 13.2ms preprocess, 126.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1087: Read 4.5 ms | Inference 177.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 136.2ms\n",
            "Speed: 5.9ms preprocess, 136.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1088: Read 3.5 ms | Inference 178.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 130.3ms\n",
            "Speed: 6.4ms preprocess, 130.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1089: Read 3.7 ms | Inference 168.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.0ms\n",
            "Speed: 8.9ms preprocess, 121.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1090: Read 3.5 ms | Inference 166.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 132.8ms\n",
            "Speed: 10.6ms preprocess, 132.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1091: Read 3.5 ms | Inference 176.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 123.5ms\n",
            "Speed: 5.9ms preprocess, 123.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1092: Read 3.6 ms | Inference 177.1 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 121.2ms\n",
            "Speed: 5.7ms preprocess, 121.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1093: Read 3.5 ms | Inference 173.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 132.1ms\n",
            "Speed: 12.8ms preprocess, 132.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1094: Read 3.6 ms | Inference 180.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 128.2ms\n",
            "Speed: 11.2ms preprocess, 128.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1095: Read 3.8 ms | Inference 172.6 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 126.3ms\n",
            "Speed: 6.5ms preprocess, 126.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1096: Read 3.7 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 124.9ms\n",
            "Speed: 5.3ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1097: Read 8.9 ms | Inference 162.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 126.3ms\n",
            "Speed: 6.2ms preprocess, 126.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1098: Read 3.5 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 125.1ms\n",
            "Speed: 5.9ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1099: Read 3.6 ms | Inference 169.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 143.6ms\n",
            "Speed: 5.8ms preprocess, 143.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1100: Read 3.7 ms | Inference 183.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.7ms\n",
            "Speed: 9.3ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1101: Read 3.7 ms | Inference 170.3 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 120.4ms\n",
            "Speed: 6.6ms preprocess, 120.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1102: Read 3.5 ms | Inference 165.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 136.9ms\n",
            "Speed: 6.1ms preprocess, 136.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1103: Read 3.8 ms | Inference 185.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 bicycles, 1 cell phone, 121.7ms\n",
            "Speed: 6.5ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1104: Read 3.6 ms | Inference 167.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 122.8ms\n",
            "Speed: 7.5ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1105: Read 3.7 ms | Inference 162.4 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 137.3ms\n",
            "Speed: 7.3ms preprocess, 137.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1106: Read 3.5 ms | Inference 185.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 123.0ms\n",
            "Speed: 7.6ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1107: Read 3.7 ms | Inference 168.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 144.5ms\n",
            "Speed: 6.8ms preprocess, 144.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1108: Read 3.7 ms | Inference 186.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 121.8ms\n",
            "Speed: 6.5ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1109: Read 3.7 ms | Inference 160.5 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 122.5ms\n",
            "Speed: 5.4ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1110: Read 12.2 ms | Inference 166.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 bicycles, 1 cell phone, 135.6ms\n",
            "Speed: 6.1ms preprocess, 135.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1111: Read 3.8 ms | Inference 184.9 ms\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 137.9ms\n",
            "Speed: 5.8ms preprocess, 137.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1112: Read 10.5 ms | Inference 195.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 121.3ms\n",
            "Speed: 4.5ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1113: Read 3.6 ms | Inference 169.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 7 cars, 1 backpack, 117.3ms\n",
            "Speed: 12.5ms preprocess, 117.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1114: Read 3.6 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 backpack, 121.7ms\n",
            "Speed: 4.5ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1115: Read 3.6 ms | Inference 168.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 8 cars, 1 backpack, 122.3ms\n",
            "Speed: 6.0ms preprocess, 122.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1116: Read 3.6 ms | Inference 174.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 10 cars, 1 backpack, 128.7ms\n",
            "Speed: 6.0ms preprocess, 128.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1117: Read 3.6 ms | Inference 198.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 7 cars, 1 backpack, 128.4ms\n",
            "Speed: 5.7ms preprocess, 128.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1118: Read 3.7 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 1 backpack, 127.4ms\n",
            "Speed: 6.0ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1119: Read 3.6 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 backpack, 122.2ms\n",
            "Speed: 6.8ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1120: Read 3.5 ms | Inference 185.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 10 cars, 194.0ms\n",
            "Speed: 7.0ms preprocess, 194.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1121: Read 3.6 ms | Inference 251.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 1 backpack, 190.7ms\n",
            "Speed: 7.9ms preprocess, 190.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1122: Read 3.8 ms | Inference 255.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 8 cars, 1 backpack, 188.3ms\n",
            "Speed: 7.3ms preprocess, 188.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1123: Read 3.9 ms | Inference 257.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 1 backpack, 198.2ms\n",
            "Speed: 9.5ms preprocess, 198.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1124: Read 3.6 ms | Inference 260.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 backpack, 194.1ms\n",
            "Speed: 8.2ms preprocess, 194.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1125: Read 3.6 ms | Inference 252.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 backpack, 185.2ms\n",
            "Speed: 7.8ms preprocess, 185.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1126: Read 3.6 ms | Inference 244.0 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 backpack, 221.3ms\n",
            "Speed: 14.9ms preprocess, 221.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1127: Read 13.3 ms | Inference 292.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 1 backpack, 185.7ms\n",
            "Speed: 7.7ms preprocess, 185.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1128: Read 3.6 ms | Inference 247.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 2 backpacks, 183.9ms\n",
            "Speed: 11.9ms preprocess, 183.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1129: Read 9.6 ms | Inference 261.5 ms\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 backpack, 183.1ms\n",
            "Speed: 8.3ms preprocess, 183.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1130: Read 3.6 ms | Inference 240.6 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 backpack, 222.3ms\n",
            "Speed: 6.9ms preprocess, 222.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1131: Read 13.3 ms | Inference 290.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 196.2ms\n",
            "Speed: 8.5ms preprocess, 196.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1132: Read 3.6 ms | Inference 257.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 203.9ms\n",
            "Speed: 10.9ms preprocess, 203.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1133: Read 6.6 ms | Inference 275.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 backpack, 194.6ms\n",
            "Speed: 11.6ms preprocess, 194.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1134: Read 11.5 ms | Inference 264.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 200.7ms\n",
            "Speed: 6.3ms preprocess, 200.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1135: Read 4.9 ms | Inference 263.3 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 6 cars, 1 backpack, 189.0ms\n",
            "Speed: 10.1ms preprocess, 189.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1136: Read 13.1 ms | Inference 243.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 131.1ms\n",
            "Speed: 5.7ms preprocess, 131.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1137: Read 3.8 ms | Inference 173.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 122.2ms\n",
            "Speed: 5.8ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1138: Read 3.6 ms | Inference 170.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 126.4ms\n",
            "Speed: 6.1ms preprocess, 126.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1139: Read 3.6 ms | Inference 175.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 144.1ms\n",
            "Speed: 5.8ms preprocess, 144.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1140: Read 3.8 ms | Inference 187.1 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 5 cars, 1 backpack, 128.5ms\n",
            "Speed: 6.2ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1141: Read 3.8 ms | Inference 172.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 125.9ms\n",
            "Speed: 5.8ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1142: Read 3.7 ms | Inference 169.7 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 5 cars, 1 backpack, 130.9ms\n",
            "Speed: 5.9ms preprocess, 130.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1143: Read 3.9 ms | Inference 174.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 6 cars, 1 backpack, 138.1ms\n",
            "Speed: 9.0ms preprocess, 138.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1144: Read 3.8 ms | Inference 189.7 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 7 cars, 1 backpack, 124.6ms\n",
            "Speed: 9.2ms preprocess, 124.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1145: Read 3.7 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 backpack, 141.2ms\n",
            "Speed: 5.8ms preprocess, 141.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1146: Read 3.5 ms | Inference 191.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 backpack, 125.1ms\n",
            "Speed: 5.8ms preprocess, 125.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1147: Read 3.7 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 backpack, 124.8ms\n",
            "Speed: 6.3ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1148: Read 3.7 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 2 backpacks, 125.9ms\n",
            "Speed: 5.9ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1149: Read 3.8 ms | Inference 171.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 backpack, 125.4ms\n",
            "Speed: 5.6ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1150: Read 3.6 ms | Inference 176.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 1 backpack, 141.1ms\n",
            "Speed: 8.1ms preprocess, 141.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1151: Read 3.8 ms | Inference 191.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 5 cars, 1 backpack, 140.2ms\n",
            "Speed: 6.0ms preprocess, 140.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1152: Read 3.5 ms | Inference 184.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 5 cars, 1 backpack, 127.9ms\n",
            "Speed: 6.1ms preprocess, 127.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1153: Read 3.8 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 2 backpacks, 127.6ms\n",
            "Speed: 7.3ms preprocess, 127.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1154: Read 3.8 ms | Inference 174.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 backpack, 126.9ms\n",
            "Speed: 6.2ms preprocess, 126.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1155: Read 3.9 ms | Inference 170.4 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 backpacks, 127.9ms\n",
            "Speed: 7.7ms preprocess, 127.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1156: Read 3.8 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 backpacks, 128.1ms\n",
            "Speed: 7.7ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1157: Read 3.7 ms | Inference 180.6 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 4 cars, 1 backpack, 134.5ms\n",
            "Speed: 5.6ms preprocess, 134.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1158: Read 3.7 ms | Inference 178.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 backpacks, 121.3ms\n",
            "Speed: 9.5ms preprocess, 121.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1159: Read 3.8 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 backpack, 123.7ms\n",
            "Speed: 9.3ms preprocess, 123.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1160: Read 3.7 ms | Inference 170.4 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 backpack, 125.5ms\n",
            "Speed: 6.2ms preprocess, 125.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1161: Read 3.6 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 backpack, 126.5ms\n",
            "Speed: 5.7ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1162: Read 3.8 ms | Inference 167.2 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 backpack, 124.4ms\n",
            "Speed: 5.8ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1163: Read 3.7 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 backpack, 134.8ms\n",
            "Speed: 5.6ms preprocess, 134.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1164: Read 3.4 ms | Inference 178.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 backpack, 129.2ms\n",
            "Speed: 7.3ms preprocess, 129.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1165: Read 3.8 ms | Inference 173.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 128.6ms\n",
            "Speed: 8.7ms preprocess, 128.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1166: Read 3.7 ms | Inference 174.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 4 cars, 1 backpack, 127.2ms\n",
            "Speed: 5.8ms preprocess, 127.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1167: Read 3.5 ms | Inference 168.8 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 5 cars, 2 backpacks, 121.4ms\n",
            "Speed: 15.5ms preprocess, 121.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1168: Read 3.8 ms | Inference 175.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 124.9ms\n",
            "Speed: 9.6ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1169: Read 3.6 ms | Inference 184.2 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 backpack, 122.8ms\n",
            "Speed: 9.9ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1170: Read 10.9 ms | Inference 174.9 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 traffic light, 2 backpacks, 122.5ms\n",
            "Speed: 5.8ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1171: Read 3.5 ms | Inference 175.3 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 backpack, 130.6ms\n",
            "Speed: 5.6ms preprocess, 130.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1172: Read 3.5 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 backpack, 124.2ms\n",
            "Speed: 7.0ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1173: Read 3.7 ms | Inference 166.0 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 backpack, 124.1ms\n",
            "Speed: 6.5ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1174: Read 3.5 ms | Inference 173.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 backpack, 142.0ms\n",
            "Speed: 7.1ms preprocess, 142.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1175: Read 3.7 ms | Inference 194.0 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 backpack, 133.3ms\n",
            "Speed: 8.1ms preprocess, 133.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1176: Read 4.5 ms | Inference 177.1 ms\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 124.0ms\n",
            "Speed: 6.4ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1177: Read 3.5 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 backpack, 125.9ms\n",
            "Speed: 7.5ms preprocess, 125.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1178: Read 3.7 ms | Inference 169.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 backpack, 122.2ms\n",
            "Speed: 5.7ms preprocess, 122.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1179: Read 3.5 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 122.4ms\n",
            "Speed: 6.1ms preprocess, 122.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1180: Read 3.5 ms | Inference 172.9 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 142.7ms\n",
            "Speed: 5.7ms preprocess, 142.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1181: Read 3.5 ms | Inference 186.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 127.8ms\n",
            "Speed: 8.0ms preprocess, 127.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1182: Read 3.7 ms | Inference 174.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 7 cars, 122.9ms\n",
            "Speed: 9.3ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1183: Read 3.8 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 123.0ms\n",
            "Speed: 6.7ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1184: Read 4.2 ms | Inference 175.1 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 125.6ms\n",
            "Speed: 5.8ms preprocess, 125.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1185: Read 3.6 ms | Inference 168.8 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 123.9ms\n",
            "Speed: 12.6ms preprocess, 123.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1186: Read 3.8 ms | Inference 177.0 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 backpack, 142.3ms\n",
            "Speed: 9.2ms preprocess, 142.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1187: Read 3.8 ms | Inference 190.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 128.4ms\n",
            "Speed: 8.1ms preprocess, 128.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1188: Read 3.7 ms | Inference 177.7 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 129.5ms\n",
            "Speed: 9.3ms preprocess, 129.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1189: Read 3.8 ms | Inference 177.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 124.9ms\n",
            "Speed: 6.1ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1190: Read 3.5 ms | Inference 171.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 128.5ms\n",
            "Speed: 9.7ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1191: Read 3.7 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 8 cars, 1 backpack, 171.6ms\n",
            "Speed: 5.8ms preprocess, 171.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1192: Read 3.7 ms | Inference 242.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 backpack, 196.3ms\n",
            "Speed: 6.0ms preprocess, 196.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1193: Read 13.5 ms | Inference 264.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 190.0ms\n",
            "Speed: 6.1ms preprocess, 190.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1194: Read 3.6 ms | Inference 247.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 backpack, 182.6ms\n",
            "Speed: 6.0ms preprocess, 182.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1195: Read 9.7 ms | Inference 245.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 8 cars, 201.3ms\n",
            "Speed: 5.8ms preprocess, 201.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1196: Read 3.6 ms | Inference 270.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 9 cars, 1 truck, 192.5ms\n",
            "Speed: 12.7ms preprocess, 192.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1197: Read 16.1 ms | Inference 271.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 185.8ms\n",
            "Speed: 5.8ms preprocess, 185.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1198: Read 10.3 ms | Inference 251.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 8 cars, 207.1ms\n",
            "Speed: 5.8ms preprocess, 207.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1199: Read 10.3 ms | Inference 266.5 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 truck, 180.8ms\n",
            "Speed: 7.2ms preprocess, 180.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1200: Read 3.6 ms | Inference 244.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 1 truck, 199.7ms\n",
            "Speed: 15.0ms preprocess, 199.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1201: Read 15.7 ms | Inference 275.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 truck, 192.5ms\n",
            "Speed: 16.5ms preprocess, 192.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1202: Read 3.6 ms | Inference 259.8 ms\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 truck, 191.5ms\n",
            "Speed: 15.9ms preprocess, 191.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1203: Read 15.7 ms | Inference 253.8 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 191.2ms\n",
            "Speed: 7.5ms preprocess, 191.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1204: Read 11.4 ms | Inference 259.3 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 traffic light, 242.6ms\n",
            "Speed: 5.7ms preprocess, 242.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1205: Read 9.0 ms | Inference 301.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 truck, 193.2ms\n",
            "Speed: 19.5ms preprocess, 193.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1206: Read 3.6 ms | Inference 280.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 176.8ms\n",
            "Speed: 4.3ms preprocess, 176.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1207: Read 16.6 ms | Inference 224.1 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 128.7ms\n",
            "Speed: 5.6ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1208: Read 3.6 ms | Inference 170.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 142.7ms\n",
            "Speed: 12.1ms preprocess, 142.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1209: Read 3.5 ms | Inference 199.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 123.8ms\n",
            "Speed: 5.6ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1210: Read 3.6 ms | Inference 173.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 126.0ms\n",
            "Speed: 5.7ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1211: Read 3.5 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 127.0ms\n",
            "Speed: 6.2ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1212: Read 3.6 ms | Inference 169.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 142.7ms\n",
            "Speed: 7.1ms preprocess, 142.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1213: Read 3.7 ms | Inference 188.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 130.0ms\n",
            "Speed: 5.7ms preprocess, 130.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1214: Read 3.6 ms | Inference 177.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 141.7ms\n",
            "Speed: 13.1ms preprocess, 141.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1215: Read 3.8 ms | Inference 195.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 131.2ms\n",
            "Speed: 7.6ms preprocess, 131.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1216: Read 6.4 ms | Inference 186.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 125.4ms\n",
            "Speed: 8.1ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1217: Read 3.8 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 132.8ms\n",
            "Speed: 5.7ms preprocess, 132.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1218: Read 3.5 ms | Inference 182.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 1 traffic light, 1 backpack, 127.2ms\n",
            "Speed: 5.8ms preprocess, 127.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1219: Read 5.8 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 1 backpack, 131.1ms\n",
            "Speed: 8.9ms preprocess, 131.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1220: Read 3.6 ms | Inference 199.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 truck, 1 backpack, 129.7ms\n",
            "Speed: 5.7ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1221: Read 3.7 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 122.5ms\n",
            "Speed: 6.4ms preprocess, 122.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1222: Read 5.3 ms | Inference 170.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 146.1ms\n",
            "Speed: 5.9ms preprocess, 146.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1223: Read 3.8 ms | Inference 187.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 121.2ms\n",
            "Speed: 11.8ms preprocess, 121.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1224: Read 3.5 ms | Inference 177.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 traffic light, 129.4ms\n",
            "Speed: 9.8ms preprocess, 129.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1225: Read 3.8 ms | Inference 179.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 139.5ms\n",
            "Speed: 6.1ms preprocess, 139.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1226: Read 3.5 ms | Inference 190.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 132.4ms\n",
            "Speed: 6.0ms preprocess, 132.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1227: Read 3.8 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 126.0ms\n",
            "Speed: 9.7ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1228: Read 3.7 ms | Inference 174.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 120.2ms\n",
            "Speed: 6.0ms preprocess, 120.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1229: Read 3.6 ms | Inference 171.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 1 stop sign, 137.7ms\n",
            "Speed: 6.1ms preprocess, 137.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1230: Read 3.7 ms | Inference 185.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 128.6ms\n",
            "Speed: 5.6ms preprocess, 128.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1231: Read 3.6 ms | Inference 177.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 truck, 141.5ms\n",
            "Speed: 8.2ms preprocess, 141.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1232: Read 3.6 ms | Inference 199.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 120.9ms\n",
            "Speed: 5.9ms preprocess, 120.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1233: Read 3.6 ms | Inference 168.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 123.3ms\n",
            "Speed: 12.5ms preprocess, 123.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1234: Read 3.6 ms | Inference 177.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 119.0ms\n",
            "Speed: 4.4ms preprocess, 119.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1235: Read 3.6 ms | Inference 166.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 2 trucks, 133.9ms\n",
            "Speed: 8.5ms preprocess, 133.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1236: Read 5.5 ms | Inference 187.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 128.8ms\n",
            "Speed: 7.0ms preprocess, 128.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1237: Read 3.8 ms | Inference 186.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 1 truck, 126.9ms\n",
            "Speed: 5.9ms preprocess, 126.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1238: Read 13.6 ms | Inference 168.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 truck, 1 backpack, 120.6ms\n",
            "Speed: 6.2ms preprocess, 120.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1239: Read 4.8 ms | Inference 168.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 truck, 121.6ms\n",
            "Speed: 9.8ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1240: Read 3.7 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 123.8ms\n",
            "Speed: 11.1ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1241: Read 3.7 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 truck, 129.1ms\n",
            "Speed: 5.8ms preprocess, 129.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1242: Read 3.7 ms | Inference 174.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 truck, 130.2ms\n",
            "Speed: 13.2ms preprocess, 130.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1243: Read 3.6 ms | Inference 189.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 truck, 132.3ms\n",
            "Speed: 7.3ms preprocess, 132.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1244: Read 3.7 ms | Inference 180.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 6 cars, 118.5ms\n",
            "Speed: 4.4ms preprocess, 118.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1245: Read 3.5 ms | Inference 168.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 118.9ms\n",
            "Speed: 7.8ms preprocess, 118.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1246: Read 3.7 ms | Inference 167.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 132.1ms\n",
            "Speed: 4.6ms preprocess, 132.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1247: Read 3.7 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 129.4ms\n",
            "Speed: 13.1ms preprocess, 129.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1248: Read 3.8 ms | Inference 180.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 148.1ms\n",
            "Speed: 6.8ms preprocess, 148.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1249: Read 3.8 ms | Inference 192.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 backpack, 117.4ms\n",
            "Speed: 4.3ms preprocess, 117.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1250: Read 3.6 ms | Inference 172.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 backpack, 119.9ms\n",
            "Speed: 4.8ms preprocess, 119.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1251: Read 3.7 ms | Inference 168.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 118.6ms\n",
            "Speed: 7.9ms preprocess, 118.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1252: Read 3.6 ms | Inference 169.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 traffic light, 116.5ms\n",
            "Speed: 9.1ms preprocess, 116.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1253: Read 4.1 ms | Inference 166.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 backpack, 124.9ms\n",
            "Speed: 9.5ms preprocess, 124.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1254: Read 3.7 ms | Inference 176.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 backpack, 136.3ms\n",
            "Speed: 6.7ms preprocess, 136.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1255: Read 3.5 ms | Inference 181.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 2 backpacks, 124.5ms\n",
            "Speed: 6.3ms preprocess, 124.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1256: Read 3.7 ms | Inference 166.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 1 backpack, 124.2ms\n",
            "Speed: 10.3ms preprocess, 124.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1257: Read 3.7 ms | Inference 172.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 backpack, 130.7ms\n",
            "Speed: 12.3ms preprocess, 130.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1258: Read 3.8 ms | Inference 190.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 backpack, 130.5ms\n",
            "Speed: 9.7ms preprocess, 130.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1259: Read 12.7 ms | Inference 179.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 120.1ms\n",
            "Speed: 5.8ms preprocess, 120.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1260: Read 3.5 ms | Inference 162.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 1 backpack, 150.2ms\n",
            "Speed: 9.7ms preprocess, 150.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1261: Read 3.5 ms | Inference 202.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 167.4ms\n",
            "Speed: 10.9ms preprocess, 167.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1262: Read 3.5 ms | Inference 234.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 190.8ms\n",
            "Speed: 6.7ms preprocess, 190.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1263: Read 3.6 ms | Inference 248.4 ms\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 192.6ms\n",
            "Speed: 8.2ms preprocess, 192.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1264: Read 3.6 ms | Inference 248.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 car, 196.8ms\n",
            "Speed: 5.8ms preprocess, 196.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1265: Read 3.6 ms | Inference 251.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 2 cars, 182.9ms\n",
            "Speed: 10.8ms preprocess, 182.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1266: Read 17.1 ms | Inference 248.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 192.1ms\n",
            "Speed: 6.0ms preprocess, 192.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1267: Read 3.6 ms | Inference 246.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 4 cars, 185.9ms\n",
            "Speed: 5.8ms preprocess, 185.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1268: Read 10.0 ms | Inference 249.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 186.3ms\n",
            "Speed: 15.3ms preprocess, 186.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1269: Read 3.5 ms | Inference 259.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 184.7ms\n",
            "Speed: 15.5ms preprocess, 184.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1270: Read 16.7 ms | Inference 252.6 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 198.8ms\n",
            "Speed: 5.9ms preprocess, 198.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1271: Read 10.4 ms | Inference 259.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 194.6ms\n",
            "Speed: 6.2ms preprocess, 194.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1272: Read 3.6 ms | Inference 253.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 4 cars, 178.7ms\n",
            "Speed: 13.8ms preprocess, 178.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1273: Read 17.3 ms | Inference 254.4 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 3 cars, 215.5ms\n",
            "Speed: 8.9ms preprocess, 215.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1274: Read 15.3 ms | Inference 278.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 199.1ms\n",
            "Speed: 6.1ms preprocess, 199.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1275: Read 3.6 ms | Inference 248.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 5 cars, 198.2ms\n",
            "Speed: 7.1ms preprocess, 198.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1276: Read 3.6 ms | Inference 268.4 ms\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 187.5ms\n",
            "Speed: 9.8ms preprocess, 187.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1277: Read 16.8 ms | Inference 249.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 195.4ms\n",
            "Speed: 7.2ms preprocess, 195.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1278: Read 3.6 ms | Inference 237.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 124.8ms\n",
            "Speed: 13.5ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1279: Read 3.7 ms | Inference 176.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 128.3ms\n",
            "Speed: 5.8ms preprocess, 128.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1280: Read 3.7 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 121.8ms\n",
            "Speed: 5.8ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1281: Read 3.5 ms | Inference 169.3 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 cars, 1 truck, 124.2ms\n",
            "Speed: 10.4ms preprocess, 124.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1282: Read 3.7 ms | Inference 172.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 129.7ms\n",
            "Speed: 6.2ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1283: Read 3.8 ms | Inference 186.1 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 cars, 1 traffic light, 125.2ms\n",
            "Speed: 6.2ms preprocess, 125.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1284: Read 9.5 ms | Inference 175.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 126.5ms\n",
            "Speed: 5.9ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1285: Read 3.6 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 126.6ms\n",
            "Speed: 7.1ms preprocess, 126.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1286: Read 3.6 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 126.3ms\n",
            "Speed: 5.9ms preprocess, 126.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1287: Read 3.5 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 1 car, 1 truck, 125.3ms\n",
            "Speed: 6.0ms preprocess, 125.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1288: Read 3.5 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 backpack, 141.5ms\n",
            "Speed: 6.0ms preprocess, 141.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1289: Read 3.6 ms | Inference 192.1 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 125.7ms\n",
            "Speed: 5.8ms preprocess, 125.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1290: Read 3.5 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 124.8ms\n",
            "Speed: 5.8ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1291: Read 3.6 ms | Inference 170.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 123.4ms\n",
            "Speed: 7.3ms preprocess, 123.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1292: Read 3.7 ms | Inference 173.8 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 133.9ms\n",
            "Speed: 7.4ms preprocess, 133.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1293: Read 3.8 ms | Inference 179.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 2 trucks, 133.4ms\n",
            "Speed: 9.9ms preprocess, 133.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1294: Read 3.8 ms | Inference 177.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 1 truck, 154.0ms\n",
            "Speed: 14.9ms preprocess, 154.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1295: Read 4.5 ms | Inference 204.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 1 car, 1 truck, 127.8ms\n",
            "Speed: 5.7ms preprocess, 127.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1296: Read 3.5 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 truck, 128.5ms\n",
            "Speed: 5.7ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1297: Read 3.6 ms | Inference 181.2 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 cars, 1 truck, 124.6ms\n",
            "Speed: 10.0ms preprocess, 124.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1298: Read 3.8 ms | Inference 174.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 1 car, 1 truck, 124.0ms\n",
            "Speed: 5.9ms preprocess, 124.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1299: Read 3.8 ms | Inference 168.3 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 4 cars, 1 truck, 126.7ms\n",
            "Speed: 5.9ms preprocess, 126.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1300: Read 3.5 ms | Inference 180.8 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 cars, 142.5ms\n",
            "Speed: 10.8ms preprocess, 142.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1301: Read 3.8 ms | Inference 190.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 truck, 129.2ms\n",
            "Speed: 5.6ms preprocess, 129.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1302: Read 3.6 ms | Inference 178.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 truck, 122.4ms\n",
            "Speed: 10.0ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1303: Read 3.6 ms | Inference 172.2 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 cars, 2 trucks, 121.9ms\n",
            "Speed: 6.8ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1304: Read 3.5 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 3 cars, 2 trucks, 127.3ms\n",
            "Speed: 5.7ms preprocess, 127.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1305: Read 3.7 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 1 truck, 132.3ms\n",
            "Speed: 7.2ms preprocess, 132.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1306: Read 3.8 ms | Inference 189.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 5 cars, 1 truck, 127.0ms\n",
            "Speed: 10.9ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1307: Read 11.3 ms | Inference 187.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 4 cars, 2 trucks, 130.8ms\n",
            "Speed: 10.0ms preprocess, 130.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1308: Read 4.4 ms | Inference 184.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 4 cars, 1 truck, 124.3ms\n",
            "Speed: 5.8ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1309: Read 3.6 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 truck, 127.0ms\n",
            "Speed: 9.3ms preprocess, 127.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1310: Read 3.8 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 car, 1 truck, 125.7ms\n",
            "Speed: 5.8ms preprocess, 125.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1311: Read 3.5 ms | Inference 178.2 ms\n",
            "\n",
            "0: 384x640 2 persons, 3 bicycles, 3 cars, 1 truck, 141.5ms\n",
            "Speed: 5.8ms preprocess, 141.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1312: Read 3.7 ms | Inference 188.9 ms\n",
            "\n",
            "0: 384x640 2 persons, 2 bicycles, 2 cars, 1 truck, 124.8ms\n",
            "Speed: 6.7ms preprocess, 124.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1313: Read 3.8 ms | Inference 169.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 2 cars, 1 truck, 125.6ms\n",
            "Speed: 8.2ms preprocess, 125.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1314: Read 3.7 ms | Inference 177.9 ms\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 121.6ms\n",
            "Speed: 5.8ms preprocess, 121.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1315: Read 3.5 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 car, 1 truck, 122.7ms\n",
            "Speed: 6.1ms preprocess, 122.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1316: Read 3.6 ms | Inference 171.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 3 cars, 2 buss, 1 truck, 128.0ms\n",
            "Speed: 8.9ms preprocess, 128.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1317: Read 3.6 ms | Inference 178.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 3 cars, 1 bus, 1 truck, 142.6ms\n",
            "Speed: 5.9ms preprocess, 142.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1318: Read 3.6 ms | Inference 193.1 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 bus, 1 truck, 1 umbrella, 130.8ms\n",
            "Speed: 6.0ms preprocess, 130.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1319: Read 3.8 ms | Inference 178.7 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 1 motorcycle, 1 bus, 1 truck, 121.7ms\n",
            "Speed: 6.2ms preprocess, 121.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1320: Read 3.5 ms | Inference 171.9 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 truck, 133.0ms\n",
            "Speed: 5.8ms preprocess, 133.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1321: Read 3.8 ms | Inference 176.1 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 1 car, 1 bus, 1 truck, 125.6ms\n",
            "Speed: 4.5ms preprocess, 125.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1322: Read 3.6 ms | Inference 178.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 1 car, 1 bus, 1 truck, 123.4ms\n",
            "Speed: 6.0ms preprocess, 123.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1323: Read 3.6 ms | Inference 176.7 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 1 car, 147.6ms\n",
            "Speed: 9.0ms preprocess, 147.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1324: Read 4.0 ms | Inference 194.9 ms\n",
            "\n",
            "0: 384x640 5 persons, 2 bicycles, 2 cars, 132.3ms\n",
            "Speed: 6.6ms preprocess, 132.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1325: Read 4.4 ms | Inference 179.6 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 1 bus, 1 stop sign, 122.6ms\n",
            "Speed: 5.7ms preprocess, 122.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1326: Read 3.6 ms | Inference 173.7 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 2 cars, 1 truck, 125.0ms\n",
            "Speed: 6.2ms preprocess, 125.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1327: Read 3.6 ms | Inference 179.3 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 2 cars, 1 truck, 130.0ms\n",
            "Speed: 6.1ms preprocess, 130.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1328: Read 3.9 ms | Inference 180.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 1 car, 1 truck, 128.7ms\n",
            "Speed: 6.0ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1329: Read 3.6 ms | Inference 198.3 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 truck, 127.2ms\n",
            "Speed: 8.0ms preprocess, 127.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1330: Read 3.7 ms | Inference 176.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 3 cars, 1 truck, 121.9ms\n",
            "Speed: 14.3ms preprocess, 121.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1331: Read 3.7 ms | Inference 178.5 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 2 cars, 126.5ms\n",
            "Speed: 8.4ms preprocess, 126.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1332: Read 3.8 ms | Inference 170.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 3 bicycles, 2 cars, 168.4ms\n",
            "Speed: 8.0ms preprocess, 168.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1333: Read 3.6 ms | Inference 237.5 ms\n",
            "\n",
            "0: 384x640 5 persons, 4 bicycles, 3 cars, 1 truck, 192.7ms\n",
            "Speed: 8.6ms preprocess, 192.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1334: Read 11.9 ms | Inference 261.2 ms\n",
            "\n",
            "0: 384x640 3 persons, 2 bicycles, 1 car, 1 truck, 197.2ms\n",
            "Speed: 5.9ms preprocess, 197.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1335: Read 3.5 ms | Inference 258.8 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 3 cars, 1 truck, 203.0ms\n",
            "Speed: 7.1ms preprocess, 203.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1336: Read 3.5 ms | Inference 263.2 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 2 cars, 1 truck, 191.8ms\n",
            "Speed: 10.7ms preprocess, 191.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1337: Read 14.9 ms | Inference 254.9 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 2 cars, 1 truck, 191.1ms\n",
            "Speed: 5.9ms preprocess, 191.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1338: Read 5.9 ms | Inference 247.0 ms\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 3 cars, 1 truck, 188.4ms\n",
            "Speed: 13.6ms preprocess, 188.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1339: Read 10.7 ms | Inference 258.8 ms\n",
            "\n",
            "0: 384x640 3 persons, 4 bicycles, 2 cars, 1 truck, 191.1ms\n",
            "Speed: 10.0ms preprocess, 191.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1340: Read 9.8 ms | Inference 264.6 ms\n",
            "\n",
            "0: 384x640 3 persons, 3 bicycles, 1 car, 1 truck, 188.3ms\n",
            "Speed: 7.7ms preprocess, 188.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1341: Read 8.9 ms | Inference 253.3 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 1 car, 1 bus, 1 truck, 185.7ms\n",
            "Speed: 12.8ms preprocess, 185.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1342: Read 17.5 ms | Inference 246.2 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 1 car, 1 truck, 195.9ms\n",
            "Speed: 14.1ms preprocess, 195.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1343: Read 13.5 ms | Inference 260.1 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 2 cars, 1 truck, 186.2ms\n",
            "Speed: 6.2ms preprocess, 186.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1344: Read 10.1 ms | Inference 248.0 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 1 car, 1 truck, 198.1ms\n",
            "Speed: 12.2ms preprocess, 198.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1345: Read 12.0 ms | Inference 260.1 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 3 cars, 1 truck, 201.8ms\n",
            "Speed: 6.0ms preprocess, 201.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1346: Read 13.4 ms | Inference 261.5 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 1 car, 1 bus, 1 truck, 194.7ms\n",
            "Speed: 13.7ms preprocess, 194.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1347: Read 10.3 ms | Inference 267.3 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 3 cars, 1 truck, 193.4ms\n",
            "Speed: 11.8ms preprocess, 193.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1348: Read 12.3 ms | Inference 252.8 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 3 cars, 179.0ms\n",
            "Speed: 14.6ms preprocess, 179.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1349: Read 12.7 ms | Inference 236.8 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 3 cars, 1 truck, 130.8ms\n",
            "Speed: 5.8ms preprocess, 130.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1350: Read 3.8 ms | Inference 176.4 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 2 cars, 1 bus, 1 truck, 120.0ms\n",
            "Speed: 11.1ms preprocess, 120.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1351: Read 3.6 ms | Inference 173.3 ms\n",
            "\n",
            "0: 384x640 1 person, 3 bicycles, 2 cars, 1 truck, 142.8ms\n",
            "Speed: 5.8ms preprocess, 142.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1352: Read 3.6 ms | Inference 188.2 ms\n",
            "\n",
            "0: 384x640 1 person, 4 bicycles, 2 cars, 1 bus, 1 truck, 134.0ms\n",
            "Speed: 6.5ms preprocess, 134.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1353: Read 3.8 ms | Inference 180.0 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 bus, 1 truck, 126.4ms\n",
            "Speed: 5.7ms preprocess, 126.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1354: Read 3.8 ms | Inference 171.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 1 truck, 120.8ms\n",
            "Speed: 5.9ms preprocess, 120.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1355: Read 3.5 ms | Inference 170.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 122.9ms\n",
            "Speed: 6.0ms preprocess, 122.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1356: Read 3.6 ms | Inference 167.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 bus, 1 truck, 121.8ms\n",
            "Speed: 6.0ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1357: Read 3.6 ms | Inference 178.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 bus, 140.6ms\n",
            "Speed: 5.6ms preprocess, 140.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1358: Read 3.5 ms | Inference 195.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 128.7ms\n",
            "Speed: 8.1ms preprocess, 128.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1359: Read 4.6 ms | Inference 176.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 126.3ms\n",
            "Speed: 7.4ms preprocess, 126.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1360: Read 3.8 ms | Inference 169.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 122.8ms\n",
            "Speed: 6.2ms preprocess, 122.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1361: Read 3.6 ms | Inference 174.4 ms\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 bus, 1 truck, 119.0ms\n",
            "Speed: 6.0ms preprocess, 119.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1362: Read 3.7 ms | Inference 168.2 ms\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 134.1ms\n",
            "Speed: 7.2ms preprocess, 134.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1363: Read 3.7 ms | Inference 186.8 ms\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 137.3ms\n",
            "Speed: 5.9ms preprocess, 137.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1364: Read 14.3 ms | Inference 181.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 bus, 129.7ms\n",
            "Speed: 8.2ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1365: Read 3.8 ms | Inference 175.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 bus, 124.4ms\n",
            "Speed: 6.0ms preprocess, 124.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1366: Read 3.6 ms | Inference 177.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 bus, 131.4ms\n",
            "Speed: 9.5ms preprocess, 131.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1367: Read 3.8 ms | Inference 179.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 3 cars, 1 bus, 1 truck, 124.7ms\n",
            "Speed: 6.1ms preprocess, 124.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1368: Read 3.6 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 1 traffic light, 153.8ms\n",
            "Speed: 7.7ms preprocess, 153.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1369: Read 3.8 ms | Inference 200.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 127.2ms\n",
            "Speed: 6.3ms preprocess, 127.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1370: Read 3.7 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 1 bus, 123.0ms\n",
            "Speed: 5.9ms preprocess, 123.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1371: Read 3.5 ms | Inference 170.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 121.8ms\n",
            "Speed: 6.7ms preprocess, 121.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1372: Read 3.7 ms | Inference 171.8 ms\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 117.6ms\n",
            "Speed: 4.4ms preprocess, 117.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1373: Read 4.3 ms | Inference 165.8 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 7 cars, 1 bus, 126.7ms\n",
            "Speed: 8.0ms preprocess, 126.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1374: Read 3.8 ms | Inference 175.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 151.8ms\n",
            "Speed: 6.4ms preprocess, 151.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1375: Read 3.7 ms | Inference 195.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 4 cars, 1 bus, 130.2ms\n",
            "Speed: 5.6ms preprocess, 130.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1376: Read 3.6 ms | Inference 173.1 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 1 bus, 126.0ms\n",
            "Speed: 5.9ms preprocess, 126.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1377: Read 3.5 ms | Inference 176.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 5 cars, 125.4ms\n",
            "Speed: 13.1ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1378: Read 3.8 ms | Inference 175.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 121.0ms\n",
            "Speed: 15.9ms preprocess, 121.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1379: Read 3.5 ms | Inference 176.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 125.7ms\n",
            "Speed: 8.3ms preprocess, 125.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1380: Read 5.0 ms | Inference 186.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 141.5ms\n",
            "Speed: 9.2ms preprocess, 141.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1381: Read 3.7 ms | Inference 199.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 131.5ms\n",
            "Speed: 5.8ms preprocess, 131.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1382: Read 3.7 ms | Inference 181.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 127.4ms\n",
            "Speed: 6.0ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1383: Read 3.5 ms | Inference 174.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 125.4ms\n",
            "Speed: 11.1ms preprocess, 125.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1384: Read 3.7 ms | Inference 174.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 129.7ms\n",
            "Speed: 6.1ms preprocess, 129.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1385: Read 3.7 ms | Inference 179.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 135.9ms\n",
            "Speed: 9.7ms preprocess, 135.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1386: Read 3.5 ms | Inference 200.5 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 6 cars, 129.8ms\n",
            "Speed: 6.4ms preprocess, 129.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1387: Read 3.8 ms | Inference 174.7 ms\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 7 cars, 123.0ms\n",
            "Speed: 7.2ms preprocess, 123.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1388: Read 3.7 ms | Inference 175.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 7 cars, 127.8ms\n",
            "Speed: 6.1ms preprocess, 127.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1389: Read 3.5 ms | Inference 176.8 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 9 cars, 120.6ms\n",
            "Speed: 10.7ms preprocess, 120.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1390: Read 3.8 ms | Inference 182.1 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 7 cars, 140.1ms\n",
            "Speed: 9.3ms preprocess, 140.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1391: Read 3.9 ms | Inference 189.3 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 8 cars, 145.2ms\n",
            "Speed: 9.5ms preprocess, 145.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1392: Read 3.8 ms | Inference 191.4 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 7 cars, 129.7ms\n",
            "Speed: 5.8ms preprocess, 129.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1393: Read 3.8 ms | Inference 175.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 7 cars, 121.9ms\n",
            "Speed: 7.6ms preprocess, 121.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1394: Read 3.6 ms | Inference 172.7 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 122.1ms\n",
            "Speed: 9.3ms preprocess, 122.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1395: Read 3.7 ms | Inference 172.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 122.4ms\n",
            "Speed: 6.2ms preprocess, 122.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1396: Read 3.6 ms | Inference 180.0 ms\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 132.5ms\n",
            "Speed: 12.6ms preprocess, 132.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1397: Read 3.6 ms | Inference 188.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 146.1ms\n",
            "Speed: 5.7ms preprocess, 146.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1398: Read 3.6 ms | Inference 196.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 131.5ms\n",
            "Speed: 7.9ms preprocess, 131.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1399: Read 3.8 ms | Inference 182.3 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 9 cars, 126.9ms\n",
            "Speed: 13.0ms preprocess, 126.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1400: Read 3.8 ms | Inference 181.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 119.0ms\n",
            "Speed: 5.8ms preprocess, 119.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1401: Read 3.7 ms | Inference 173.2 ms\n",
            "\n",
            "0: 384x640 1 person, 2 bicycles, 7 cars, 132.7ms\n",
            "Speed: 8.7ms preprocess, 132.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1402: Read 3.8 ms | Inference 181.7 ms\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 125.1ms\n",
            "Speed: 5.9ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1403: Read 3.8 ms | Inference 182.4 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 6 cars, 187.9ms\n",
            "Speed: 5.8ms preprocess, 187.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1404: Read 10.3 ms | Inference 233.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 184.2ms\n",
            "Speed: 5.9ms preprocess, 184.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1405: Read 3.6 ms | Inference 244.2 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 8 cars, 185.0ms\n",
            "Speed: 9.9ms preprocess, 185.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1406: Read 3.6 ms | Inference 255.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 206.8ms\n",
            "Speed: 7.7ms preprocess, 206.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1407: Read 3.5 ms | Inference 262.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 185.8ms\n",
            "Speed: 10.0ms preprocess, 185.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1408: Read 10.5 ms | Inference 247.5 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 188.6ms\n",
            "Speed: 5.9ms preprocess, 188.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1409: Read 3.7 ms | Inference 240.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 196.6ms\n",
            "Speed: 5.9ms preprocess, 196.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1410: Read 11.1 ms | Inference 266.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 184.8ms\n",
            "Speed: 8.3ms preprocess, 184.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1411: Read 3.6 ms | Inference 248.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 187.4ms\n",
            "Speed: 11.8ms preprocess, 187.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1412: Read 8.6 ms | Inference 270.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 188.3ms\n",
            "Speed: 9.9ms preprocess, 188.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1413: Read 3.6 ms | Inference 256.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 201.5ms\n",
            "Speed: 7.0ms preprocess, 201.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1414: Read 3.5 ms | Inference 270.0 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 12 cars, 180.3ms\n",
            "Speed: 9.8ms preprocess, 180.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1415: Read 3.6 ms | Inference 252.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 13 cars, 205.8ms\n",
            "Speed: 5.9ms preprocess, 205.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1416: Read 7.5 ms | Inference 268.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 197.5ms\n",
            "Speed: 7.4ms preprocess, 197.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1417: Read 3.6 ms | Inference 253.6 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 195.5ms\n",
            "Speed: 11.0ms preprocess, 195.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1418: Read 13.7 ms | Inference 278.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 187.5ms\n",
            "Speed: 5.8ms preprocess, 187.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1419: Read 9.5 ms | Inference 262.9 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 10 cars, 166.1ms\n",
            "Speed: 8.9ms preprocess, 166.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1420: Read 17.0 ms | Inference 215.5 ms\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 123.8ms\n",
            "Speed: 7.3ms preprocess, 123.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1421: Read 3.8 ms | Inference 172.8 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 9 cars, 128.1ms\n",
            "Speed: 6.2ms preprocess, 128.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1422: Read 3.7 ms | Inference 183.3 ms\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 11 cars, 124.3ms\n",
            "Speed: 5.6ms preprocess, 124.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Frame 1423: Read 2.8 ms | Inference 173.6 ms\n",
            "Processing complete! Video saved to Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================\n",
        "# STEP 5: Run Detection on Video\n",
        "# =====================\n",
        "# Path to your trained model\n",
        "\n",
        "\n",
        "\n",
        "model_path = \"/content/gdrive/MyDrive/yolov10_train/bicycle_model2/weights/best.pt\"\n",
        "\n",
        "# Path to input video in Drive\n",
        "video_path = \"/content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4\"  # <-- Change to your video path\n",
        "\n",
        "\n",
        "\n",
        "# Output path\n",
        "output_path = \"/content/gdrive/MyDrive/bicycle_dataset/bike_detected.mp4\"\n",
        "\n",
        "# Run detection\n",
        "model = YOLO(model_path)\n",
        "model.predict(\n",
        "    source=video_path,\n",
        "    conf=0.25,\n",
        "    save=True,\n",
        "    project=\"/content/gdrive/MyDrive/bicycle_dataset\",\n",
        "    name=\"bike_detected\"\n",
        ")\n",
        "\n",
        "print(f\"âœ… Detection complete! Check output folder: /content/gdrive/MyDrive/bicycle_dataset/bike_detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKZY2aOSahZP",
        "outputId": "819f2add-3acf-4362-917c-9e4e563cc882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING âš ï¸ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 2/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 3/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.2ms\n",
            "video 1/1 (frame 4/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 5/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 6/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 7/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 8/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.0ms\n",
            "video 1/1 (frame 9/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 10/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 11/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.7ms\n",
            "video 1/1 (frame 12/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 13/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 14/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.7ms\n",
            "video 1/1 (frame 15/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 16/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 17/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.2ms\n",
            "video 1/1 (frame 18/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 19/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.4ms\n",
            "video 1/1 (frame 20/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 11.2ms\n",
            "video 1/1 (frame 21/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.0ms\n",
            "video 1/1 (frame 22/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 10.1ms\n",
            "video 1/1 (frame 23/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 11.1ms\n",
            "video 1/1 (frame 24/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.6ms\n",
            "video 1/1 (frame 25/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 26/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 27/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.1ms\n",
            "video 1/1 (frame 28/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 29/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 30/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.6ms\n",
            "video 1/1 (frame 31/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.4ms\n",
            "video 1/1 (frame 32/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.8ms\n",
            "video 1/1 (frame 33/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 34/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 35/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 36/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 37/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 38/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 39/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 40/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.9ms\n",
            "video 1/1 (frame 41/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 42/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 43/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 44/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.0ms\n",
            "video 1/1 (frame 45/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 23.1ms\n",
            "video 1/1 (frame 46/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.9ms\n",
            "video 1/1 (frame 47/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 48/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 29.0ms\n",
            "video 1/1 (frame 49/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 50/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.5ms\n",
            "video 1/1 (frame 51/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 52/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 53/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 54/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 55/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 56/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 57/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.6ms\n",
            "video 1/1 (frame 58/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.4ms\n",
            "video 1/1 (frame 59/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.2ms\n",
            "video 1/1 (frame 60/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 21.6ms\n",
            "video 1/1 (frame 61/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 24.2ms\n",
            "video 1/1 (frame 62/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 25.1ms\n",
            "video 1/1 (frame 63/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 64/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 65/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.3ms\n",
            "video 1/1 (frame 66/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.1ms\n",
            "video 1/1 (frame 67/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.2ms\n",
            "video 1/1 (frame 68/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 69/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 70/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 71/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 72/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 73/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.2ms\n",
            "video 1/1 (frame 74/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.6ms\n",
            "video 1/1 (frame 75/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.9ms\n",
            "video 1/1 (frame 76/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 77/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 78/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 79/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.6ms\n",
            "video 1/1 (frame 80/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 81/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 82/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.8ms\n",
            "video 1/1 (frame 83/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 84/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.7ms\n",
            "video 1/1 (frame 85/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.5ms\n",
            "video 1/1 (frame 86/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.7ms\n",
            "video 1/1 (frame 87/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 24.6ms\n",
            "video 1/1 (frame 88/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 89/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 90/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 91/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 92/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.8ms\n",
            "video 1/1 (frame 93/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.2ms\n",
            "video 1/1 (frame 94/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 95/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.7ms\n",
            "video 1/1 (frame 96/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 97/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 98/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.0ms\n",
            "video 1/1 (frame 99/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 100/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.2ms\n",
            "video 1/1 (frame 101/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 102/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 103/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 104/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 105/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 9.1ms\n",
            "video 1/1 (frame 106/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 107/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.1ms\n",
            "video 1/1 (frame 108/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 109/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 110/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 111/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 112/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.3ms\n",
            "video 1/1 (frame 113/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 114/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 115/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 116/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 117/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.9ms\n",
            "video 1/1 (frame 118/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 119/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 120/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.4ms\n",
            "video 1/1 (frame 121/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 122/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 123/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 124/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.3ms\n",
            "video 1/1 (frame 125/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 126/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 127/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.6ms\n",
            "video 1/1 (frame 128/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.3ms\n",
            "video 1/1 (frame 129/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.8ms\n",
            "video 1/1 (frame 130/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 131/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.6ms\n",
            "video 1/1 (frame 132/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 133/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 134/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 10.1ms\n",
            "video 1/1 (frame 135/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 9.7ms\n",
            "video 1/1 (frame 136/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 137/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 138/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 139/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 140/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 141/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 142/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 143/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 144/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.2ms\n",
            "video 1/1 (frame 145/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.2ms\n",
            "video 1/1 (frame 146/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 11.8ms\n",
            "video 1/1 (frame 147/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 148/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.2ms\n",
            "video 1/1 (frame 149/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 150/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.1ms\n",
            "video 1/1 (frame 151/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 152/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.6ms\n",
            "video 1/1 (frame 153/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 154/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 155/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 156/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.4ms\n",
            "video 1/1 (frame 157/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 158/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 159/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 160/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 161/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 162/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 163/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 164/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 165/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 166/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 167/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 168/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 169/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.5ms\n",
            "video 1/1 (frame 170/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.3ms\n",
            "video 1/1 (frame 171/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.6ms\n",
            "video 1/1 (frame 172/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 173/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 174/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 175/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 176/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 177/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 178/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 179/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.1ms\n",
            "video 1/1 (frame 180/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 181/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.8ms\n",
            "video 1/1 (frame 182/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.1ms\n",
            "video 1/1 (frame 183/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 21.5ms\n",
            "video 1/1 (frame 184/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 185/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 186/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 187/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 188/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 189/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.8ms\n",
            "video 1/1 (frame 190/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 191/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 192/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 193/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 194/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 195/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 196/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 197/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 198/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 199/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 200/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 201/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 202/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 203/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 204/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 205/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 206/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 207/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 208/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 209/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.4ms\n",
            "video 1/1 (frame 210/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 211/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.8ms\n",
            "video 1/1 (frame 212/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 213/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 214/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.9ms\n",
            "video 1/1 (frame 215/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 216/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 217/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.8ms\n",
            "video 1/1 (frame 218/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 219/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 220/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 221/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 222/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.1ms\n",
            "video 1/1 (frame 223/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 224/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 225/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 226/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.9ms\n",
            "video 1/1 (frame 227/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.2ms\n",
            "video 1/1 (frame 228/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.6ms\n",
            "video 1/1 (frame 229/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.4ms\n",
            "video 1/1 (frame 230/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 231/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 232/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.4ms\n",
            "video 1/1 (frame 233/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.5ms\n",
            "video 1/1 (frame 234/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.8ms\n",
            "video 1/1 (frame 235/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 236/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 237/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 238/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.2ms\n",
            "video 1/1 (frame 239/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 240/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 241/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 242/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 243/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.3ms\n",
            "video 1/1 (frame 244/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 245/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 246/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 247/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 248/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 249/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 250/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.1ms\n",
            "video 1/1 (frame 251/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 252/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 253/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 254/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 255/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 256/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.9ms\n",
            "video 1/1 (frame 257/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 258/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 259/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.9ms\n",
            "video 1/1 (frame 260/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 261/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.5ms\n",
            "video 1/1 (frame 262/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 263/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 264/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 265/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 266/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 267/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 268/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 269/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.2ms\n",
            "video 1/1 (frame 270/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.2ms\n",
            "video 1/1 (frame 271/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 272/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.0ms\n",
            "video 1/1 (frame 273/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 274/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 275/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 276/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.0ms\n",
            "video 1/1 (frame 277/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 278/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.8ms\n",
            "video 1/1 (frame 279/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 280/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 281/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 282/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 283/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 284/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 285/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 286/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 287/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 288/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 289/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.8ms\n",
            "video 1/1 (frame 290/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.2ms\n",
            "video 1/1 (frame 291/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.7ms\n",
            "video 1/1 (frame 292/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.4ms\n",
            "video 1/1 (frame 293/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 21.0ms\n",
            "video 1/1 (frame 294/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 295/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.0ms\n",
            "video 1/1 (frame 296/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.4ms\n",
            "video 1/1 (frame 297/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 298/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.1ms\n",
            "video 1/1 (frame 299/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 16.9ms\n",
            "video 1/1 (frame 300/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 14.0ms\n",
            "video 1/1 (frame 301/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 14.9ms\n",
            "video 1/1 (frame 302/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 26.1ms\n",
            "video 1/1 (frame 303/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 13.4ms\n",
            "video 1/1 (frame 304/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.2ms\n",
            "video 1/1 (frame 305/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 306/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.5ms\n",
            "video 1/1 (frame 307/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.9ms\n",
            "video 1/1 (frame 308/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 20.5ms\n",
            "video 1/1 (frame 309/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.7ms\n",
            "video 1/1 (frame 310/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 28.3ms\n",
            "video 1/1 (frame 311/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 312/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.5ms\n",
            "video 1/1 (frame 313/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 314/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.3ms\n",
            "video 1/1 (frame 315/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 316/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.3ms\n",
            "video 1/1 (frame 317/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.5ms\n",
            "video 1/1 (frame 318/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 319/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 320/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.9ms\n",
            "video 1/1 (frame 321/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 322/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.2ms\n",
            "video 1/1 (frame 323/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 324/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.8ms\n",
            "video 1/1 (frame 325/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 326/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 33.0ms\n",
            "video 1/1 (frame 327/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 328/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 329/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 330/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 331/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 332/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.5ms\n",
            "video 1/1 (frame 333/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 334/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 335/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.0ms\n",
            "video 1/1 (frame 336/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.4ms\n",
            "video 1/1 (frame 337/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.9ms\n",
            "video 1/1 (frame 338/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.8ms\n",
            "video 1/1 (frame 339/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.5ms\n",
            "video 1/1 (frame 340/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.5ms\n",
            "video 1/1 (frame 341/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 26.5ms\n",
            "video 1/1 (frame 342/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 22.6ms\n",
            "video 1/1 (frame 343/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 344/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 345/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 346/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 347/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 348/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 349/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 350/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 351/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 352/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 353/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 354/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 355/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 356/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 357/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 358/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 359/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 360/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 361/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 362/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 363/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.5ms\n",
            "video 1/1 (frame 364/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 365/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 366/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 367/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 368/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 369/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 370/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.1ms\n",
            "video 1/1 (frame 371/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 372/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 373/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 374/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.8ms\n",
            "video 1/1 (frame 375/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 376/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 377/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 378/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 379/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 380/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 381/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 382/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 383/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 384/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 385/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.3ms\n",
            "video 1/1 (frame 386/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 387/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.8ms\n",
            "video 1/1 (frame 388/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 389/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 390/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 391/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 392/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 393/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 394/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 395/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.5ms\n",
            "video 1/1 (frame 396/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 397/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 398/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 399/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 400/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 401/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 402/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 403/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 404/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 405/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 406/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.8ms\n",
            "video 1/1 (frame 407/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 408/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 409/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 410/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.0ms\n",
            "video 1/1 (frame 411/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 412/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 413/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 414/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 415/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 416/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 417/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 418/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.5ms\n",
            "video 1/1 (frame 419/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 420/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 421/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 422/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 423/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 424/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 425/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 426/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 427/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 428/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.1ms\n",
            "video 1/1 (frame 429/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 430/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 431/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 432/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 433/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 434/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 435/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 436/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 437/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 438/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 439/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 440/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 441/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.5ms\n",
            "video 1/1 (frame 442/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 443/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 444/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 445/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 446/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 447/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 448/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 449/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.2ms\n",
            "video 1/1 (frame 450/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 451/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 452/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 453/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 454/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 455/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 456/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 457/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 458/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 459/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 460/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 461/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 462/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 463/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 464/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 465/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 466/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.4ms\n",
            "video 1/1 (frame 467/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 468/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 469/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 470/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.8ms\n",
            "video 1/1 (frame 471/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 472/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 473/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 474/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 475/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 476/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 477/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 478/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 479/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 480/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 481/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 482/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.6ms\n",
            "video 1/1 (frame 483/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 484/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 485/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 486/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.6ms\n",
            "video 1/1 (frame 487/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 488/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.6ms\n",
            "video 1/1 (frame 489/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 490/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.9ms\n",
            "video 1/1 (frame 491/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 492/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 493/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 494/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 495/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 496/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 497/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.7ms\n",
            "video 1/1 (frame 498/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 499/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 500/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 501/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 502/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 503/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 504/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 505/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 506/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.6ms\n",
            "video 1/1 (frame 507/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 508/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 509/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 510/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 511/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.9ms\n",
            "video 1/1 (frame 512/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 513/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 514/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.4ms\n",
            "video 1/1 (frame 515/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 516/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 517/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 518/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 519/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 520/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 521/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 522/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 523/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 524/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 525/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 526/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 527/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 528/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 529/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.1ms\n",
            "video 1/1 (frame 530/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 531/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 532/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.8ms\n",
            "video 1/1 (frame 533/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 534/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 535/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 536/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 537/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 538/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 539/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 540/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.4ms\n",
            "video 1/1 (frame 541/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 542/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 543/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.7ms\n",
            "video 1/1 (frame 544/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 545/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.8ms\n",
            "video 1/1 (frame 546/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.7ms\n",
            "video 1/1 (frame 547/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.2ms\n",
            "video 1/1 (frame 548/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 549/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 24.6ms\n",
            "video 1/1 (frame 550/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 22.0ms\n",
            "video 1/1 (frame 551/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.6ms\n",
            "video 1/1 (frame 552/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 22.7ms\n",
            "video 1/1 (frame 553/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 554/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.9ms\n",
            "video 1/1 (frame 555/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.5ms\n",
            "video 1/1 (frame 556/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 557/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.8ms\n",
            "video 1/1 (frame 558/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 559/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.1ms\n",
            "video 1/1 (frame 560/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.9ms\n",
            "video 1/1 (frame 561/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.1ms\n",
            "video 1/1 (frame 562/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.1ms\n",
            "video 1/1 (frame 563/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.7ms\n",
            "video 1/1 (frame 564/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 15.7ms\n",
            "video 1/1 (frame 565/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.9ms\n",
            "video 1/1 (frame 566/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 20.4ms\n",
            "video 1/1 (frame 567/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.2ms\n",
            "video 1/1 (frame 568/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.9ms\n",
            "video 1/1 (frame 569/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.8ms\n",
            "video 1/1 (frame 570/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 571/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 13.9ms\n",
            "video 1/1 (frame 572/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.4ms\n",
            "video 1/1 (frame 573/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.4ms\n",
            "video 1/1 (frame 574/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 21.6ms\n",
            "video 1/1 (frame 575/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.2ms\n",
            "video 1/1 (frame 576/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 28.5ms\n",
            "video 1/1 (frame 577/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 578/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.7ms\n",
            "video 1/1 (frame 579/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 580/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 581/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 582/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.6ms\n",
            "video 1/1 (frame 583/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.2ms\n",
            "video 1/1 (frame 584/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.8ms\n",
            "video 1/1 (frame 585/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.1ms\n",
            "video 1/1 (frame 586/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 22.6ms\n",
            "video 1/1 (frame 587/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.7ms\n",
            "video 1/1 (frame 588/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.1ms\n",
            "video 1/1 (frame 589/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.4ms\n",
            "video 1/1 (frame 590/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.1ms\n",
            "video 1/1 (frame 591/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.3ms\n",
            "video 1/1 (frame 592/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 593/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 594/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 595/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.7ms\n",
            "video 1/1 (frame 596/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 597/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 598/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 599/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 600/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 601/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 602/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 603/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.0ms\n",
            "video 1/1 (frame 604/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 605/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 606/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 607/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.5ms\n",
            "video 1/1 (frame 608/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 609/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 610/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 611/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 612/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 613/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.1ms\n",
            "video 1/1 (frame 614/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.5ms\n",
            "video 1/1 (frame 615/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 616/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 617/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.3ms\n",
            "video 1/1 (frame 618/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 619/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 620/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 621/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 622/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 623/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 624/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 625/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 626/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.9ms\n",
            "video 1/1 (frame 627/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 628/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 629/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 630/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 631/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 632/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 633/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 634/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 635/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 636/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 27.0ms\n",
            "video 1/1 (frame 637/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 638/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 639/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 640/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 641/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 642/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 643/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 644/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 645/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 646/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 647/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 648/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 649/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 650/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 651/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.2ms\n",
            "video 1/1 (frame 652/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 653/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 654/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 655/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 656/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 657/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.9ms\n",
            "video 1/1 (frame 658/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 659/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 660/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 661/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 662/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 663/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 664/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 665/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 666/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 667/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.9ms\n",
            "video 1/1 (frame 668/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 669/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.9ms\n",
            "video 1/1 (frame 670/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 671/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.7ms\n",
            "video 1/1 (frame 672/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.7ms\n",
            "video 1/1 (frame 673/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.4ms\n",
            "video 1/1 (frame 674/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.2ms\n",
            "video 1/1 (frame 675/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 676/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.0ms\n",
            "video 1/1 (frame 677/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 678/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.5ms\n",
            "video 1/1 (frame 679/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 680/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.4ms\n",
            "video 1/1 (frame 681/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 682/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 683/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.7ms\n",
            "video 1/1 (frame 684/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.9ms\n",
            "video 1/1 (frame 685/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 686/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 687/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 688/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 689/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 690/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 691/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 692/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.4ms\n",
            "video 1/1 (frame 693/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 694/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 695/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 696/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 697/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 698/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.5ms\n",
            "video 1/1 (frame 699/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.3ms\n",
            "video 1/1 (frame 700/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 701/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 702/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 703/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 704/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 705/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 706/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 707/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 708/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 709/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 710/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 711/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 712/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 713/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 714/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 715/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.2ms\n",
            "video 1/1 (frame 716/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 717/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 718/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 719/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 720/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 721/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 722/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 723/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 724/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 725/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.8ms\n",
            "video 1/1 (frame 726/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.1ms\n",
            "video 1/1 (frame 727/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 728/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.7ms\n",
            "video 1/1 (frame 729/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 730/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 731/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.1ms\n",
            "video 1/1 (frame 732/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 733/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 734/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.1ms\n",
            "video 1/1 (frame 735/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.3ms\n",
            "video 1/1 (frame 736/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.6ms\n",
            "video 1/1 (frame 737/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 738/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.6ms\n",
            "video 1/1 (frame 739/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 740/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 741/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.3ms\n",
            "video 1/1 (frame 742/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.6ms\n",
            "video 1/1 (frame 743/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 744/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 745/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 746/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.7ms\n",
            "video 1/1 (frame 747/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 748/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 749/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 750/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 751/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 752/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 753/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 754/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.9ms\n",
            "video 1/1 (frame 755/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 756/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.5ms\n",
            "video 1/1 (frame 757/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 758/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.0ms\n",
            "video 1/1 (frame 759/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 760/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 761/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 762/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 763/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 764/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 765/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.8ms\n",
            "video 1/1 (frame 766/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 767/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 768/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 769/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 770/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.9ms\n",
            "video 1/1 (frame 771/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.2ms\n",
            "video 1/1 (frame 772/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.1ms\n",
            "video 1/1 (frame 773/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 774/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.9ms\n",
            "video 1/1 (frame 775/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 776/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 777/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 778/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.9ms\n",
            "video 1/1 (frame 779/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 780/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.3ms\n",
            "video 1/1 (frame 781/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 782/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 783/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.6ms\n",
            "video 1/1 (frame 784/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 31.7ms\n",
            "video 1/1 (frame 785/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.0ms\n",
            "video 1/1 (frame 786/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.3ms\n",
            "video 1/1 (frame 787/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 788/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.9ms\n",
            "video 1/1 (frame 789/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.8ms\n",
            "video 1/1 (frame 790/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.8ms\n",
            "video 1/1 (frame 791/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 792/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 25.4ms\n",
            "video 1/1 (frame 793/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.9ms\n",
            "video 1/1 (frame 794/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 25.3ms\n",
            "video 1/1 (frame 795/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.2ms\n",
            "video 1/1 (frame 796/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.4ms\n",
            "video 1/1 (frame 797/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.6ms\n",
            "video 1/1 (frame 798/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.9ms\n",
            "video 1/1 (frame 799/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.2ms\n",
            "video 1/1 (frame 800/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.0ms\n",
            "video 1/1 (frame 801/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 802/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 803/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 21.5ms\n",
            "video 1/1 (frame 804/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.9ms\n",
            "video 1/1 (frame 805/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 26.1ms\n",
            "video 1/1 (frame 806/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 17.6ms\n",
            "video 1/1 (frame 807/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 808/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.7ms\n",
            "video 1/1 (frame 809/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.5ms\n",
            "video 1/1 (frame 810/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.9ms\n",
            "video 1/1 (frame 811/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.1ms\n",
            "video 1/1 (frame 812/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 20.6ms\n",
            "video 1/1 (frame 813/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.3ms\n",
            "video 1/1 (frame 814/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.2ms\n",
            "video 1/1 (frame 815/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 816/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.3ms\n",
            "video 1/1 (frame 817/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.4ms\n",
            "video 1/1 (frame 818/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.2ms\n",
            "video 1/1 (frame 819/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 820/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.2ms\n",
            "video 1/1 (frame 821/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.9ms\n",
            "video 1/1 (frame 822/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.3ms\n",
            "video 1/1 (frame 823/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 22.7ms\n",
            "video 1/1 (frame 824/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 23.9ms\n",
            "video 1/1 (frame 825/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.7ms\n",
            "video 1/1 (frame 826/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.0ms\n",
            "video 1/1 (frame 827/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.4ms\n",
            "video 1/1 (frame 828/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.8ms\n",
            "video 1/1 (frame 829/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.3ms\n",
            "video 1/1 (frame 830/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.2ms\n",
            "video 1/1 (frame 831/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.5ms\n",
            "video 1/1 (frame 832/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 833/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 834/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.8ms\n",
            "video 1/1 (frame 835/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.5ms\n",
            "video 1/1 (frame 836/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 837/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 838/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.0ms\n",
            "video 1/1 (frame 839/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 840/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 841/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 842/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 843/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 844/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.8ms\n",
            "video 1/1 (frame 845/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 846/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 847/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.4ms\n",
            "video 1/1 (frame 848/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 849/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.6ms\n",
            "video 1/1 (frame 850/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 851/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 852/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.3ms\n",
            "video 1/1 (frame 853/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.2ms\n",
            "video 1/1 (frame 854/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 855/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.5ms\n",
            "video 1/1 (frame 856/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 857/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 858/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 859/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 860/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 861/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 862/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 863/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 864/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 865/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 866/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 867/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 868/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.5ms\n",
            "video 1/1 (frame 869/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 870/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 871/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 872/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.6ms\n",
            "video 1/1 (frame 873/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 874/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 875/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.6ms\n",
            "video 1/1 (frame 876/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 877/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 878/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.5ms\n",
            "video 1/1 (frame 879/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 880/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 881/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 882/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 883/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.0ms\n",
            "video 1/1 (frame 884/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 885/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 886/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.8ms\n",
            "video 1/1 (frame 887/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 888/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 889/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.0ms\n",
            "video 1/1 (frame 890/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 891/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 892/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 893/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 894/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 895/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 24.0ms\n",
            "video 1/1 (frame 896/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 897/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 898/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 899/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 900/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 901/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 13.7ms\n",
            "video 1/1 (frame 902/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 903/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.2ms\n",
            "video 1/1 (frame 904/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.6ms\n",
            "video 1/1 (frame 905/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.4ms\n",
            "video 1/1 (frame 906/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 907/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.8ms\n",
            "video 1/1 (frame 908/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 909/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.1ms\n",
            "video 1/1 (frame 910/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.6ms\n",
            "video 1/1 (frame 911/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 912/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.7ms\n",
            "video 1/1 (frame 913/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.4ms\n",
            "video 1/1 (frame 914/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 915/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 916/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.6ms\n",
            "video 1/1 (frame 917/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.0ms\n",
            "video 1/1 (frame 918/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 919/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 920/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.7ms\n",
            "video 1/1 (frame 921/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 922/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 923/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.6ms\n",
            "video 1/1 (frame 924/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 925/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.6ms\n",
            "video 1/1 (frame 926/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 927/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 928/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.3ms\n",
            "video 1/1 (frame 929/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.3ms\n",
            "video 1/1 (frame 930/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 931/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.7ms\n",
            "video 1/1 (frame 932/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.2ms\n",
            "video 1/1 (frame 933/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 934/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 935/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 936/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.1ms\n",
            "video 1/1 (frame 937/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.6ms\n",
            "video 1/1 (frame 938/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 939/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 940/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.4ms\n",
            "video 1/1 (frame 941/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 942/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.1ms\n",
            "video 1/1 (frame 943/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 944/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.0ms\n",
            "video 1/1 (frame 945/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 946/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 947/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.1ms\n",
            "video 1/1 (frame 948/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 949/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 950/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 951/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.2ms\n",
            "video 1/1 (frame 952/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 953/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.1ms\n",
            "video 1/1 (frame 954/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 955/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.4ms\n",
            "video 1/1 (frame 956/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.4ms\n",
            "video 1/1 (frame 957/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.2ms\n",
            "video 1/1 (frame 958/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 959/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.7ms\n",
            "video 1/1 (frame 960/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.6ms\n",
            "video 1/1 (frame 961/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.3ms\n",
            "video 1/1 (frame 962/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.5ms\n",
            "video 1/1 (frame 963/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 964/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 965/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 966/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 967/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.2ms\n",
            "video 1/1 (frame 968/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 969/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 970/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 971/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.9ms\n",
            "video 1/1 (frame 972/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 973/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.0ms\n",
            "video 1/1 (frame 974/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 975/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 976/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.1ms\n",
            "video 1/1 (frame 977/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.5ms\n",
            "video 1/1 (frame 978/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.4ms\n",
            "video 1/1 (frame 979/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 980/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.9ms\n",
            "video 1/1 (frame 981/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 982/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.3ms\n",
            "video 1/1 (frame 983/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.6ms\n",
            "video 1/1 (frame 984/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.5ms\n",
            "video 1/1 (frame 985/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 986/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.2ms\n",
            "video 1/1 (frame 987/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.6ms\n",
            "video 1/1 (frame 988/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 989/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 990/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 991/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 992/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 993/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.2ms\n",
            "video 1/1 (frame 994/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 995/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.7ms\n",
            "video 1/1 (frame 996/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.9ms\n",
            "video 1/1 (frame 997/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.8ms\n",
            "video 1/1 (frame 998/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.0ms\n",
            "video 1/1 (frame 999/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.5ms\n",
            "video 1/1 (frame 1000/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.8ms\n",
            "video 1/1 (frame 1001/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.9ms\n",
            "video 1/1 (frame 1002/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 1003/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 1004/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 1005/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.7ms\n",
            "video 1/1 (frame 1006/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.0ms\n",
            "video 1/1 (frame 1007/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 1008/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 1009/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 1010/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.6ms\n",
            "video 1/1 (frame 1011/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.8ms\n",
            "video 1/1 (frame 1012/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.9ms\n",
            "video 1/1 (frame 1013/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 1014/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 1015/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.7ms\n",
            "video 1/1 (frame 1016/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.6ms\n",
            "video 1/1 (frame 1017/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 1018/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.0ms\n",
            "video 1/1 (frame 1019/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.6ms\n",
            "video 1/1 (frame 1020/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.5ms\n",
            "video 1/1 (frame 1021/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 1022/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 1023/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 1024/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.5ms\n",
            "video 1/1 (frame 1025/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.9ms\n",
            "video 1/1 (frame 1026/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.0ms\n",
            "video 1/1 (frame 1027/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.5ms\n",
            "video 1/1 (frame 1028/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.8ms\n",
            "video 1/1 (frame 1029/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.3ms\n",
            "video 1/1 (frame 1030/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.4ms\n",
            "video 1/1 (frame 1031/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.3ms\n",
            "video 1/1 (frame 1032/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 1033/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.0ms\n",
            "video 1/1 (frame 1034/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.2ms\n",
            "video 1/1 (frame 1035/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.9ms\n",
            "video 1/1 (frame 1036/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.3ms\n",
            "video 1/1 (frame 1037/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 1038/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.1ms\n",
            "video 1/1 (frame 1039/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 1040/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.3ms\n",
            "video 1/1 (frame 1041/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.7ms\n",
            "video 1/1 (frame 1042/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.5ms\n",
            "video 1/1 (frame 1043/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.5ms\n",
            "video 1/1 (frame 1044/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.3ms\n",
            "video 1/1 (frame 1045/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 20.0ms\n",
            "video 1/1 (frame 1046/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.1ms\n",
            "video 1/1 (frame 1047/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 20.3ms\n",
            "video 1/1 (frame 1048/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 18.5ms\n",
            "video 1/1 (frame 1049/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 1050/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.3ms\n",
            "video 1/1 (frame 1051/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 15.6ms\n",
            "video 1/1 (frame 1052/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.1ms\n",
            "video 1/1 (frame 1053/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.3ms\n",
            "video 1/1 (frame 1054/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.2ms\n",
            "video 1/1 (frame 1055/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 12.5ms\n",
            "video 1/1 (frame 1056/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 18.7ms\n",
            "video 1/1 (frame 1057/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 16.9ms\n",
            "video 1/1 (frame 1058/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.9ms\n",
            "video 1/1 (frame 1059/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.8ms\n",
            "video 1/1 (frame 1060/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.0ms\n",
            "video 1/1 (frame 1061/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.1ms\n",
            "video 1/1 (frame 1062/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.9ms\n",
            "video 1/1 (frame 1063/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.9ms\n",
            "video 1/1 (frame 1064/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.7ms\n",
            "video 1/1 (frame 1065/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 2 Bicycles, 17.0ms\n",
            "video 1/1 (frame 1066/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.6ms\n",
            "video 1/1 (frame 1067/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.7ms\n",
            "video 1/1 (frame 1068/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 20.3ms\n",
            "video 1/1 (frame 1069/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.8ms\n",
            "video 1/1 (frame 1070/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.9ms\n",
            "video 1/1 (frame 1071/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.0ms\n",
            "video 1/1 (frame 1072/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.1ms\n",
            "video 1/1 (frame 1073/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.7ms\n",
            "video 1/1 (frame 1074/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 1075/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.7ms\n",
            "video 1/1 (frame 1076/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 1077/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.1ms\n",
            "video 1/1 (frame 1078/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 1079/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 19.4ms\n",
            "video 1/1 (frame 1080/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.2ms\n",
            "video 1/1 (frame 1081/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 1082/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 1083/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.3ms\n",
            "video 1/1 (frame 1084/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.9ms\n",
            "video 1/1 (frame 1085/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.0ms\n",
            "video 1/1 (frame 1086/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.1ms\n",
            "video 1/1 (frame 1087/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.1ms\n",
            "video 1/1 (frame 1088/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.2ms\n",
            "video 1/1 (frame 1089/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 14.5ms\n",
            "video 1/1 (frame 1090/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.9ms\n",
            "video 1/1 (frame 1091/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 13.7ms\n",
            "video 1/1 (frame 1092/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.8ms\n",
            "video 1/1 (frame 1093/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 12.0ms\n",
            "video 1/1 (frame 1094/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 10.9ms\n",
            "video 1/1 (frame 1095/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.2ms\n",
            "video 1/1 (frame 1096/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.4ms\n",
            "video 1/1 (frame 1097/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.2ms\n",
            "video 1/1 (frame 1098/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.4ms\n",
            "video 1/1 (frame 1099/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 23.0ms\n",
            "video 1/1 (frame 1100/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 17.1ms\n",
            "video 1/1 (frame 1101/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 1102/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 1103/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.4ms\n",
            "video 1/1 (frame 1104/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 1105/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 1106/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.2ms\n",
            "video 1/1 (frame 1107/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 1108/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 1109/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 1110/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 1111/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 1112/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 1113/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.2ms\n",
            "video 1/1 (frame 1114/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.3ms\n",
            "video 1/1 (frame 1115/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 1116/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.6ms\n",
            "video 1/1 (frame 1117/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 1118/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 1119/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.0ms\n",
            "video 1/1 (frame 1120/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 1121/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 1122/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 1123/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 1124/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 1125/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 1126/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 1127/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 1128/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 1129/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 1130/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.1ms\n",
            "video 1/1 (frame 1131/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 1132/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 1133/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 1134/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 1135/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 1136/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 1137/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 1138/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 1139/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.8ms\n",
            "video 1/1 (frame 1140/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 1141/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 1142/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 1143/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 1144/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 1145/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 1146/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 1147/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 1148/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 1149/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.1ms\n",
            "video 1/1 (frame 1150/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 1151/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 1152/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.3ms\n",
            "video 1/1 (frame 1153/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.2ms\n",
            "video 1/1 (frame 1154/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.5ms\n",
            "video 1/1 (frame 1155/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 1156/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 1157/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 1158/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.0ms\n",
            "video 1/1 (frame 1159/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.6ms\n",
            "video 1/1 (frame 1160/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.7ms\n",
            "video 1/1 (frame 1161/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (frame 1162/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.2ms\n",
            "video 1/1 (frame 1163/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 1164/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 1165/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 1166/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 1167/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.8ms\n",
            "video 1/1 (frame 1168/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.2ms\n",
            "video 1/1 (frame 1169/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 1170/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 1171/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 1172/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 1173/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 1174/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.3ms\n",
            "video 1/1 (frame 1175/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.1ms\n",
            "video 1/1 (frame 1176/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 1177/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 1178/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 1179/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 1180/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 1181/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 1182/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 1183/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.3ms\n",
            "video 1/1 (frame 1184/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.4ms\n",
            "video 1/1 (frame 1185/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.4ms\n",
            "video 1/1 (frame 1186/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.0ms\n",
            "video 1/1 (frame 1187/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.5ms\n",
            "video 1/1 (frame 1188/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 1189/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 1190/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 1191/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 1192/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.4ms\n",
            "video 1/1 (frame 1193/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.0ms\n",
            "video 1/1 (frame 1194/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 1195/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.2ms\n",
            "video 1/1 (frame 1196/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.5ms\n",
            "video 1/1 (frame 1197/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.8ms\n",
            "video 1/1 (frame 1198/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.9ms\n",
            "video 1/1 (frame 1199/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 1200/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.7ms\n",
            "video 1/1 (frame 1201/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.5ms\n",
            "video 1/1 (frame 1202/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 1203/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.4ms\n",
            "video 1/1 (frame 1204/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 1205/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 1206/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 1207/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.7ms\n",
            "video 1/1 (frame 1208/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.8ms\n",
            "video 1/1 (frame 1209/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 1210/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 1211/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 1212/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 1213/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 1214/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.6ms\n",
            "video 1/1 (frame 1215/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 1216/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.3ms\n",
            "video 1/1 (frame 1217/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 1218/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 1219/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.6ms\n",
            "video 1/1 (frame 1220/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 1221/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.3ms\n",
            "video 1/1 (frame 1222/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 1223/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 1224/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 1225/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 1226/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.8ms\n",
            "video 1/1 (frame 1227/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 1228/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.7ms\n",
            "video 1/1 (frame 1229/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.6ms\n",
            "video 1/1 (frame 1230/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 1231/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.0ms\n",
            "video 1/1 (frame 1232/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 1233/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.1ms\n",
            "video 1/1 (frame 1234/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (frame 1235/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.7ms\n",
            "video 1/1 (frame 1236/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 1237/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 1238/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.6ms\n",
            "video 1/1 (frame 1239/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.2ms\n",
            "video 1/1 (frame 1240/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.2ms\n",
            "video 1/1 (frame 1241/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.9ms\n",
            "video 1/1 (frame 1242/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.9ms\n",
            "video 1/1 (frame 1243/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 1244/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 1245/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 1246/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 1247/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 10.1ms\n",
            "video 1/1 (frame 1248/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.4ms\n",
            "video 1/1 (frame 1249/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.5ms\n",
            "video 1/1 (frame 1250/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.7ms\n",
            "video 1/1 (frame 1251/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.9ms\n",
            "video 1/1 (frame 1252/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.3ms\n",
            "video 1/1 (frame 1253/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 22.5ms\n",
            "video 1/1 (frame 1254/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.4ms\n",
            "video 1/1 (frame 1255/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 1256/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 1257/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 1258/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.3ms\n",
            "video 1/1 (frame 1259/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 23.7ms\n",
            "video 1/1 (frame 1260/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 1261/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.4ms\n",
            "video 1/1 (frame 1262/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.8ms\n",
            "video 1/1 (frame 1263/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.3ms\n",
            "video 1/1 (frame 1264/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.4ms\n",
            "video 1/1 (frame 1265/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.6ms\n",
            "video 1/1 (frame 1266/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 1267/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.3ms\n",
            "video 1/1 (frame 1268/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.7ms\n",
            "video 1/1 (frame 1269/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.4ms\n",
            "video 1/1 (frame 1270/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 24.6ms\n",
            "video 1/1 (frame 1271/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.9ms\n",
            "video 1/1 (frame 1272/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 33.6ms\n",
            "video 1/1 (frame 1273/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.0ms\n",
            "video 1/1 (frame 1274/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.5ms\n",
            "video 1/1 (frame 1275/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.9ms\n",
            "video 1/1 (frame 1276/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 18.7ms\n",
            "video 1/1 (frame 1277/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.9ms\n",
            "video 1/1 (frame 1278/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 17.3ms\n",
            "video 1/1 (frame 1279/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 1280/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.5ms\n",
            "video 1/1 (frame 1281/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.7ms\n",
            "video 1/1 (frame 1282/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.6ms\n",
            "video 1/1 (frame 1283/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.5ms\n",
            "video 1/1 (frame 1284/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 24.2ms\n",
            "video 1/1 (frame 1285/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 21.6ms\n",
            "video 1/1 (frame 1286/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.5ms\n",
            "video 1/1 (frame 1287/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 20.6ms\n",
            "video 1/1 (frame 1288/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 16.4ms\n",
            "video 1/1 (frame 1289/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 19.4ms\n",
            "video 1/1 (frame 1290/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 16.2ms\n",
            "video 1/1 (frame 1291/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 1292/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.1ms\n",
            "video 1/1 (frame 1293/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 1294/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 1295/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 1296/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.6ms\n",
            "video 1/1 (frame 1297/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 1298/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 9.6ms\n",
            "video 1/1 (frame 1299/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 15.1ms\n",
            "video 1/1 (frame 1300/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 1 Bicycle, 11.5ms\n",
            "video 1/1 (frame 1301/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.8ms\n",
            "video 1/1 (frame 1302/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.9ms\n",
            "video 1/1 (frame 1303/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 1304/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.7ms\n",
            "video 1/1 (frame 1305/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.0ms\n",
            "video 1/1 (frame 1306/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 11.3ms\n",
            "video 1/1 (frame 1307/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 13.1ms\n",
            "video 1/1 (frame 1308/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (frame 1309/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 1310/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 14.3ms\n",
            "video 1/1 (frame 1311/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 9.7ms\n",
            "video 1/1 (frame 1312/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 3028.5ms\n",
            "video 1/1 (frame 1313/1424) /content/gdrive/MyDrive/bicycle_dataset/bicycle.mp4: 384x640 (no detections), 41073.4ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()  # unmounts Google Drive\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AQfdNXtkgu5",
        "outputId": "6769beed-bfbd-4ade-a01f-cbe1da9337b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/bicycle_raw/\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File exists\")\n",
        "else:\n",
        "    print(\"File does not exist\")\n",
        "print(os.getcwd())\n",
        "\n",
        "print(os.listdir(\"/content/drive/MyDrive\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSoRm-cKbz_t",
        "outputId": "b903f8c9-76da-47ca-d671-09b9712e355d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File does not exist\n",
            "/content\n",
            "['yolov10_train']\n"
          ]
        }
      ]
    }
  ]
}